{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Textile documentation. Whether you are an expert or an absolute beginner, you'll find your answers here. Pick a starting point below, or use the search box to find documents matching your keywords. Textile is designed to connect and extend Libp2p , IPFS , and Filecoin . Below, you'll find the three technologies that makeup Textile: the Hub, ThreadDB, and the Powergate. Together, these tools should help you build apps that are only limited by your imagination! The Hub \u00b6 The Hub is a portal to the IPFS network. Use Textile's managed services to persist your data on the IPFS network, enhance the speed and availability of your decentralized databases, and more. The Hub has APIs for developers and teams to push data to the network and it has developer libraries to provide remote IPFS pinning in your apps or simplify the deployment of our decentralized database, ThreadDB. Start building \u00b6 Introduction Learn more about using the Textile Hub. Buckets Persist your data on remote IPFS peers. App APIs Use Threads & Buckets to persist data on IPFS from your apps. ThreadDB \u00b6 ThreadDB is a secure, decentralized, p2p database built on IPFS and Libp2p. Developers use ThreadDB so they can spend less time configuring encryption or managing content addresses, instead ThreadDB allows them to start building right away. A familiar MongoDB/Mongoose API and simple data hosting services make dynamic data on the DWeb easy! Learn more \u00b6 Introduction Learn about ThreadDB and how to use them in your app. App APIs Use the Hub to help persist and scale your user's databases. JavaScript Docs Start using the ThreadDB in your NodeJS and browser apps. Start building \u00b6 JS Todo App Build a Todo app with Textile Thread pinning services. Go Chat App Build a multi-user chat app in Go. Filecoin Powergate \u00b6 The Powergate is just warming up! The Powergate is an API driven solution to deploy hybrid Filecoin and IPFS storage into your app. If you are eager to learn more about what we are up to, we invite you to follow our regular community updates or follow along in the the open-source repo . If you want to jump right in, follow one of the links below. Dive into Filecoin \u00b6 System overview Multitiered file storage API built on Filecoin and IPFS. Spin-up the Devnet You can test, explore, and build on all the Filecoin APIs today with Devnet POW JS Client Typescript/Javascript client for Textile's Powergate . Other Resources \u00b6 Join our public Slack , visit our GitHub , follow us on Twitter , and check out the Blog ! This site is on /ipns/bafzbeicijsxazzszfhoqcmm4z76p54w56bazq4aaobwafbdkmq2beyn5a Thanks! \u00b6 To all of the great people who have contributed to the Textile projects recently.","title":"Home"},{"location":"#the-hub","text":"The Hub is a portal to the IPFS network. Use Textile's managed services to persist your data on the IPFS network, enhance the speed and availability of your decentralized databases, and more. The Hub has APIs for developers and teams to push data to the network and it has developer libraries to provide remote IPFS pinning in your apps or simplify the deployment of our decentralized database, ThreadDB.","title":"The Hub"},{"location":"#start-building","text":"","title":"Start building"},{"location":"#threaddb","text":"ThreadDB is a secure, decentralized, p2p database built on IPFS and Libp2p. Developers use ThreadDB so they can spend less time configuring encryption or managing content addresses, instead ThreadDB allows them to start building right away. A familiar MongoDB/Mongoose API and simple data hosting services make dynamic data on the DWeb easy!","title":"ThreadDB"},{"location":"#learn-more","text":"","title":"Learn more"},{"location":"#start-building_1","text":"","title":"Start building"},{"location":"#filecoin-powergate","text":"The Powergate is just warming up! The Powergate is an API driven solution to deploy hybrid Filecoin and IPFS storage into your app. If you are eager to learn more about what we are up to, we invite you to follow our regular community updates or follow along in the the open-source repo . If you want to jump right in, follow one of the links below.","title":"Filecoin Powergate"},{"location":"#dive-into-filecoin","text":"","title":"Dive into Filecoin"},{"location":"#other-resources","text":"Join our public Slack , visit our GitHub , follow us on Twitter , and check out the Blog ! This site is on /ipns/bafzbeicijsxazzszfhoqcmm4z76p54w56bazq4aaobwafbdkmq2beyn5a","title":"Other Resources"},{"location":"#thanks","text":"To all of the great people who have contributed to the Textile projects recently.","title":"Thanks!"},{"location":"a-tour-of-textile/","text":"The tour has moved, start here .","title":"A tour of textile"},{"location":"hub/","text":"The Hub is a portal where teams and individual developers can access IPFS and soon Filecoin resources easily. The Hub makes it simple to manage and update Buckets on IPFS, persist data for your users on IPFS, deploy and scale Threads databases for your app users, and collaborate on all of it with your team! Getting Started \u00b6 The Hub is API driven and available through the command-line tool and developer libraries. To use the Hub, first you need to download the command-line interface and create an account. Textile Hub Accounts Download the CLI and create your free Hub account. Once you have your Hub account, you can start using the Hub to host your data on the IPFS network. IPFS hosting is offered using a Textile technology called, Buckets. Buckets offer you dynamic, folder-based, directories that you can use to persist data on IPFS. They are editable, sharable, and come with free URLs. Buckets Learn how to create, manage, share, and publish data on IPFS. Another thing you can do with your account on the Hub, is create an app token that will allow you to use the Hub for persisting user Thread data. Think of it as a trustless service that your app's database can rely on to quickly store and access data on IPFS! Thread Services Persist and relay Thread updates for your app users. Other Documentation \u00b6 Next steps \u00b6 Create an Account Start using hosted services by creating your free account. Connect your Apps Learn how to use the Hub's APIs in your app. Hub CLI Read the full CLI documentation.","title":"Introduction"},{"location":"hub/#getting-started","text":"The Hub is API driven and available through the command-line tool and developer libraries. To use the Hub, first you need to download the command-line interface and create an account.","title":"Getting Started"},{"location":"hub/#other-documentation","text":"","title":"Other Documentation"},{"location":"hub/#next-steps","text":"","title":"Next steps"},{"location":"hub/accounts/","text":"Getting Started \u00b6 Installation \u00b6 To access and manage Hub resources, you need to install the Textile CLI. First, download the Textile CLI binary for your platform from the latest releases. Download \u00b6 Download the Textile CLI Latest Release . Install \u00b6 Open the contents of the downloaded archive and run the install script. This should install the tt tool on your computer. You can verify with hub --help . Mac Installation \u00b6 On MacOS you will need to confirm that it is okay to run the tt binary before it will run successfully. You will see this warning: Select 'Cancel' Go to 'System Settings' => 'General' where you will be able to click, 'Always Allow' Run hub --help again and this time select, 'Open` when promted. You will now be able to continue using the CLI without issue. When you update the binary, you may need to repeat the above steps. We will add developer signing to our MacOS binaries soon. Account setup \u00b6 Initialize \u00b6 To start using remote services such as IPFS pinning, Bucket sharing, and Thread APIs, you need an account on the Hub. Textile provides a simple, password-less account setup. You can create a new account and username with just an email address. hub init Whoami \u00b6 You can always verify that you have an active session on the Hub and that you are using the correct account by running the hub whoami command. Login \u00b6 If you've just initialized your account successfully, there is no need to login. However, if you are returning to the Hub and need to re-login, simply use the login command. hub login Organizations \u00b6 The Hub allows you to create organizations easily. Organizations can be one or many collaborators. Members of an Org have management access to the Buckets and App Keys created while in an Org's directory. Info You can create , invite , and leave organizations easily. Read more about all Org methods on the CLI docs . To learn more about sharing Buckets with an organization, read the intro on Organization Buckets . Enterprise users \u00b6 If you are interested in enterprise support from Textile, please email us at support@textile.io .","title":"Accounts"},{"location":"hub/accounts/#getting-started","text":"","title":"Getting Started"},{"location":"hub/accounts/#installation","text":"To access and manage Hub resources, you need to install the Textile CLI. First, download the Textile CLI binary for your platform from the latest releases.","title":"Installation"},{"location":"hub/accounts/#download","text":"Download the Textile CLI Latest Release .","title":"Download"},{"location":"hub/accounts/#install","text":"Open the contents of the downloaded archive and run the install script. This should install the tt tool on your computer. You can verify with hub --help .","title":"Install"},{"location":"hub/accounts/#mac-installation","text":"On MacOS you will need to confirm that it is okay to run the tt binary before it will run successfully. You will see this warning: Select 'Cancel' Go to 'System Settings' => 'General' where you will be able to click, 'Always Allow' Run hub --help again and this time select, 'Open` when promted. You will now be able to continue using the CLI without issue. When you update the binary, you may need to repeat the above steps. We will add developer signing to our MacOS binaries soon.","title":"Mac Installation"},{"location":"hub/accounts/#account-setup","text":"","title":"Account setup"},{"location":"hub/accounts/#initialize","text":"To start using remote services such as IPFS pinning, Bucket sharing, and Thread APIs, you need an account on the Hub. Textile provides a simple, password-less account setup. You can create a new account and username with just an email address. hub init","title":"Initialize"},{"location":"hub/accounts/#whoami","text":"You can always verify that you have an active session on the Hub and that you are using the correct account by running the hub whoami command.","title":"Whoami"},{"location":"hub/accounts/#login","text":"If you've just initialized your account successfully, there is no need to login. However, if you are returning to the Hub and need to re-login, simply use the login command. hub login","title":"Login"},{"location":"hub/accounts/#organizations","text":"The Hub allows you to create organizations easily. Organizations can be one or many collaborators. Members of an Org have management access to the Buckets and App Keys created while in an Org's directory. Info You can create , invite , and leave organizations easily. Read more about all Org methods on the CLI docs . To learn more about sharing Buckets with an organization, read the intro on Organization Buckets .","title":"Organizations"},{"location":"hub/accounts/#enterprise-users","text":"If you are interested in enterprise support from Textile, please email us at support@textile.io .","title":"Enterprise users"},{"location":"hub/app-apis/","text":"Getting Started \u00b6 Use the Hub to help scale your applications on IPFS. The Hub APIs are available for your apps and your app users. You can use the Hub APIs with a privileged Account API Key or with a User Group Key . Both have the ability to push new data to Buckets, persist ThreadDB data, and relay ThreadDB updates (among other things). Attaching the Hub to your users' data will allow you to deliver high-quality user-experiences. In order to make this as straightforward as possible, you need to understand a few additional basic concepts. Owner CLI Account Key User Group Key Developer Threads Hub Login create, access create, access Developer Buckets Hub Login create, access create, access Organization Threads Hub Login create, access create, access Organization Buckets Hub Login create, access create, access App User Threads PKI Identity create, access App User Buckets PKI Identity create, access The above table gives an overview of the different roles that can create or manage Threads and Buckets. In short, there are developer identities on the Hub and then a developer's app users represented as private-key identities originating in their app. Each can use resources on the Hub, and below we will walk through the details of each. API Access \u00b6 Account Key \u00b6 Account keys provide direct access to developer and org account Buckets and Threads. Account keys make it possible to build apps that have full access to developer or organization Buckets. You can use account keys to integrate your Buckets into CI, dashboards, team messaging integration, etc. To create a new Account Key using hub key create and selecting the account option. See CLI options User Group Key \u00b6 User groups are non-admin groups of users (e.g. app users or beta users) that you want to provide restricted access to your Hub APIs. For each user group you want, you create a single user group key that will be used by all members of the group to access your API endpoint (developer or organization). For example, your app can create Buckets and Threads on behalf of your user that they sign on device with their own identity. Managing User Group Keys \u00b6 To create a new user group key using hub key create and selecting the user group option. If you are buiding an app in an organization, use hub key create --org=<name> to link a new key to the organization not your personal account. There is currently no migration tools, so we recommend creating a new organization or using an existing organization when starting a new app (see Organizations ) You can replace your keys in your app at any time and the user will still have access to their Threads and Buckets as long as the key is connected to the same developer or organization. If you fully delete your account or organization, data replicated on IPFS through the user group key will also be removed . So if you remove your account, we highly encourage you to replicate the data on an external IPFS node, provide tools for your users to export or replicate their own account data, or host external Thread Services to migrate your user Thread replication to. Also see Identity section and how to use identity providers such as 3Box with user group keys. See CLI commands Domain whitelisting \u00b6 If you are building a web application, you can use domain whitelisting to access the same resources without embedding keys in your application. You can track the release of domain whitelisting here . App APIs \u00b6 Buckets \u00b6 Buckets provide S3-like data storage on IPFS. Just as you can create Buckets with the Hub CLI , you can create Buckets using JavaScript with js-hub . The js-hub library allows you to create and edit Buckets owned by you or your organization using an account key . Alternatively, you can use Buckets to store your user's data using a user group key . ThreadDB \u00b6 ThreadDB is a mongo-like database that runs on IPFS. You can use it in combination with js-hub to add replication and relay to your user's databases. When combined, js-threads and js-hub allow you to embed private, p2p databases in your app that use remote IPFS peers for pinning and remote ThreadDB peers to relay updates to all parties. This configuration will help you scale your app and offer the highest quality experience to your users. Data Ownership \u00b6 The databases and buckets you create over the APIs are owned in one of three ways. Developer owned. If you use an account key with the Buckets or ThreadDB APIs, the data will be linked directly to your account. Org owned. If you create an account key using the --org flag, the Buckets and Threads will be linked to the organization. User owned. If you create a user group key, Textile allows your app to provision new Buckets and Threads on behalf of your users. This data will be signed and owned by your end-users and only accessible to them. Developers can specify the context to customize exactly how resources (e.g., storage, networking, etc) are used/allocated within their own apps, and which of the three above ownership strategies are applied. This Conext API allows a developer to shift what role they are using to access the remote Hub APIs. This is interesting because a developer is able to access Hub resources as themselves (i.e., the developer), with all the administrative capabilities that entails, or as users of their app, which are sandboxed but able to create Threads (and Buckets) of their own within that user-scoped sandbox. This is a very powerful framework for accessing and allocating developer resources on behalf of users, while still providing the control and quality user-experience that apps built on Threads should provide. Identity \u00b6 Related to data ownership is the concept of identity. Textile's Hub and Buckets/ThreadDB APIs are flexible when it comes to user identity, allowing you to handle user identities (for access control and security/encryption) in the best way for your app and your users. In order to handle multiple peers collaborating on a single database, as well as the ability to handle storage on behalf of a user, Hub APIs expect a simple Identity interface for singing and validating updates. interface Public { verify ( data : Buffer , sig : Buffer ) : Promise < boolean > } interface Identity { sign ( data : Buffer ) : Promise < Buffer > public : Public } Identity here represents any entity capable of signing a message. This is a simple public key infrastructure inspired interface that similarly requires the implementer to be capable of returning an associated public key for verification. In many cases, the Identity will just be a private key, but callers can use any setup that suits their needs. A default implementation based on Libp2p's crypto library is provided for convinience (and is also used by default if no identity is provided), however, many developers will want to use alternative identity provides, such as 3box/Ceramic , Fortmatic , and existing private/public keypair, or a web3 provider such as Metamask . Textile Hub also provides email-based identities. Identities also provide a way for developers to allocate resources (i.e., storage) for a particular user, and in fact, is a key component in ensuring that a user controls their own data . Example: User Owned Database \u00b6 To illustrate the utility of Identity and Context, in the following example, we will create a user owned ThreadDB within a \"user context\". This should provide a useful example for getting started with Textile's Hub APIs in the context of a database. We'll also interact with our remote database using the Threads Client library (see also additional examples using the local-first database in the ThreadDB introduction ). To get started with Textile's Context API, follow the instructions in our getting started guide . Once you have downloaded and installed the command-line tools, be sure to create a developer account. Next, create a new user key using hub key create command line tool. After some steps to create an account, you can create the keys. \u279c hub key create # select the 'user' option This should produce output similar to the following. Make note of these values, but do not share them! For a Node app, it is a good idea to use a tool such as dotenv to reference them in your apps, which is what we will assume below. So create a simple .env file with USER_API_KEY and USER_API_SECRET keys. \u2714 user KEY SECRET TYPE bqab5csdh...no6jjezox4 bm2tk476yivwlw...3a4cayll7ztha user > Success! Created new API key and secret Once you have the key information handy, let's jump to some code. We'll start with the required imports, and initialize a basic default Context . import { Context } from '@textile/context' import { Libp2pCryptoIdentity } from '@textile/threads-core' import { Client } from '@textile/threads-client' import { config } from 'dotenv' // Load your .env into process.env const parsed = config () Prepare Identity & Token \u00b6 The Context module provides a useful set of methods for managing and using developer keys and signatures on the client side, abstracting away some of the complexity of developer key management and communication with Textile's remote Hub gRPC APIs. For example, to create a new basic Context that will connect to Textile's remote Hub, you can initialize a Context with all defaults. While we're at it, we'll also create a default identity for our user, using the Libp2pCryptoIdentity object. In practice, you might have your own identity provider, or you might want to use a hierarchical key/wallet or mnemonic phrase to help store a users keys for them. Whatever you decide, Textile's generic identity interface should be able to support it. const ctx = new Context () const identity = await Libp2pCryptoIdentity . fromRandom () // Random identity The next step is to authenticate the user with your user group key and Secret. This will allow the user to store threads and buckets using your developer resources on the Hub. // Update the context WITH the user group key information await ctx . withUserKey ({ key : process.env.USER_API_KEY , secret : process.env.USER_API_SECRET , type : 1 , // User group key type }) // This will also return a promise with your updated context: Setup ThreadDB \u00b6 Now we will connect to our remote ThreadDB client. This will allow us to connect to a remote ThreadDB on the Textile Hub. This is an alternative to a local-first database where keys and data are stored locally on the device. const db = new Client ( ctx ) // API calls will now include the credentials created above With the ThreadDB instance ready to connect to the remote database, it is time to generate a user token. This allows us (the developer) to allocate user-scoped resources without our remote database. The app user (defined by their Identity created above) needs an API token to perform database operations. The API will give you one based on ID plus your developer credentials. The token will be added to the existing db.context. The token can also be stored/cached for future use by the same user identity (and then manually be added to a context later). const token = await db . getToken ( identity ) Note that this operation updates the database's context in place. This updated context can be stored in a session or however your app stores app state. console . log ( JSON . stringify ( db . context . toJSON ())) An app should create a minimal number of Threads per user to avoid creating unnecessary storage. A single Thread can contain a large number of distinct Collections for different types of data. Here, we create a new Thread for a user, but you could similarly store this ThreadID in (say) a local database or your app state and restore it using ThreadID.fromString() . import { ThreadID } from '@textile/threads-id' const id = ThreadID . fromRandom () await db . newDB ( id ) // Updates the context to include the thread id // Or, do it manually // db.context.withThread(id) For this example, we're going to be working with a Collection of Astronauts. The schema looks like this. const astronautSchema = { $id : 'https://example.com/astronaut.schema.json' , $schema : 'http://json-schema.org/draft-07/schema#' , title : 'Astronauts' , type : 'object' , required : [ '_id' ], properties : { _id : { type : 'string' , }, firstName : { type : 'string' , }, lastName : { type : 'string' , }, missions : { type : 'integer' , minimum : 0 , }, }, } ``` Using that schema, we'll create a new collection. See [our ThreadDB introduction](https://docs.textile.io/threads/) for details about Collections, Schemas, and Instances. ``` typescript await db . newCollection ( id , 'Astronaut' , astronautSchema ) ``` ### Add Instance to Collection Now that our ThreadDB contains the Astronaut Collection, you just need to add a new astronaut that matches the expected schema. If you run the following code many times, you'll notice many Buzz Aldrin entries in your ThreadDB, each with a unique ID. ``` typescript const ids = await db . create ( id , 'Astronaut' , [ { _id : '' , // Leave empty to auto-generate firstName : 'Buzz' , lastName : 'Aldrin' , missions : 2 , } ]) Query from our Collection \u00b6 You can search all your existing Buzz Aldrins pretty easily. You can also clean up our entries (just delete them all!), modify them, or perform various transactions. import { Where } from '@textile/threads-client' const q = new Where ( 'firstName' ). eq ( 'Buzz' ) const r = await db . find ( id , 'Astronaut' , q ) // Extract just the ids const ids = r . instancesList . map (( instance : any ) => instance . _id ) console . log ( `Found ${ ids . length } entries` ) // Cleanup! await db . delete ( id , 'Astronaut' , ids ) We leave the remaining operations as an exercise for the reader. Have fun, explore, and let us know what you think! Libraries \u00b6 You can find all remote Thread and Bucket APIs in the textile libraries below. These libraries are meant to work in combination with the threads libraries when you want to create and manage Threads database in your app. Here are the libraries you will find useful to start building today. ThreadDB Threads APIs & Buckets Browser, React Native, & NodeJS js-threads js-hub Dart & Flutter Apps ( pending release ) dart-threads-client dart-textile Golang Libraries go-threads Command-line thread-shell (coming) Hub CLI","title":"App APIs"},{"location":"hub/app-apis/#getting-started","text":"Use the Hub to help scale your applications on IPFS. The Hub APIs are available for your apps and your app users. You can use the Hub APIs with a privileged Account API Key or with a User Group Key . Both have the ability to push new data to Buckets, persist ThreadDB data, and relay ThreadDB updates (among other things). Attaching the Hub to your users' data will allow you to deliver high-quality user-experiences. In order to make this as straightforward as possible, you need to understand a few additional basic concepts. Owner CLI Account Key User Group Key Developer Threads Hub Login create, access create, access Developer Buckets Hub Login create, access create, access Organization Threads Hub Login create, access create, access Organization Buckets Hub Login create, access create, access App User Threads PKI Identity create, access App User Buckets PKI Identity create, access The above table gives an overview of the different roles that can create or manage Threads and Buckets. In short, there are developer identities on the Hub and then a developer's app users represented as private-key identities originating in their app. Each can use resources on the Hub, and below we will walk through the details of each.","title":"Getting Started"},{"location":"hub/app-apis/#api-access","text":"","title":"API Access"},{"location":"hub/app-apis/#account-key","text":"Account keys provide direct access to developer and org account Buckets and Threads. Account keys make it possible to build apps that have full access to developer or organization Buckets. You can use account keys to integrate your Buckets into CI, dashboards, team messaging integration, etc. To create a new Account Key using hub key create and selecting the account option. See CLI options","title":"Account Key"},{"location":"hub/app-apis/#user-group-key","text":"User groups are non-admin groups of users (e.g. app users or beta users) that you want to provide restricted access to your Hub APIs. For each user group you want, you create a single user group key that will be used by all members of the group to access your API endpoint (developer or organization). For example, your app can create Buckets and Threads on behalf of your user that they sign on device with their own identity.","title":"User Group Key"},{"location":"hub/app-apis/#managing-user-group-keys","text":"To create a new user group key using hub key create and selecting the user group option. If you are buiding an app in an organization, use hub key create --org=<name> to link a new key to the organization not your personal account. There is currently no migration tools, so we recommend creating a new organization or using an existing organization when starting a new app (see Organizations ) You can replace your keys in your app at any time and the user will still have access to their Threads and Buckets as long as the key is connected to the same developer or organization. If you fully delete your account or organization, data replicated on IPFS through the user group key will also be removed . So if you remove your account, we highly encourage you to replicate the data on an external IPFS node, provide tools for your users to export or replicate their own account data, or host external Thread Services to migrate your user Thread replication to. Also see Identity section and how to use identity providers such as 3Box with user group keys. See CLI commands","title":"Managing User Group Keys"},{"location":"hub/app-apis/#domain-whitelisting","text":"If you are building a web application, you can use domain whitelisting to access the same resources without embedding keys in your application. You can track the release of domain whitelisting here .","title":"Domain whitelisting"},{"location":"hub/app-apis/#app-apis","text":"","title":"App APIs"},{"location":"hub/app-apis/#buckets","text":"Buckets provide S3-like data storage on IPFS. Just as you can create Buckets with the Hub CLI , you can create Buckets using JavaScript with js-hub . The js-hub library allows you to create and edit Buckets owned by you or your organization using an account key . Alternatively, you can use Buckets to store your user's data using a user group key .","title":"Buckets"},{"location":"hub/app-apis/#threaddb","text":"ThreadDB is a mongo-like database that runs on IPFS. You can use it in combination with js-hub to add replication and relay to your user's databases. When combined, js-threads and js-hub allow you to embed private, p2p databases in your app that use remote IPFS peers for pinning and remote ThreadDB peers to relay updates to all parties. This configuration will help you scale your app and offer the highest quality experience to your users.","title":"ThreadDB"},{"location":"hub/app-apis/#data-ownership","text":"The databases and buckets you create over the APIs are owned in one of three ways. Developer owned. If you use an account key with the Buckets or ThreadDB APIs, the data will be linked directly to your account. Org owned. If you create an account key using the --org flag, the Buckets and Threads will be linked to the organization. User owned. If you create a user group key, Textile allows your app to provision new Buckets and Threads on behalf of your users. This data will be signed and owned by your end-users and only accessible to them. Developers can specify the context to customize exactly how resources (e.g., storage, networking, etc) are used/allocated within their own apps, and which of the three above ownership strategies are applied. This Conext API allows a developer to shift what role they are using to access the remote Hub APIs. This is interesting because a developer is able to access Hub resources as themselves (i.e., the developer), with all the administrative capabilities that entails, or as users of their app, which are sandboxed but able to create Threads (and Buckets) of their own within that user-scoped sandbox. This is a very powerful framework for accessing and allocating developer resources on behalf of users, while still providing the control and quality user-experience that apps built on Threads should provide.","title":"Data Ownership"},{"location":"hub/app-apis/#identity","text":"Related to data ownership is the concept of identity. Textile's Hub and Buckets/ThreadDB APIs are flexible when it comes to user identity, allowing you to handle user identities (for access control and security/encryption) in the best way for your app and your users. In order to handle multiple peers collaborating on a single database, as well as the ability to handle storage on behalf of a user, Hub APIs expect a simple Identity interface for singing and validating updates. interface Public { verify ( data : Buffer , sig : Buffer ) : Promise < boolean > } interface Identity { sign ( data : Buffer ) : Promise < Buffer > public : Public } Identity here represents any entity capable of signing a message. This is a simple public key infrastructure inspired interface that similarly requires the implementer to be capable of returning an associated public key for verification. In many cases, the Identity will just be a private key, but callers can use any setup that suits their needs. A default implementation based on Libp2p's crypto library is provided for convinience (and is also used by default if no identity is provided), however, many developers will want to use alternative identity provides, such as 3box/Ceramic , Fortmatic , and existing private/public keypair, or a web3 provider such as Metamask . Textile Hub also provides email-based identities. Identities also provide a way for developers to allocate resources (i.e., storage) for a particular user, and in fact, is a key component in ensuring that a user controls their own data .","title":"Identity"},{"location":"hub/app-apis/#example-user-owned-database","text":"To illustrate the utility of Identity and Context, in the following example, we will create a user owned ThreadDB within a \"user context\". This should provide a useful example for getting started with Textile's Hub APIs in the context of a database. We'll also interact with our remote database using the Threads Client library (see also additional examples using the local-first database in the ThreadDB introduction ). To get started with Textile's Context API, follow the instructions in our getting started guide . Once you have downloaded and installed the command-line tools, be sure to create a developer account. Next, create a new user key using hub key create command line tool. After some steps to create an account, you can create the keys. \u279c hub key create # select the 'user' option This should produce output similar to the following. Make note of these values, but do not share them! For a Node app, it is a good idea to use a tool such as dotenv to reference them in your apps, which is what we will assume below. So create a simple .env file with USER_API_KEY and USER_API_SECRET keys. \u2714 user KEY SECRET TYPE bqab5csdh...no6jjezox4 bm2tk476yivwlw...3a4cayll7ztha user > Success! Created new API key and secret Once you have the key information handy, let's jump to some code. We'll start with the required imports, and initialize a basic default Context . import { Context } from '@textile/context' import { Libp2pCryptoIdentity } from '@textile/threads-core' import { Client } from '@textile/threads-client' import { config } from 'dotenv' // Load your .env into process.env const parsed = config ()","title":"Example: User Owned Database"},{"location":"hub/app-apis/#prepare-identity-token","text":"The Context module provides a useful set of methods for managing and using developer keys and signatures on the client side, abstracting away some of the complexity of developer key management and communication with Textile's remote Hub gRPC APIs. For example, to create a new basic Context that will connect to Textile's remote Hub, you can initialize a Context with all defaults. While we're at it, we'll also create a default identity for our user, using the Libp2pCryptoIdentity object. In practice, you might have your own identity provider, or you might want to use a hierarchical key/wallet or mnemonic phrase to help store a users keys for them. Whatever you decide, Textile's generic identity interface should be able to support it. const ctx = new Context () const identity = await Libp2pCryptoIdentity . fromRandom () // Random identity The next step is to authenticate the user with your user group key and Secret. This will allow the user to store threads and buckets using your developer resources on the Hub. // Update the context WITH the user group key information await ctx . withUserKey ({ key : process.env.USER_API_KEY , secret : process.env.USER_API_SECRET , type : 1 , // User group key type }) // This will also return a promise with your updated context:","title":"Prepare Identity &amp; Token"},{"location":"hub/app-apis/#setup-threaddb","text":"Now we will connect to our remote ThreadDB client. This will allow us to connect to a remote ThreadDB on the Textile Hub. This is an alternative to a local-first database where keys and data are stored locally on the device. const db = new Client ( ctx ) // API calls will now include the credentials created above With the ThreadDB instance ready to connect to the remote database, it is time to generate a user token. This allows us (the developer) to allocate user-scoped resources without our remote database. The app user (defined by their Identity created above) needs an API token to perform database operations. The API will give you one based on ID plus your developer credentials. The token will be added to the existing db.context. The token can also be stored/cached for future use by the same user identity (and then manually be added to a context later). const token = await db . getToken ( identity ) Note that this operation updates the database's context in place. This updated context can be stored in a session or however your app stores app state. console . log ( JSON . stringify ( db . context . toJSON ())) An app should create a minimal number of Threads per user to avoid creating unnecessary storage. A single Thread can contain a large number of distinct Collections for different types of data. Here, we create a new Thread for a user, but you could similarly store this ThreadID in (say) a local database or your app state and restore it using ThreadID.fromString() . import { ThreadID } from '@textile/threads-id' const id = ThreadID . fromRandom () await db . newDB ( id ) // Updates the context to include the thread id // Or, do it manually // db.context.withThread(id) For this example, we're going to be working with a Collection of Astronauts. The schema looks like this. const astronautSchema = { $id : 'https://example.com/astronaut.schema.json' , $schema : 'http://json-schema.org/draft-07/schema#' , title : 'Astronauts' , type : 'object' , required : [ '_id' ], properties : { _id : { type : 'string' , }, firstName : { type : 'string' , }, lastName : { type : 'string' , }, missions : { type : 'integer' , minimum : 0 , }, }, } ``` Using that schema, we'll create a new collection. See [our ThreadDB introduction](https://docs.textile.io/threads/) for details about Collections, Schemas, and Instances. ``` typescript await db . newCollection ( id , 'Astronaut' , astronautSchema ) ``` ### Add Instance to Collection Now that our ThreadDB contains the Astronaut Collection, you just need to add a new astronaut that matches the expected schema. If you run the following code many times, you'll notice many Buzz Aldrin entries in your ThreadDB, each with a unique ID. ``` typescript const ids = await db . create ( id , 'Astronaut' , [ { _id : '' , // Leave empty to auto-generate firstName : 'Buzz' , lastName : 'Aldrin' , missions : 2 , } ])","title":"Setup ThreadDB"},{"location":"hub/app-apis/#query-from-our-collection","text":"You can search all your existing Buzz Aldrins pretty easily. You can also clean up our entries (just delete them all!), modify them, or perform various transactions. import { Where } from '@textile/threads-client' const q = new Where ( 'firstName' ). eq ( 'Buzz' ) const r = await db . find ( id , 'Astronaut' , q ) // Extract just the ids const ids = r . instancesList . map (( instance : any ) => instance . _id ) console . log ( `Found ${ ids . length } entries` ) // Cleanup! await db . delete ( id , 'Astronaut' , ids ) We leave the remaining operations as an exercise for the reader. Have fun, explore, and let us know what you think!","title":"Query from our Collection"},{"location":"hub/app-apis/#libraries","text":"You can find all remote Thread and Bucket APIs in the textile libraries below. These libraries are meant to work in combination with the threads libraries when you want to create and manage Threads database in your app. Here are the libraries you will find useful to start building today. ThreadDB Threads APIs & Buckets Browser, React Native, & NodeJS js-threads js-hub Dart & Flutter Apps ( pending release ) dart-threads-client dart-textile Golang Libraries go-threads Command-line thread-shell (coming) Hub CLI","title":"Libraries"},{"location":"hub/buckets/","text":"Buckets \u00b6 Getting Started \u00b6 If you've used cloud storage before, you'll find Buckets easy to understand. Unlike traditional cloud services, Buckets are built on open, decentralized protocols including the IPFS and Libp2p. You can serve websites, data, and apps from Buckets. Buckets are packed with useful features, including: Explore your Buckets on the Hub gateway . Render web content in your Bucket on a persistent website . Automatically distribute your updates on IPFS using IPNS . Collaboratively manage Buckets as an organization . Create private Buckets where your app users can store data . Initialize a Bucket \u00b6 When working on your local machine, Buckets are mapped to working directories. Once you initialize a Bucket in a directory, anytime you return to the directory, the Textile CLI will automatically detect the Bucket you are interacting with. To start a Bucket in your current working directory, you must first initialize the Bucket. You can initialize a bucket with an existing UnixFS DAG available in the IPFS network, or import it interactively in an already existing bucket. Read CLI docs for Buckets . Info Bucket names are unique to a developer and within an Org. They are not globally unique.** Warning Be careful creating a bucket in a root directory, because all children directories will linked to that bucket. To move or remove a bucket's link to a directory, edit, move or delete the .textile/config.yml file (it will be a hidden folder in the bucket's directory) Shared Buckets \u00b6 You can create Buckets to share with all members of an organization. To do so, simply initialize an Org first and then initialize a Bucket using the --org flag, specifying the name of the Org you want to share the bucket with. For example hub bucket init --org nasa . All members of the Org will be able to push and pull files to and from the shared Bucket. Read more about creating Orgs . Info to check which org a bucket is registered with, examine the .textile/config.yml file (it will be a hidden folder in the bucket's directory) Publishing content \u00b6 Push new files \u00b6 View the Bucket push CLI docs . hub bucket push site/ . Retrieving content \u00b6 Pull files \u00b6 hub bucket init --existing Info By using the --existing flag, you can list Buckets already pushed by you or, when using --org , your collaborators. Explore on the gateway \u00b6 To inspect your pushed files, exlore on the gateway: hub bucket links then open the first result 'Thread links' in your browser. The Hub gateway gives you a static URL where you can explore, download, and share your latest Bucket content. Render on a website \u00b6 If your Bucket contains web content, the Bucket website endpoint will provide you a static URL that will always render the latest content from your Bucket. See HTTP Domains . Render on IPFS gateways \u00b6 Buckets are dynamic folders distributed over IPFS using ThreadDB. Each time you create a new Bucket, you will receive a new IPNS Address that you can use on the IPFS address to fetch the latest Bucket content. The IPNS address will not change, but the content will update each time you push changes to your Bucket. Each time you update your Bucket, you will receive a new IPFS address to fetch that version of your Bucket content. HTTP Domain \u00b6 All public Buckets are automatically provided a subdomain on textile.space that will reflect the latest changes in to your Bucket. Your Bucket's IPNS address is used as the subdomain, such that your Bucket URL will always be: <ipns-address>.textile.space . This is designed to further enhance the interoperability of protocols using Textile Buckets. IPNS Address \u00b6 Each Bucket has a unique IPNS address that will allow you to render or fetch your Bucket on any IPFS peer or gateway that supports IPNS (including ipfs.io and Cloudflare ). Buckets can't change the speed of IPNS propagation through the network, but we recommend you explore and try for yourself. The Hub gateway will always render the latest data right away. Bucket Automation (CI/CD) \u00b6 Buckets are an ideal tool for persisting your website, source code, or documentation on IPFS using continuous integration. Tools like Travis CI, CircleCI, and GitHub Actions all make it possible to do very easily. We have provided a configurable GitHub Action that allows you to: Push or update your Bucket based on pull requests, commits, and merges. Generate IPNS, IPFS, and HTTP addresses for every Bucket creation or update. Create temporary Buckets for staging or review that can be removed automatically when content is merged or pull requests are closed. Example output from Textile Bucket GitHub Action Learn more \u00b6 Bucket Permissions \u00b6 Developer Buckets \u00b6 All Buckets you create are scoped to your developer account. You can always find your currently logged in account with hub whoami . Organization Buckets \u00b6 Any Buckets you create using the --org flag will also be shared with Org members. Here are the steps to create an Org, create a new Bucket in the Org, and invite a collaborator to the Org: Create a new Org \u00b6 hub org create Choose an Org name: nasa\u2588 > The name of your account on Textile will be nasa > Your URL will be http://hub.textile.io/nasa Please confirm: y\u2588 > Success! Created new org nasa with URL http://hub.textile.io/nasa You have now created the nasa Org. Create a new Bucket shared with an Org \u00b6 mkdir launchpad cd launchpad hub bucket init --org nasa You have now created a new Bucket inside of the launchpad directory and owned by your nasa organization. Invite a collaborator \u00b6 hub org invite The final step is to invite collaborators to your Org. Once they accept the invite, they will be able to interact with Buckets associated with the Org. App user Buckets \u00b6 If you are building an app using one of our developer libraries you can use Buckets from inside your apps. Apps generally will create Buckets on behalf of each user, meaning the user should retain control of the Bucket metadata and contents. JS Hub Docs Persist user Buckets on IPFS from your JS app. 3Box example See how to use 3Box identities to own Threads and Buckets. Bucket Protocols \u00b6 Buckets are designed to be interoperable across protocols and services. Here are a few examples. Buckets and Threads \u00b6 Buckets are built on ThreadDB . In fact, in their most basic form, Buckets are just a document in a Thread that is updated each time the directory of data is updated. Since Buckets run on Threads, it opens the door to many new integrations that can be built on Buckets! Buckets and HTTP \u00b6 Buckets can be rendered over HTTP through either the Hub Gateway , the Bucket subdomains , or on any IPFS gateway supporting IPNS (see below). Buckets and IPFS \u00b6 Data in a Bucket is stored as IPLD and pinned on IPFS. You can use the underlying content addresses to pin new Bucket content on additional pinning services such as Pinata or Infura . This can be useful if you want additinal replication of your content on the IPFS network. Buckets and IPNS \u00b6 Every Bucket you create has a unique ID associated with it. The Bucket ID is an IPNS address that you can also use to fetch the latest Bucket content from any IPFS peer or view it over IPFS gateways that support the IPNS protocol. More resources \u00b6 Textile Hub CLI Read the full CLI documentation. Textile JavaScript SDK Persist Buckets on IPFS from your JavaScript app. GitHub Action for Buckets Push and updates from your GitHub repos.","title":"Buckets"},{"location":"hub/buckets/#buckets","text":"","title":"Buckets"},{"location":"hub/buckets/#getting-started","text":"If you've used cloud storage before, you'll find Buckets easy to understand. Unlike traditional cloud services, Buckets are built on open, decentralized protocols including the IPFS and Libp2p. You can serve websites, data, and apps from Buckets. Buckets are packed with useful features, including: Explore your Buckets on the Hub gateway . Render web content in your Bucket on a persistent website . Automatically distribute your updates on IPFS using IPNS . Collaboratively manage Buckets as an organization . Create private Buckets where your app users can store data .","title":"Getting Started"},{"location":"hub/buckets/#initialize-a-bucket","text":"When working on your local machine, Buckets are mapped to working directories. Once you initialize a Bucket in a directory, anytime you return to the directory, the Textile CLI will automatically detect the Bucket you are interacting with. To start a Bucket in your current working directory, you must first initialize the Bucket. You can initialize a bucket with an existing UnixFS DAG available in the IPFS network, or import it interactively in an already existing bucket. Read CLI docs for Buckets . Info Bucket names are unique to a developer and within an Org. They are not globally unique.** Warning Be careful creating a bucket in a root directory, because all children directories will linked to that bucket. To move or remove a bucket's link to a directory, edit, move or delete the .textile/config.yml file (it will be a hidden folder in the bucket's directory)","title":"Initialize a Bucket"},{"location":"hub/buckets/#shared-buckets","text":"You can create Buckets to share with all members of an organization. To do so, simply initialize an Org first and then initialize a Bucket using the --org flag, specifying the name of the Org you want to share the bucket with. For example hub bucket init --org nasa . All members of the Org will be able to push and pull files to and from the shared Bucket. Read more about creating Orgs . Info to check which org a bucket is registered with, examine the .textile/config.yml file (it will be a hidden folder in the bucket's directory)","title":"Shared Buckets"},{"location":"hub/buckets/#publishing-content","text":"","title":"Publishing content"},{"location":"hub/buckets/#push-new-files","text":"View the Bucket push CLI docs . hub bucket push site/ .","title":"Push new files"},{"location":"hub/buckets/#retrieving-content","text":"","title":"Retrieving content"},{"location":"hub/buckets/#pull-files","text":"hub bucket init --existing Info By using the --existing flag, you can list Buckets already pushed by you or, when using --org , your collaborators.","title":"Pull files"},{"location":"hub/buckets/#explore-on-the-gateway","text":"To inspect your pushed files, exlore on the gateway: hub bucket links then open the first result 'Thread links' in your browser. The Hub gateway gives you a static URL where you can explore, download, and share your latest Bucket content.","title":"Explore on the gateway"},{"location":"hub/buckets/#render-on-a-website","text":"If your Bucket contains web content, the Bucket website endpoint will provide you a static URL that will always render the latest content from your Bucket. See HTTP Domains .","title":"Render on a website"},{"location":"hub/buckets/#render-on-ipfs-gateways","text":"Buckets are dynamic folders distributed over IPFS using ThreadDB. Each time you create a new Bucket, you will receive a new IPNS Address that you can use on the IPFS address to fetch the latest Bucket content. The IPNS address will not change, but the content will update each time you push changes to your Bucket. Each time you update your Bucket, you will receive a new IPFS address to fetch that version of your Bucket content.","title":"Render on IPFS gateways"},{"location":"hub/buckets/#http-domain","text":"All public Buckets are automatically provided a subdomain on textile.space that will reflect the latest changes in to your Bucket. Your Bucket's IPNS address is used as the subdomain, such that your Bucket URL will always be: <ipns-address>.textile.space . This is designed to further enhance the interoperability of protocols using Textile Buckets.","title":"HTTP Domain"},{"location":"hub/buckets/#ipns-address","text":"Each Bucket has a unique IPNS address that will allow you to render or fetch your Bucket on any IPFS peer or gateway that supports IPNS (including ipfs.io and Cloudflare ). Buckets can't change the speed of IPNS propagation through the network, but we recommend you explore and try for yourself. The Hub gateway will always render the latest data right away.","title":"IPNS Address"},{"location":"hub/buckets/#bucket-automation-cicd","text":"Buckets are an ideal tool for persisting your website, source code, or documentation on IPFS using continuous integration. Tools like Travis CI, CircleCI, and GitHub Actions all make it possible to do very easily. We have provided a configurable GitHub Action that allows you to: Push or update your Bucket based on pull requests, commits, and merges. Generate IPNS, IPFS, and HTTP addresses for every Bucket creation or update. Create temporary Buckets for staging or review that can be removed automatically when content is merged or pull requests are closed. Example output from Textile Bucket GitHub Action","title":"Bucket Automation (CI/CD)"},{"location":"hub/buckets/#learn-more","text":"","title":"Learn more"},{"location":"hub/buckets/#bucket-permissions","text":"","title":"Bucket Permissions"},{"location":"hub/buckets/#developer-buckets","text":"All Buckets you create are scoped to your developer account. You can always find your currently logged in account with hub whoami .","title":"Developer Buckets"},{"location":"hub/buckets/#organization-buckets","text":"Any Buckets you create using the --org flag will also be shared with Org members. Here are the steps to create an Org, create a new Bucket in the Org, and invite a collaborator to the Org:","title":"Organization Buckets"},{"location":"hub/buckets/#create-a-new-org","text":"hub org create Choose an Org name: nasa\u2588 > The name of your account on Textile will be nasa > Your URL will be http://hub.textile.io/nasa Please confirm: y\u2588 > Success! Created new org nasa with URL http://hub.textile.io/nasa You have now created the nasa Org.","title":"Create a new Org"},{"location":"hub/buckets/#create-a-new-bucket-shared-with-an-org","text":"mkdir launchpad cd launchpad hub bucket init --org nasa You have now created a new Bucket inside of the launchpad directory and owned by your nasa organization.","title":"Create a new Bucket shared with an Org"},{"location":"hub/buckets/#invite-a-collaborator","text":"hub org invite The final step is to invite collaborators to your Org. Once they accept the invite, they will be able to interact with Buckets associated with the Org.","title":"Invite a collaborator"},{"location":"hub/buckets/#app-user-buckets","text":"If you are building an app using one of our developer libraries you can use Buckets from inside your apps. Apps generally will create Buckets on behalf of each user, meaning the user should retain control of the Bucket metadata and contents.","title":"App user Buckets"},{"location":"hub/buckets/#bucket-protocols","text":"Buckets are designed to be interoperable across protocols and services. Here are a few examples.","title":"Bucket Protocols"},{"location":"hub/buckets/#buckets-and-threads","text":"Buckets are built on ThreadDB . In fact, in their most basic form, Buckets are just a document in a Thread that is updated each time the directory of data is updated. Since Buckets run on Threads, it opens the door to many new integrations that can be built on Buckets!","title":"Buckets and Threads"},{"location":"hub/buckets/#buckets-and-http","text":"Buckets can be rendered over HTTP through either the Hub Gateway , the Bucket subdomains , or on any IPFS gateway supporting IPNS (see below).","title":"Buckets and HTTP"},{"location":"hub/buckets/#buckets-and-ipfs","text":"Data in a Bucket is stored as IPLD and pinned on IPFS. You can use the underlying content addresses to pin new Bucket content on additional pinning services such as Pinata or Infura . This can be useful if you want additinal replication of your content on the IPFS network.","title":"Buckets and IPFS"},{"location":"hub/buckets/#buckets-and-ipns","text":"Every Bucket you create has a unique ID associated with it. The Bucket ID is an IPNS address that you can also use to fetch the latest Bucket content from any IPFS peer or view it over IPFS gateways that support the IPNS protocol.","title":"Buckets and IPNS"},{"location":"hub/buckets/#more-resources","text":"","title":"More resources"},{"location":"hub/cli/hub/","text":"hub \u00b6 The Hub Client. Options \u00b6 --api string API target (default \"api.textile.io:443\") -h, --help help for hub -s, --session string User session token SEE ALSO \u00b6 hub buck - Manage an object storage bucket hub destroy - Destroy your account hub init - Initialize account hub keys - API key management hub login - Login hub logout - Logout hub orgs - Org management hub threads - Thread management hub whoami - Show current user","title":"CLI Docs"},{"location":"hub/cli/hub/#hub","text":"The Hub Client.","title":"hub"},{"location":"hub/cli/hub/#options","text":"--api string API target (default \"api.textile.io:443\") -h, --help help for hub -s, --session string User session token","title":"Options"},{"location":"hub/cli/hub/#see-also","text":"hub buck - Manage an object storage bucket hub destroy - Destroy your account hub init - Initialize account hub keys - API key management hub login - Login hub logout - Logout hub orgs - Org management hub threads - Thread management hub whoami - Show current user","title":"SEE ALSO"},{"location":"hub/cli/hub_buck/","text":"hub buck \u00b6 Manages files and folders in an object storage bucket. Options \u00b6 -h, --help help for buck SEE ALSO \u00b6 hub - Hub Client hub buck archive - Create a Filecoin archive hub buck cat - Cat bucket objects at path hub buck destroy - Destroy bucket and all objects hub buck init - Initialize a new or existing bucket hub buck links - Show links to where this bucket can be accessed hub buck ls - List top-level or nested bucket objects hub buck pull - Pull bucket object changes hub buck push - Push bucket object changes hub buck root - Show local bucket root CID hub buck status - Show bucket object changes","title":"Bucket"},{"location":"hub/cli/hub_buck/#hub-buck","text":"Manages files and folders in an object storage bucket.","title":"hub buck"},{"location":"hub/cli/hub_buck/#options","text":"-h, --help help for buck","title":"Options"},{"location":"hub/cli/hub_buck/#see-also","text":"hub - Hub Client hub buck archive - Create a Filecoin archive hub buck cat - Cat bucket objects at path hub buck destroy - Destroy bucket and all objects hub buck init - Initialize a new or existing bucket hub buck links - Show links to where this bucket can be accessed hub buck ls - List top-level or nested bucket objects hub buck pull - Pull bucket object changes hub buck push - Push bucket object changes hub buck root - Show local bucket root CID hub buck status - Show bucket object changes","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_archive/","text":"hub buck archive \u00b6 Creates a Filecoin archive from the remote bucket root. hub buck archive [flags] Options \u00b6 -h, --help help for archive SEE ALSO \u00b6 hub buck - Manage an object storage bucket hub buck archive info - Show info about the current archive hub buck archive status - Show status of the latest archive","title":"hub buck archive"},{"location":"hub/cli/hub_buck_archive/#hub-buck-archive","text":"Creates a Filecoin archive from the remote bucket root. hub buck archive [flags]","title":"hub buck archive"},{"location":"hub/cli/hub_buck_archive/#options","text":"-h, --help help for archive","title":"Options"},{"location":"hub/cli/hub_buck_archive/#see-also","text":"hub buck - Manage an object storage bucket hub buck archive info - Show info about the current archive hub buck archive status - Show status of the latest archive","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_archive_info/","text":"hub buck archive info \u00b6 Shows information about the current archive. hub buck archive info [flags] Options \u00b6 -h, --help help for info SEE ALSO \u00b6 hub buck archive - Create a Filecoin archive","title":"hub buck archive info"},{"location":"hub/cli/hub_buck_archive_info/#hub-buck-archive-info","text":"Shows information about the current archive. hub buck archive info [flags]","title":"hub buck archive info"},{"location":"hub/cli/hub_buck_archive_info/#options","text":"-h, --help help for info","title":"Options"},{"location":"hub/cli/hub_buck_archive_info/#see-also","text":"hub buck archive - Create a Filecoin archive","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_archive_status/","text":"hub buck archive status \u00b6 Shows the status of the most recent bucket archive. hub buck archive status [flags] Options \u00b6 -h, --help help for status -w, --watch Watch execution log SEE ALSO \u00b6 hub buck archive - Create a Filecoin archive","title":"hub buck archive status"},{"location":"hub/cli/hub_buck_archive_status/#hub-buck-archive-status","text":"Shows the status of the most recent bucket archive. hub buck archive status [flags]","title":"hub buck archive status"},{"location":"hub/cli/hub_buck_archive_status/#options","text":"-h, --help help for status -w, --watch Watch execution log","title":"Options"},{"location":"hub/cli/hub_buck_archive_status/#see-also","text":"hub buck archive - Create a Filecoin archive","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_cat/","text":"hub buck cat \u00b6 Cats bucket objects at path. hub buck cat [path] [flags] Options \u00b6 -h, --help help for cat SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"hub buck cat"},{"location":"hub/cli/hub_buck_cat/#hub-buck-cat","text":"Cats bucket objects at path. hub buck cat [path] [flags]","title":"hub buck cat"},{"location":"hub/cli/hub_buck_cat/#options","text":"-h, --help help for cat","title":"Options"},{"location":"hub/cli/hub_buck_cat/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_destroy/","text":"hub buck destroy \u00b6 Destroys the bucket and all objects. hub buck destroy [flags] Options \u00b6 -h, --help help for destroy SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"hub buck destroy"},{"location":"hub/cli/hub_buck_destroy/#hub-buck-destroy","text":"Destroys the bucket and all objects. hub buck destroy [flags]","title":"hub buck destroy"},{"location":"hub/cli/hub_buck_destroy/#options","text":"-h, --help help for destroy","title":"Options"},{"location":"hub/cli/hub_buck_destroy/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_init/","text":"hub buck init \u00b6 Initializes a new or existing bucket. A .textile config directory and a seed file will be created in the current working directory. Existing configs will not be overwritten. Use the '--existing' flag to initialize from an existing remote bucket. Use the '--cid' flag to initialize from an existing UnixFS DAG. hub buck init [flags] Options \u00b6 --cid string Bootstrap the bucket with a UnixFS Cid available in the IPFS network -e, --existing Initializes from an existing remote bucket if true -h, --help help for init --key string Bucket key --org string Org username --public Allow public access --thread string Thread ID SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"hub buck init"},{"location":"hub/cli/hub_buck_init/#hub-buck-init","text":"Initializes a new or existing bucket. A .textile config directory and a seed file will be created in the current working directory. Existing configs will not be overwritten. Use the '--existing' flag to initialize from an existing remote bucket. Use the '--cid' flag to initialize from an existing UnixFS DAG. hub buck init [flags]","title":"hub buck init"},{"location":"hub/cli/hub_buck_init/#options","text":"--cid string Bootstrap the bucket with a UnixFS Cid available in the IPFS network -e, --existing Initializes from an existing remote bucket if true -h, --help help for init --key string Bucket key --org string Org username --public Allow public access --thread string Thread ID","title":"Options"},{"location":"hub/cli/hub_buck_init/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_links/","text":"hub buck links \u00b6 Displays a thread, IPNS, and website link to this bucket. hub buck links [flags] Options \u00b6 -h, --help help for links SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"hub buck links"},{"location":"hub/cli/hub_buck_links/#hub-buck-links","text":"Displays a thread, IPNS, and website link to this bucket. hub buck links [flags]","title":"hub buck links"},{"location":"hub/cli/hub_buck_links/#options","text":"-h, --help help for links","title":"Options"},{"location":"hub/cli/hub_buck_links/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_ls/","text":"hub buck ls \u00b6 Lists top-level or nested bucket objects. hub buck ls [path] [flags] Options \u00b6 -h, --help help for ls SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"hub buck ls"},{"location":"hub/cli/hub_buck_ls/#hub-buck-ls","text":"Lists top-level or nested bucket objects. hub buck ls [path] [flags]","title":"hub buck ls"},{"location":"hub/cli/hub_buck_ls/#options","text":"-h, --help help for ls","title":"Options"},{"location":"hub/cli/hub_buck_ls/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_pull/","text":"hub buck pull \u00b6 Pulls paths that have been added to and paths that have been removed or differ from the remote bucket root. hub buck pull [flags] Options \u00b6 -f, --force Force pull all remote files if true --hard Pulls and prunes local changes if true -h, --help help for pull -y, --yes Skips the confirmation prompt if true SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"hub buck pull"},{"location":"hub/cli/hub_buck_pull/#hub-buck-pull","text":"Pulls paths that have been added to and paths that have been removed or differ from the remote bucket root. hub buck pull [flags]","title":"hub buck pull"},{"location":"hub/cli/hub_buck_pull/#options","text":"-f, --force Force pull all remote files if true --hard Pulls and prunes local changes if true -h, --help help for pull -y, --yes Skips the confirmation prompt if true","title":"Options"},{"location":"hub/cli/hub_buck_pull/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_push/","text":"hub buck push \u00b6 Pushes paths that have been added to and paths that have been removed or differ from the local bucket root. hub buck push [flags] Options \u00b6 -f, --force Allows non-fast-forward updates if true -h, --help help for push -y, --yes Skips the confirmation prompt if true SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"hub buck push"},{"location":"hub/cli/hub_buck_push/#hub-buck-push","text":"Pushes paths that have been added to and paths that have been removed or differ from the local bucket root. hub buck push [flags]","title":"hub buck push"},{"location":"hub/cli/hub_buck_push/#options","text":"-f, --force Allows non-fast-forward updates if true -h, --help help for push -y, --yes Skips the confirmation prompt if true","title":"Options"},{"location":"hub/cli/hub_buck_push/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_root/","text":"hub buck root \u00b6 Shows the local bucket root CID hub buck root [flags] Options \u00b6 -h, --help help for root SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"hub buck root"},{"location":"hub/cli/hub_buck_root/#hub-buck-root","text":"Shows the local bucket root CID hub buck root [flags]","title":"hub buck root"},{"location":"hub/cli/hub_buck_root/#options","text":"-h, --help help for root","title":"Options"},{"location":"hub/cli/hub_buck_root/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_status/","text":"hub buck status \u00b6 Displays paths that have been added to and paths that have been removed or differ from the local bucket root. hub buck status [flags] Options \u00b6 -h, --help help for status SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"hub buck status"},{"location":"hub/cli/hub_buck_status/#hub-buck-status","text":"Displays paths that have been added to and paths that have been removed or differ from the local bucket root. hub buck status [flags]","title":"hub buck status"},{"location":"hub/cli/hub_buck_status/#options","text":"-h, --help help for status","title":"Options"},{"location":"hub/cli/hub_buck_status/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_destroy/","text":"hub destroy \u00b6 Destroys your Hub account and all associated data. hub destroy [flags] Options \u00b6 -h, --help help for destroy SEE ALSO \u00b6 hub - Hub Client","title":"hub destroy"},{"location":"hub/cli/hub_destroy/#hub-destroy","text":"Destroys your Hub account and all associated data. hub destroy [flags]","title":"hub destroy"},{"location":"hub/cli/hub_destroy/#options","text":"-h, --help help for destroy","title":"Options"},{"location":"hub/cli/hub_destroy/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"hub/cli/hub_init/","text":"hub init \u00b6 Initializes a new Hub account. hub init [flags] Options \u00b6 -h, --help help for init SEE ALSO \u00b6 hub - Hub Client","title":"hub init"},{"location":"hub/cli/hub_init/#hub-init","text":"Initializes a new Hub account. hub init [flags]","title":"hub init"},{"location":"hub/cli/hub_init/#options","text":"-h, --help help for init","title":"Options"},{"location":"hub/cli/hub_init/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"hub/cli/hub_keys/","text":"hub keys \u00b6 Manages your API keys. Options \u00b6 -h, --help help for keys --org string Org username SEE ALSO \u00b6 hub - Hub Client hub keys create - Create an API key and secret hub keys invalidate - Invalidate an API key hub keys ls - List your API keys","title":"API Keys"},{"location":"hub/cli/hub_keys/#hub-keys","text":"Manages your API keys.","title":"hub keys"},{"location":"hub/cli/hub_keys/#options","text":"-h, --help help for keys --org string Org username","title":"Options"},{"location":"hub/cli/hub_keys/#see-also","text":"hub - Hub Client hub keys create - Create an API key and secret hub keys invalidate - Invalidate an API key hub keys ls - List your API keys","title":"SEE ALSO"},{"location":"hub/cli/hub_keys_create/","text":"hub keys create \u00b6 Creates a new API key and secret. Keys are used by apps and services that leverage buckets or threads. Using the '--org' flag will create a new key under the Organization's account. There are two types of API keys: 1. 'Account' keys provide direct access to developer/org account buckets and threads. 2. 'User Group' keys provide existing non-admin identities (e.g. app users) access to their own buckets and threads, using the resources of the parent account (i.e. the developer or organization). API secrets should be kept safely on a backend server, not in publicly readable client code. hub keys create [flags] Options \u00b6 -h, --help help for create SEE ALSO \u00b6 hub keys - API key management","title":"hub keys create"},{"location":"hub/cli/hub_keys_create/#hub-keys-create","text":"Creates a new API key and secret. Keys are used by apps and services that leverage buckets or threads. Using the '--org' flag will create a new key under the Organization's account. There are two types of API keys: 1. 'Account' keys provide direct access to developer/org account buckets and threads. 2. 'User Group' keys provide existing non-admin identities (e.g. app users) access to their own buckets and threads, using the resources of the parent account (i.e. the developer or organization). API secrets should be kept safely on a backend server, not in publicly readable client code. hub keys create [flags]","title":"hub keys create"},{"location":"hub/cli/hub_keys_create/#options","text":"-h, --help help for create","title":"Options"},{"location":"hub/cli/hub_keys_create/#see-also","text":"hub keys - API key management","title":"SEE ALSO"},{"location":"hub/cli/hub_keys_invalidate/","text":"hub keys invalidate \u00b6 Invalidates an API key. Invalidated keys cannot be used to create new threads. hub keys invalidate [flags] Options \u00b6 -h, --help help for invalidate SEE ALSO \u00b6 hub keys - API key management","title":"hub keys invalidate"},{"location":"hub/cli/hub_keys_invalidate/#hub-keys-invalidate","text":"Invalidates an API key. Invalidated keys cannot be used to create new threads. hub keys invalidate [flags]","title":"hub keys invalidate"},{"location":"hub/cli/hub_keys_invalidate/#options","text":"-h, --help help for invalidate","title":"Options"},{"location":"hub/cli/hub_keys_invalidate/#see-also","text":"hub keys - API key management","title":"SEE ALSO"},{"location":"hub/cli/hub_keys_ls/","text":"hub keys ls \u00b6 Lists all of your API keys. hub keys ls [flags] Options \u00b6 -h, --help help for ls SEE ALSO \u00b6 hub keys - API key management","title":"hub keys ls"},{"location":"hub/cli/hub_keys_ls/#hub-keys-ls","text":"Lists all of your API keys. hub keys ls [flags]","title":"hub keys ls"},{"location":"hub/cli/hub_keys_ls/#options","text":"-h, --help help for ls","title":"Options"},{"location":"hub/cli/hub_keys_ls/#see-also","text":"hub keys - API key management","title":"SEE ALSO"},{"location":"hub/cli/hub_login/","text":"hub login \u00b6 Handles login to a Hub account. hub login [flags] Options \u00b6 -h, --help help for login SEE ALSO \u00b6 hub - Hub Client","title":"Login"},{"location":"hub/cli/hub_login/#hub-login","text":"Handles login to a Hub account. hub login [flags]","title":"hub login"},{"location":"hub/cli/hub_login/#options","text":"-h, --help help for login","title":"Options"},{"location":"hub/cli/hub_login/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"hub/cli/hub_logout/","text":"hub logout \u00b6 Handles logout of a Hub account. hub logout [flags] Options \u00b6 -h, --help help for logout SEE ALSO \u00b6 hub - Hub Client","title":"Logout"},{"location":"hub/cli/hub_logout/#hub-logout","text":"Handles logout of a Hub account. hub logout [flags]","title":"hub logout"},{"location":"hub/cli/hub_logout/#options","text":"-h, --help help for logout","title":"Options"},{"location":"hub/cli/hub_logout/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs/","text":"hub orgs \u00b6 Manages your organizations. Options \u00b6 -h, --help help for orgs SEE ALSO \u00b6 hub - Hub Client hub orgs create - Create an org hub orgs destroy - Destroy an org hub orgs invite - Invite members to an org hub orgs leave - Leave an org hub orgs ls - List orgs you're a member of hub orgs members - List org members","title":"Orgs"},{"location":"hub/cli/hub_orgs/#hub-orgs","text":"Manages your organizations.","title":"hub orgs"},{"location":"hub/cli/hub_orgs/#options","text":"-h, --help help for orgs","title":"Options"},{"location":"hub/cli/hub_orgs/#see-also","text":"hub - Hub Client hub orgs create - Create an org hub orgs destroy - Destroy an org hub orgs invite - Invite members to an org hub orgs leave - Leave an org hub orgs ls - List orgs you're a member of hub orgs members - List org members","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_create/","text":"hub orgs create \u00b6 Creates a new organization. hub orgs create [flags] Options \u00b6 -h, --help help for create SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs create"},{"location":"hub/cli/hub_orgs_create/#hub-orgs-create","text":"Creates a new organization. hub orgs create [flags]","title":"hub orgs create"},{"location":"hub/cli/hub_orgs_create/#options","text":"-h, --help help for create","title":"Options"},{"location":"hub/cli/hub_orgs_create/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_destroy/","text":"hub orgs destroy \u00b6 Destroys an organization and all associated data. You must be the org owner. hub orgs destroy [flags] Options \u00b6 -h, --help help for destroy SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs destroy"},{"location":"hub/cli/hub_orgs_destroy/#hub-orgs-destroy","text":"Destroys an organization and all associated data. You must be the org owner. hub orgs destroy [flags]","title":"hub orgs destroy"},{"location":"hub/cli/hub_orgs_destroy/#options","text":"-h, --help help for destroy","title":"Options"},{"location":"hub/cli/hub_orgs_destroy/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_invite/","text":"hub orgs invite \u00b6 Invites a new member to an organization. hub orgs invite [flags] Options \u00b6 -h, --help help for invite SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs invite"},{"location":"hub/cli/hub_orgs_invite/#hub-orgs-invite","text":"Invites a new member to an organization. hub orgs invite [flags]","title":"hub orgs invite"},{"location":"hub/cli/hub_orgs_invite/#options","text":"-h, --help help for invite","title":"Options"},{"location":"hub/cli/hub_orgs_invite/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_leave/","text":"hub orgs leave \u00b6 Leaves an organization. hub orgs leave [flags] Options \u00b6 -h, --help help for leave SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs leave"},{"location":"hub/cli/hub_orgs_leave/#hub-orgs-leave","text":"Leaves an organization. hub orgs leave [flags]","title":"hub orgs leave"},{"location":"hub/cli/hub_orgs_leave/#options","text":"-h, --help help for leave","title":"Options"},{"location":"hub/cli/hub_orgs_leave/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_ls/","text":"hub orgs ls \u00b6 Lists all the organizations that you're a member of. hub orgs ls [flags] Options \u00b6 -h, --help help for ls SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs ls"},{"location":"hub/cli/hub_orgs_ls/#hub-orgs-ls","text":"Lists all the organizations that you're a member of. hub orgs ls [flags]","title":"hub orgs ls"},{"location":"hub/cli/hub_orgs_ls/#options","text":"-h, --help help for ls","title":"Options"},{"location":"hub/cli/hub_orgs_ls/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_members/","text":"hub orgs members \u00b6 Lists current organization members. hub orgs members [flags] Options \u00b6 -h, --help help for members SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs members"},{"location":"hub/cli/hub_orgs_members/#hub-orgs-members","text":"Lists current organization members. hub orgs members [flags]","title":"hub orgs members"},{"location":"hub/cli/hub_orgs_members/#options","text":"-h, --help help for members","title":"Options"},{"location":"hub/cli/hub_orgs_members/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_threads/","text":"hub threads \u00b6 Manages your threads. Options \u00b6 -h, --help help for threads --org string Org username SEE ALSO \u00b6 hub - Hub Client hub threads ls - List your threads","title":"Threads"},{"location":"hub/cli/hub_threads/#hub-threads","text":"Manages your threads.","title":"hub threads"},{"location":"hub/cli/hub_threads/#options","text":"-h, --help help for threads --org string Org username","title":"Options"},{"location":"hub/cli/hub_threads/#see-also","text":"hub - Hub Client hub threads ls - List your threads","title":"SEE ALSO"},{"location":"hub/cli/hub_threads_ls/","text":"hub threads ls \u00b6 Lists all of your threads. hub threads ls [flags] Options \u00b6 -h, --help help for ls SEE ALSO \u00b6 hub threads - Thread management","title":"hub threads ls"},{"location":"hub/cli/hub_threads_ls/#hub-threads-ls","text":"Lists all of your threads. hub threads ls [flags]","title":"hub threads ls"},{"location":"hub/cli/hub_threads_ls/#options","text":"-h, --help help for ls","title":"Options"},{"location":"hub/cli/hub_threads_ls/#see-also","text":"hub threads - Thread management","title":"SEE ALSO"},{"location":"hub/cli/hub_whoami/","text":"hub whoami \u00b6 Shows the user for the current session. hub whoami [flags] Options \u00b6 -h, --help help for whoami SEE ALSO \u00b6 hub - Hub Client","title":"Whoami"},{"location":"hub/cli/hub_whoami/#hub-whoami","text":"Shows the user for the current session. hub whoami [flags]","title":"hub whoami"},{"location":"hub/cli/hub_whoami/#options","text":"-h, --help help for whoami","title":"Options"},{"location":"hub/cli/hub_whoami/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"policies/code-of-conduct/","text":"Our Pledge \u00b6 In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards \u00b6 Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities \u00b6 Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope \u00b6 This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement \u00b6 Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at contact@textile.io . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution \u00b6 This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/\u00bc","title":"Code of conduct"},{"location":"policies/code-of-conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"policies/code-of-conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"policies/code-of-conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"policies/code-of-conduct/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"policies/code-of-conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at contact@textile.io . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"policies/code-of-conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/\u00bc","title":"Attribution"},{"location":"policies/license/","text":"Unless otherwise explicitly stated, all Textile code and software products are licensed under the following license: MIT License \u00b6 Copyright \u00a9 2018, 2019 Textile Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"policies/license/#mit-license","text":"Copyright \u00a9 2018, 2019 Textile Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"},{"location":"policies/privacy/","text":"Textile provides exchange and storage of data. Textile provides remote data storage for users on the IPFS network (see https://ipfs.io/ ). The IPFS protocol has no mechanisms for deletion of data hosted on multiple providers on the network. When a Textile user 'deletes' data, we will remove that data from all servers in the IPFS network run by Textile. Information We Have \u00b6 Certain information (e.g. a user email, public keys, encrypted data content address, decrypted data, etc.) are transmitted to us solely for the purpose of transmitting and storing data. Unless otherwise stated below, this information is only kept as long as necessary to place each call or transmit each message, and is not used for any other purpose. Information we store The identifier you register with. The email contact address of any developer you invite to an organization. Encrypted or decrypted contents of ThreadDB. Encrypted or decrypted contents of Buckets. Transient information IP addresses may be kept for up to 90 days for rate limiting and to prevent abuse. Textile is currently collecting performance metrics and critical issues detected in our software. This data may be kept for up to a year. Information We May Share \u00b6 We do not share your information with companies, organizations, and individuals outside of Textile unless one of the following circumstances applies: With your consent. The data is encrypted and stored on IPFS hosts. When legally required. We will share the information we have with entities outside of Textile if we have a good faith belief that access, use, preservation, or disclosure of the information is necessary to: meet any applicable law, regulation, legal process or enforceable governmental request. enforce applicable Terms of Service, including investigation of potential violations. detect, prevent, or otherwise address fraud, security, or technical issues. protect against harm to the rights, property, or safety of Textile, our users, or the public as required or permitted by law. We will update this privacy policy as needed so that it is current, accurate, and as clear as possible. Please contact us with any questions at contact@textile.io Changelog \u00b6 05.04.20: Finalize TOS for new Textile Hub, Buckets, and ThreadDB services. 05.15.20: Corrected ThreadsDB => ThreadDB","title":"Privacy"},{"location":"policies/privacy/#information-we-have","text":"Certain information (e.g. a user email, public keys, encrypted data content address, decrypted data, etc.) are transmitted to us solely for the purpose of transmitting and storing data. Unless otherwise stated below, this information is only kept as long as necessary to place each call or transmit each message, and is not used for any other purpose. Information we store The identifier you register with. The email contact address of any developer you invite to an organization. Encrypted or decrypted contents of ThreadDB. Encrypted or decrypted contents of Buckets. Transient information IP addresses may be kept for up to 90 days for rate limiting and to prevent abuse. Textile is currently collecting performance metrics and critical issues detected in our software. This data may be kept for up to a year.","title":"Information We Have"},{"location":"policies/privacy/#information-we-may-share","text":"We do not share your information with companies, organizations, and individuals outside of Textile unless one of the following circumstances applies: With your consent. The data is encrypted and stored on IPFS hosts. When legally required. We will share the information we have with entities outside of Textile if we have a good faith belief that access, use, preservation, or disclosure of the information is necessary to: meet any applicable law, regulation, legal process or enforceable governmental request. enforce applicable Terms of Service, including investigation of potential violations. detect, prevent, or otherwise address fraud, security, or technical issues. protect against harm to the rights, property, or safety of Textile, our users, or the public as required or permitted by law. We will update this privacy policy as needed so that it is current, accurate, and as clear as possible. Please contact us with any questions at contact@textile.io","title":"Information We May Share"},{"location":"policies/privacy/#changelog","text":"05.04.20: Finalize TOS for new Textile Hub, Buckets, and ThreadDB services. 05.15.20: Corrected ThreadsDB => ThreadDB","title":"Changelog"},{"location":"policies/terms/","text":"Last updated: 05/04/20 Welcome to Textile. Please read these terms of service (these \u201c Terms \u201d) carefully as they form a contract between you and We Are Set, Inc, a Delaware corporation ( Textile , \u201c we \u201d, \u201c us \u201d, or \u201c our \u201d), that governs your access and use of (i) the web verification and encryption solution software provided by Textile (the \u201c Software \u201d); (ii) the Textile websites at textile.io (the \u201c Site \u201d); and (iii) any written or electronic use or features guides or other documentation provided or made available by Textile (the \u201c User Guides \u201d) (collectively the \u201c Service(s) \u201d). By registering or using any of the Services you agree to be bound by these Terms. If you are using the Services on behalf of an organization, you are agreeing to these Terms for that organization and promising to Textile that you have the authority to bind that organization to these Terms (in which event, \u201cyou\u201d and \u201cyour\u201d will refer to that organization). You may use the Services only in compliance with these Terms and only if you have the power to form a contract with Textile and are not barred under any applicable laws from doing so. IF YOU DO NOT AGREE TO BE BOUND BY THESE TERMS, YOU MUST NOT USE THE SERVICES . BY CLICKING THE CONFIRMATION LINK WHEN YOU OPEN AN ACCOUNT WITH US, YOU ACKNOWLEDGE AND AGREE TO BE BOUND TO THE TERMS. Should you have any questions concerning this Agreement, please contact privacy@textile.io . Please note that Textile does not provide warranties for the Services. This contract also limits our liability to you and contains an arbitration provision and a class action waiver. See Sections 14 (NO WARRANTY), 16 (LIMITATION OF LIABILITY) and 19 (ARBITRATION) of these Terms for details. 1. About this Service \u00b6 The Service offers verification and authentication services and encryption services for users. The Service provides a data storage system (\" Storage \") for developers to maintain remote copies of User Content. Storage is managed on IPFS ( https://www.ipfs.io/ ) nodes running on a user's personal device and replicated on remote IPFS nodes maintained by the Company. If you shared User Content which you no longer want to share publicly or privately using our Services, you must either delete that User Content or your Account. By making such deletion, the relevant User Content will become unlinked from the IPFS network and will be deleted from our IPFS node. You agree to immediately notify Company of any unauthorized use, or suspected unauthorized use of your Account or any other breach of security. Company cannot and will not be liable for any loss or damage arising from your failure to comply with the above requirements. 2. Changes to these Terms \u00b6 We reserve the right to revise these Terms from time to time. We will date and post the most current version of these Terms on the Site. Any changes will be effective upon posting the revised version of these Terms (or such later effective date as may be indicated at the top of the revised Terms). If, in our sole discretion, we deem a revision to these Terms to be material, we will notify you via the Service and/or by email to the email address associated with your account. Notice of other changes may be provided via the Site. Therefore, we encourage you to check the date of these Terms whenever you visit the Site to see if these Terms have been updated. Your continued access or use of any portion of the Service constitutes your acceptance of such changes. If you don\u2019t agree to any of the changes, we\u2019re not obligated to keep providing the Service to you, and you must cancel and stop using the Service. 3. Access to the Service \u00b6 You may use the Service, on a non-exclusive basis, solely in strict compliance with these Terms and all applicable laws. 4. Your Account \u00b6 To obtain access to certain Services, you may be required to obtain an account with Textile (become a \u201c Registered User \u201d). Until you apply for and are approved for an account your access to the Service will be limited to the areas of the Service, if any, that Textile makes available to the general public. When registering with Textile you must: (a) provide true, accurate, current and complete information about yourself as requested by the Service\u2019s registration form (such information being the \u201c Registration Data \u201d); and (b) maintain and promptly update the Registration Data to keep it true, accurate, current and complete. Textile may deny approval or withdraw such approval at any time in its sole discretion, with or without cause. Only you may use your Textile account. You must keep your account and passwords confidential and not authorize any third party to access or use the Service on your behalf, unless we provide an approved mechanism for such use. Textile will not be liable for any loss or damage arising from any unauthorized use of your accounts. CONTENT You represent and warrant that none of the following infringe any intellectual property, publicity or other proprietary rights: your provision of Your Content to us, your causing Your Content to be posted using the Service, and use of any such content (including of works derived from it) by us, other users of the Service, or others in contract with us that is done in connection with the Service and in compliance with these Terms. You acknowledge and agree that we may access or disclose information about you or any other information or data collected, stored or processed on our servers, including Your Content, if required to do so by law or in the good-faith belief that such action is necessary to: (a) comply with any law, regulation, legal process or lawful governmental requests; (b) protect the rights or property of Textile or our customers, including the enforcement of our agreements or policies governing your use of the Service; or \u00a9 act on a good faith belief that such access or disclosure is necessary to protect the personal safety of Textile employees, customers, or the public. We retain the right to block or otherwise prevent delivery of any type of file, email or other communication to or from the Service as part of our efforts to protect the Service, protect our customers, or stop you from breaching these Terms. 6. Consent to Electronic Communications and Solicitation \u00b6 By registering for the Service, you understand that we may send you communications or data regarding the Services, including but not limited to: (a) notices about your use of the Services, including any notices concerning violations of use; (b) updates; and \u00a9 promotional information and materials regarding Textile\u2019s products and services, via electronic mail. We give you the opportunity to opt-out of receiving promotional electronic mail from us by following the opt-out instructions provided in the message. 7. Suspension and Termination of Use of the Service \u00b6 We reserve the right, to temporarily suspend or terminate your access to the Service at any time in our sole discretion, with or without cause, with or without notice, and without incurring liability of any kind. For example, we may suspend or terminate your access to or use of the Service for: (a) the actual or suspected violation of these Terms; (b) the use of the Services in a manner that may cause Textile to have legal liability or disrupt others\u2019 use of the Services; \u00a9 the suspicion or detection of any malicious code, virus or other harmful code by you or in your account; (d) scheduled downtime and recurring downtime; (e) any actual or suspected effort by you to circumvent Textile\u2019s security or encryption; or (f) unplanned technical problems and outages. If, in Textile\u2019s determination, the suspension might be indefinite and/or Textile has elected to terminate your access to the Service, Textile will use commercially reasonable efforts to notify you through the Service and/or by email to the email address associated with your account. You acknowledge that if your access to the Service is suspended or terminated, you may no longer have access to Your Content that is stored with the Service. 8. Acceptable Use \u00b6 You must not use the Service to harm others or the Service. For example, you must not use the Service to harm, threaten, or harass another person, organization, or Textile. You must not: damage, disable, overburden, or impair the Service (or any network connected to the Service); resell or redistribute the Service or any part of it; use any unauthorized means to modify, reroute, or gain access to the Service or attempt to carry out these activities; or use any data mining, robots, or similar data gathering and extraction tools; or use any automated process or Service (such as a bot, a spider, or periodic caching of information stored by Textile) to access or use the Service;. In addition, you promise that you will not and will not encourage or assist any third party to: I. reproduce, modify, alter, tamper with, repair or create derivative works of any Software, unless that permission is granted in a license. Further, unless expressly prohibited under applicable law, you may not use the Service to develop, test, validate and/or improve any service that is a substitute for, or substantially similar to, the Service (including any portion thereof); II. reverse engineer, disassemble or decompile the Software used to provide or access the Service, including the Software, or attempt to discover or recreate the source code used to provide or access the Service, except and only to the extent that that permission is granted in a license or applicable law expressly permits doing so; III. use the Service in any manner or for any purpose other than as expressly permitted by these Terms, the Privacy Policy, any User Guides or any other policy, instruction or terms applicable to the Service that are available on the Service (\u201cPolicies\u201d); IV. sell, lend, rent, resell, lease, sublicense or otherwise transfer any of the rights granted to you with respect to the Services to any third party; V. remove, obscure or alter any proprietary rights notice pertaining to the Service; VI. use the Service in connection with the operation of nuclear facilities, aircraft navigation, communication systems, medical devices, air traffic control devices, real time control systems or other situations in which the failure of the Service could lead to death, personal injury, or physical property or environmental damage; VII. use the Service to: (i) engage in any unlawful or fraudulent activity or perpetrate a hoax or engage in phishing schemes or forgery or other similar falsification or manipulation of data; (ii) send unsolicited or unauthorized junk mail, spam, chain letters, pyramid schemes or any other form of duplicative or unsolicited messages, whether commercial or otherwise; (iii) store or transmit any inappropriate content, such as content: (1) containing unlawful, defamatory, threatening, abusive, libelous or otherwise objectionable material of any kind or nature, (2) containing any material that encourages conduct that could constitute a criminal offense, or (3) in a way that violates or infringes upon the intellectual property rights or the privacy or publicity rights of any person or entity or that may otherwise be unlawful or give rise to civil or criminal liability; (iv) store or transmit any content that contains or is used to initiate a denial of service attack, software viruses or other harmful or deleterious computer code, files or programs such as Trojan horses, worms, time bombs, cancelbots, or spyware; or (v) abuse, harass, stalk or otherwise violate the legal rights of a third party; VIII. interfere with or disrupt servers or networks used by Textile to provide the Service or used by other users\u2019 to access the Service, or violate any third party regulations, policies or procedures of such servers or networks or harass or interfere with another user\u2019s full use and enjoyment of any Software or the Service; IX. access or attempt to access Textile\u2019s other accounts, computer systems or networks not covered by these Terms, through password mining or any other means; X. cause, in Textile\u2019s sole discretion, inordinate burden on the Service or Textile\u2019s system resources or capacity; or XI. share passwords or other access information or devices or otherwise authorize any third party to access or use the Software or the Service. Textile reserves the right, in its sole discretion, to deactivate, change and/or require you to change your Textile user ID and any custom or vanity URLs, custom links, or vanity domains you may obtain through the Services for any reason or for no reason. Textile may exercise such right at any time, with or without prior notice. We will make all judgments concerning the applicability of these guidelines in our sole and exclusive discretion. We reserve the right, in our sole discretion, to determine whether and what action to take in response to each such notification, and any action or inaction in a particular instance will not dictate or limit our response to a future complaint. We will not assume or have any liability for any action or inaction with respect to any Your Content. 9. Updates to the Service \u00b6 Textile reserves the right, in its sole discretion, to make necessary unscheduled deployments of changes, updates or enhancements to the Service at any time. We may add or remove functionalities or features, and we may suspend or stop the Service altogether. 10. Software \u00b6 If you receive Software from us, its use is governed in one of two ways: If you\u2019re presented with license terms that you must accept in order to use the Software, those terms apply; if no license is presented to you, these Terms apply. We reserve all other rights to the Software. We may automatically check your version of the Software. We may also automatically download to your computer or device new versions of the Software. Any Software is licensed, not sold. Unless we notify you otherwise, the Software license ends when your Service ends. You must then promptly uninstall the Software, or we may disable it. You must not work around any technical limitations in the Software. The Software is subject to applicable U.S. export laws and regulations. You must comply with all domestic and international export laws and regulations that apply to the Software. These laws include restrictions on destinations, end users, and end use. Without limitation, you may not transfer the Software or Service without U.S. government permission to anyone on U.S. government exclusion lists (see the Commerce Department\u2019s compliance list at http://www.bis.doc.gov/index.php/policy-guidance/lists-of-parties-of-concern . You represent and warrant that you\u2019re not on any of those lists or under the control of or an agent for anyone on those lists or the entities listed above. 11. Third Party Services and Content \u00b6 All transactions using the Services are between the transacting parties only. The Services may contain features and functionalities linking you or providing you with certain functionality and access to third party content, including Web sites, directories, servers, networks, systems, information and databases, applications, software, programs, products or services, and the Internet as a whole; you acknowledge that we are not responsible for such content or services. We may also provide some content to you as part of the Services. However, Textile is not an agent of any transacting party, nor or we a direct party in any such transaction. Any such activities, and any terms associated with such activities, are solely between you and the applicable third-party. Similarly, we are not responsible for any third party content you access with the Services, and you irrevocably waive any claim against us with respect to such sites and third-party content. Textile shall have no liability, obligation or responsibility for any such correspondence, purchase or promotion between you and any such third-party. You should make whatever investigation you feel necessary or appropriate before proceeding with any online or offline transaction with any of these third parties. You are solely responsible for your dealings with any third party related to the Services, including the delivery of and payment for goods and services. 12. Textile Proprietary Rights \u00b6 As between Textile and you, Textile or its licensors own and reserve all right, title and interest in and to the Service and all hardware, software and other items used to provide the Service, other than the rights explicitly granted to you to use the Service in accordance with this Terms. No title to or ownership of any proprietary rights related to the Service is transferred to you pursuant to these Terms. All rights not explicitly granted to you are reserved by Textile. In the event that you provide comments, suggestions and recommendations to Textile with respect to the Service (including, without limitation, with respect to modifications, enhancements, improvements and other changes to the Service) (collectively, \u201cFeedback\u201d), you hereby grant to Textile a world-wide, royalty free, irrevocable, perpetual license to use and otherwise incorporate any Feedback in connection with the Service. 13. Privacy \u00b6 In order to operate and provide the Service, we collect certain information about you. We use that information as described in the privacy policy located at https://docs.textile.io/policies/privacy (\u201c Privacy Policy \u201d). 14. No Warranty \u00b6 TEXTILE PROVIDES THE SERVICE \u201cAS IS\u201d, \u201cWITH ALL FAULTS\u201d AND \u201cAS AVAILABLE\u201d. TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, TEXTILE MAKES NO (AND SPECIFICALLY DISCLAIMS ALL) REPRESENTATIONS OR WARRANTIES OF ANY KIND, WHETHER EXPRESS, IMPLIED, STATUTORY OR OTHERWISE, INCLUDING, WITHOUT LIMITATION, ANY WARRANTY THAT THE SERVICE WILL BE UNINTERRUPTED, ERROR-FREE OR FREE OF HARMFUL COMPONENTS, THAT YOUR CONTENT WILL BE SECURE OR NOT OTHERWISE LOST OR DAMAGED, OR ANY IMPLIED WARRANTY OF MERCHANTABILITY, SATISFACTORY QUALITY, FITNESS FOR A PARTICULAR PURPOSE, OR NON-INFRINGEMENT, AND ANY WARRANTY ARISING OUT OF ANY COURSE OF PERFORMANCE, COURSE OF DEALING OR USAGE OF TRADE. SOME JURISDICTIONS DO NOT ALLOW THE FOREGOING EXCLUSIONS. IN SUCH AN EVENT SUCH EXCLUSION WILL NOT APPLY SOLELY TO THE EXTENT PROHIBITED BY APPLICABLE LAW. You hereby acknowledge and agree that this disclaimer of warranties is a fundamental part of the agreement between you and Textile contained in these Terms and that Textile would not agree to enter these Terms or allow you access or use the Service without such disclaimers. 15. Indemnification \u00b6 You will defend Textile against any cost, loss, damage, or other liability arising from any third party demand or claim that any Your Content, or your use of the Service, in breach of these Terms: (a) infringes a registered patent, registered trademark, or copyright of a third party, or misappropriates a trade secret (to the extent that such misappropriation is not the result of Textile\u2019s actions); or (b) violates applicable law or these Terms. Textile will reasonably notify you of any such claim or demand that is subject to your indemnification obligation. 16. Limitation of Liability \u00b6 TO THE FULLEST EXTENT PERMITTED BY LAW, IN NO EVENT WILL TEXTILE, ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE FOR: ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, PUNITIVE, COVER OR CONSEQUENTIAL DAMAGES, OR DAMAGES FOR LOST PROFITS, REVENUE, GOODWILL, USE OR CONTENT, HOWEVER CAUSED, UNDER ANY THEORY OF LIABILITY, INCLUDING, WITHOUT LIMITATION, CONTRACT, TORT, WARRANTY, NEGLIGENCE OR OTHERWISE, EVEN IF TEXTILE HAS BEEN ADVISED AS TO THE POSSIBILITY OF SUCH DAMAGES. TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, THE AGGREGATE LIABILITY OF TEXTILE AND ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS, RELATING TO THE SERVICES WILL BE LIMITED TO FIFTY DOLLARS ($50.00). THE LIMITATIONS AND EXCLUSIONS ALSO APPLY IF THIS REMEDY DOES NOT FULLY COMPENSATE YOU FOR ANY LOSSES OR FAILS OF ITS ESSENTIAL PURPOSE. SOME JURISDICTIONS DO NOT ALLOW THE LIMITATION OF INCIDENTAL, CONSEQUENTIAL OR OTHER DAMAGES. IN SUCH AN EVENT THIS LIMITATION WILL NOT APPLY TO YOU TO THE EXTENT PROHIBITED BY LAW. You acknowledge that the foregoing limitations are an essential element of the agreement between you and Textile and that in the absence of such limitations the terms and conditions set forth in these Terms would be substantially different. 17. Arbitration; Class Action Waiver \u00b6 17.1 Introduction Introduction. This Section 17 includes an arbitration agreement and an agreement that all claims will be brought only in an individual capacity (and not as a class action or other representative proceeding). Please read it carefully. You may opt out of the arbitration agreement by following the opt out procedure described below. 17.2 Process Informal Process First You agree that in the event of any dispute between you and Textile, you will first contact Textile and make a good faith sustained effort to resolve the dispute before resorting to more formal means of resolution, including without limitation any court action. 17.3 Arbitration Agreement After the informal dispute resolution process any remaining dispute, controversy, or claim (collectively, \u201cClaim\u201d) relating in any way to your use of Textile\u2019s services and/or products, including the Service, or relating in any way to the communications between you and Textile or any other user of the Service, will be finally resolved by binding arbitration. This mandatory arbitration agreement applies equally to you and Textile. However, this arbitration agreement does not (a) govern any Claim by Textile for infringement of its intellectual property or access to the Service that is unauthorized or exceeds authorization granted in these Terms or (b) bar you from making use of applicable small claims court procedures in appropriate cases. If you are an individual you may opt out of this arbitration agreement within thirty (30) days of the first date you access or use this Service by following the procedure described below. Arbitration is more informal than a lawsuit in court. There is no judge or jury in arbitration. Instead, the dispute is resolve by a neutral arbitrator. Court review of an arbitration award is limited. Except to the extent the parties agree otherwise, arbitrators can award the same damages and relief that a court can award. You agree that the U.S. Federal Arbitration Act governs the interpretation and enforcement of this provision, and that you and Textile are each waiving the right to a trial by jury or to participate in a class action. This arbitration provision will survive any termination of these Terms. If you wish to begin an arbitration proceeding, after following the informal dispute resolution procedure, you must send a letter requesting arbitration and describing your claim to Textile, Inc., Attn: President, 85 Broad St., 18 th Floor - NY, NY 10004. The arbitration will be administered by the American Arbitration Association (AAA) under its rules including, if you are an individual, the AAA's Supplementary Procedures for Consumer-Related Disputes. If you are not an individual or have used the Services on behalf of an entity, the AAA's Supplementary Procedures for Consumer-Related Disputes will not be used. The AAA's rules are available at www.adr.org or by calling 1-800-778-7879. The number of arbitrators will be one. You may choose to have the arbitration conducted by telephone, based on written submissions, or in person in the county where you live or at another mutually agreed location. The arbitration will be conducted in the English language and California law will apply. Judgment on the award rendered by the arbitrator may be entered in any court having jurisdiction thereof. Payment of all filing, administration and arbitrator fees will be governed by the AAA's rules. If you are an individual and have not accessed or used the Service on behalf of an entity, we will reimburse those fees for claims totaling less than $10,000, unless the arbitrator determines the claims are frivolous, and we will not seek attorneys\u2019 fees and costs in arbitration unless the arbitrator determines the claims are frivolous. The arbitrator, and not any federal, state, or local court, will have exclusive authority to resolve any dispute relating to the interpretation, applicability, unconscionability, arbitrability, enforceability, or formation of this arbitration agreement, including any claim that all or any part of this arbitration agreement is void or voidable. However, the preceding sentence will not apply to the \u201cClass Action Waiver\u201d section below. If you do not want to arbitrate disputes with Textile and you are an individual, you may opt out of this arbitration agreement by sending an email to [ legal@textile.io ] within thirty (30) days of the first date you access or use the Service. CLASS ACTION WAIVER Any Claim must be brought in the respective party\u2019s individual capacity, and not as a plaintiff or class member in any purported class, collective, representative, multiple plaintiff, or similar proceeding (\u201cClass Action\u201d). The parties expressly waive any ability to maintain any Class Action in any forum. If the Claim is subject to arbitration, the arbitrator will not have authority to combine or aggregate similar claims or conduct any Class Action nor make an award to any person or entity not a party to the arbitration. Any claim that all or part of this Class Action Waiver is unenforceable, unconscionable, void, or voidable may be determined only by a court of competent jurisdiction and not by an arbitrator. The parties understand that any right to litigate in court, to have a judge or jury decide their case, or to be a party to a class or representative action, is waived, and that any claims must be decided individually, through arbitration. If this class action waiver is found to be unenforceable, then the entirety of the Arbitration Agreement, if otherwise effective, will be null and void. The arbitrator may award declaratory or injunctive relief only in favor of the individual party seeking relief and only to the extent necessary to provide relief warranted by that party's individual claim. If for any reason a claim proceeds in court rather than in arbitration, you and Textile each waive any right to a jury trial and each submit to the exclusive jurisdiction of the federal courts located in San Francisco, California. 18. Notices \u00b6 We may send you, in electronic form, information about the Service, additional information, and information the law requires us to provide. We may provide required information to you by email at the address you specified when you signed up for the Service or by access to a website that we identify. Notices emailed to you will be deemed given and received when the email is sent. If you don\u2019t consent to receive notices electronically, you must stop using the Service. You may provide legal noticed to us via email to legal@textile.io , with a duplicate copy sent via registered mail, return receipt requested, to the following address: Textile, Attn: President, 206 Jackson Street. Sunnyvale, CA 94086, USA. Any such notice, in either case, must specifically reference that it is a notice given under these Terms. 19. Miscellaneous \u00b6 19.1. Severability; Entire Agreement These Terms apply to the maximum extent permitted by relevant law. If a court holds that we cannot enforce a part of these Terms as written, you and we will replace those terms with similar terms to the extent enforceable under the relevant law, but the rest of these Terms will remain in effect. This is the entire contract between you and us regarding the Service. It supersedes any prior contract or oral or written statements regarding your use of the Service. 19.2. Assignment and transfer We may assign, transfer, or otherwise dispose our rights and obligations under these Terms, in whole or in part, at any time without notice. You may not assign these Terms or transfer any rights to use the Service. 19.3. Independent Contractors; No third-party beneficiaries Textile and you are not legal partners or agents; instead, our relationship is that of independent contractors. These Terms are solely for your and our benefit. It is not for the benefit of any other person, except for permitted successors. 19.4. Claims You must bring any claim related to these Terms or the Service within one year of the date you could first bring the claim, unless your local law requires a longer time to file claims. If it isn\u2019t filed in time, the claim is permanently barred. 19.5. Waiver The failure of you or Textile to insist upon or enforce strict performance of any of the provisions of these Terms or to exercise any rights or remedies under these Terms will not be construed as a waiver or relinquishment to any extent of your right or Textile\u2019s right to assert or rely upon any such provision, right or remedy in that or any other instance; rather, the same will remain in full force and effect. 19.6. Government Use If you are a U.S. government entity, you acknowledge that any Software and User Guides that are provided are \u201cCommercial Items\u201d as defined at 48 C.F.R. 2.101, and are being provided as commercial computer software subject to the restricted rights described in 48 C.F.R. 2.101 and 12.212. 20. Copyright Complaints and Removal Policy \u00b6 We reserve the right to delete or disable Content alleged to violate these Terms and to terminate repeat offenders. 20.1 DMCA Take-down Notices If you are a copyright owner or an agent thereof and believe, in good faith, that any materials on the Service infringe upon your copyrights, you may submit a notification pursuant to the Digital Millennium Copyright Act (see 17 U.S.C. 512) (the \u201cDMCA\u201d) by sending the following information in writing to Textile\u2019s designated copyright agent at [ legal@textile.io ]: (a) The date of your notification; (b) A physical or electronic signature of a person authorized to act on behalf of the owner of an exclusive right that is allegedly infringed; \u00a9 A description of the copyrighted work claimed to have been infringed, or, if multiple copyrighted works at a single online site are covered by a single notification, a representative list of such works at that site; (d) A description of the material that is claimed to be infringing or to be the subject of infringing activity and that is to be removed or access to which is to be disabled, and information reasonably sufficient to enable Textile to locate the material; (e) Information reasonably sufficient to permit Textile to contact you, such as an address, telephone number and/or email address; (f) A statement that you have a good faith belief that use of the material in the manner complained of is not authorized by the copyright owner, its agent or the law; and (g) A statement that the information in the notification is accurate, and under penalty of perjury, that you are authorized to act on behalf of the owner of an exclusive right that is allegedly infringed. The failure to send proper notification pursuant to the DMCA may result in our taking incomplete or no action with respect to the allegedly infringing material described in such improper notification, and under some circumstances may even result in liability to the person(s) submitting such improper notifications. 20.2 Counter-Notices If you believe that your content that has been removed from the Service is not infringing, or that you have authorization from the copyright owner, the copyright owner\u2019s agent or pursuant to the law, to post and use the content, you may send a counter-notice containing the following information to our copyright agent using the contact information set forth above: (i) Your physical or electronic signature; (ii) A description of the content that has been removed and the location at which the content appeared before it was removed; (iii) A statement that you have a good faith belief that the content was removed as a result of mistake or a misidentification of the content; and (iv) Your name, address, telephone number and email address, a statement that you consent to the jurisdiction of the federal court in the Northern District Court of California and a statement that you will accept service of process from the person who provided notification of the alleged infringement. If a counter-notice is received by the Textile copyright agent, Textile may send a copy of the counter-notice to the original complaining party informing such person that it may reinstate the removed content in 10 business days. Unless the copyright owner files an action seeking a court order against the content provider or user, the removed content may (in Textile\u2019s discretion) be reinstated on the Service within 10 to 14 business days after receipt of the counter-notice. 21. Intellectual Property Notices \u00b6 All contents of the Site and Services including but not limited to design, text, software, technical drawings, configurations, graphics, other files, and their selection and arrangement are: Copyright \u00a9 Textile, and/or the proprietary property of its suppliers, affiliates, or licensors. All Rights Reserved. Textile and the Textile logo are including without limitation, either trademarks, service marks or registered trademarks of Textile, Inc., and may not be copied, imitated, or used, in whole or in part, without Textile\u2019s prior written permission or that of our suppliers or licensors. Other product and company names may be trade or service marks of their respective owners. Textile may have patents, patent applications, trademarks, copyrights, or other intellectual property rights covering subject matter that is part of the Service. Unless we have granted you licenses to our intellectual property in these Terms, our providing you with the Service does not give you any license to our intellectual property. Any rights not expressly granted herein are reserved.","title":"Terms"},{"location":"policies/terms/#1-about-this-service","text":"The Service offers verification and authentication services and encryption services for users. The Service provides a data storage system (\" Storage \") for developers to maintain remote copies of User Content. Storage is managed on IPFS ( https://www.ipfs.io/ ) nodes running on a user's personal device and replicated on remote IPFS nodes maintained by the Company. If you shared User Content which you no longer want to share publicly or privately using our Services, you must either delete that User Content or your Account. By making such deletion, the relevant User Content will become unlinked from the IPFS network and will be deleted from our IPFS node. You agree to immediately notify Company of any unauthorized use, or suspected unauthorized use of your Account or any other breach of security. Company cannot and will not be liable for any loss or damage arising from your failure to comply with the above requirements.","title":"1. About this Service"},{"location":"policies/terms/#2-changes-to-these-terms","text":"We reserve the right to revise these Terms from time to time. We will date and post the most current version of these Terms on the Site. Any changes will be effective upon posting the revised version of these Terms (or such later effective date as may be indicated at the top of the revised Terms). If, in our sole discretion, we deem a revision to these Terms to be material, we will notify you via the Service and/or by email to the email address associated with your account. Notice of other changes may be provided via the Site. Therefore, we encourage you to check the date of these Terms whenever you visit the Site to see if these Terms have been updated. Your continued access or use of any portion of the Service constitutes your acceptance of such changes. If you don\u2019t agree to any of the changes, we\u2019re not obligated to keep providing the Service to you, and you must cancel and stop using the Service.","title":"2. Changes to these Terms"},{"location":"policies/terms/#3-access-to-the-service","text":"You may use the Service, on a non-exclusive basis, solely in strict compliance with these Terms and all applicable laws.","title":"3. Access to the Service"},{"location":"policies/terms/#4-your-account","text":"To obtain access to certain Services, you may be required to obtain an account with Textile (become a \u201c Registered User \u201d). Until you apply for and are approved for an account your access to the Service will be limited to the areas of the Service, if any, that Textile makes available to the general public. When registering with Textile you must: (a) provide true, accurate, current and complete information about yourself as requested by the Service\u2019s registration form (such information being the \u201c Registration Data \u201d); and (b) maintain and promptly update the Registration Data to keep it true, accurate, current and complete. Textile may deny approval or withdraw such approval at any time in its sole discretion, with or without cause. Only you may use your Textile account. You must keep your account and passwords confidential and not authorize any third party to access or use the Service on your behalf, unless we provide an approved mechanism for such use. Textile will not be liable for any loss or damage arising from any unauthorized use of your accounts. CONTENT You represent and warrant that none of the following infringe any intellectual property, publicity or other proprietary rights: your provision of Your Content to us, your causing Your Content to be posted using the Service, and use of any such content (including of works derived from it) by us, other users of the Service, or others in contract with us that is done in connection with the Service and in compliance with these Terms. You acknowledge and agree that we may access or disclose information about you or any other information or data collected, stored or processed on our servers, including Your Content, if required to do so by law or in the good-faith belief that such action is necessary to: (a) comply with any law, regulation, legal process or lawful governmental requests; (b) protect the rights or property of Textile or our customers, including the enforcement of our agreements or policies governing your use of the Service; or \u00a9 act on a good faith belief that such access or disclosure is necessary to protect the personal safety of Textile employees, customers, or the public. We retain the right to block or otherwise prevent delivery of any type of file, email or other communication to or from the Service as part of our efforts to protect the Service, protect our customers, or stop you from breaching these Terms.","title":"4. Your Account"},{"location":"policies/terms/#6-consent-to-electronic-communications-and-solicitation","text":"By registering for the Service, you understand that we may send you communications or data regarding the Services, including but not limited to: (a) notices about your use of the Services, including any notices concerning violations of use; (b) updates; and \u00a9 promotional information and materials regarding Textile\u2019s products and services, via electronic mail. We give you the opportunity to opt-out of receiving promotional electronic mail from us by following the opt-out instructions provided in the message.","title":"6. Consent to Electronic Communications and Solicitation"},{"location":"policies/terms/#7-suspension-and-termination-of-use-of-the-service","text":"We reserve the right, to temporarily suspend or terminate your access to the Service at any time in our sole discretion, with or without cause, with or without notice, and without incurring liability of any kind. For example, we may suspend or terminate your access to or use of the Service for: (a) the actual or suspected violation of these Terms; (b) the use of the Services in a manner that may cause Textile to have legal liability or disrupt others\u2019 use of the Services; \u00a9 the suspicion or detection of any malicious code, virus or other harmful code by you or in your account; (d) scheduled downtime and recurring downtime; (e) any actual or suspected effort by you to circumvent Textile\u2019s security or encryption; or (f) unplanned technical problems and outages. If, in Textile\u2019s determination, the suspension might be indefinite and/or Textile has elected to terminate your access to the Service, Textile will use commercially reasonable efforts to notify you through the Service and/or by email to the email address associated with your account. You acknowledge that if your access to the Service is suspended or terminated, you may no longer have access to Your Content that is stored with the Service.","title":"7. Suspension and Termination of Use of the Service"},{"location":"policies/terms/#8-acceptable-use","text":"You must not use the Service to harm others or the Service. For example, you must not use the Service to harm, threaten, or harass another person, organization, or Textile. You must not: damage, disable, overburden, or impair the Service (or any network connected to the Service); resell or redistribute the Service or any part of it; use any unauthorized means to modify, reroute, or gain access to the Service or attempt to carry out these activities; or use any data mining, robots, or similar data gathering and extraction tools; or use any automated process or Service (such as a bot, a spider, or periodic caching of information stored by Textile) to access or use the Service;. In addition, you promise that you will not and will not encourage or assist any third party to: I. reproduce, modify, alter, tamper with, repair or create derivative works of any Software, unless that permission is granted in a license. Further, unless expressly prohibited under applicable law, you may not use the Service to develop, test, validate and/or improve any service that is a substitute for, or substantially similar to, the Service (including any portion thereof); II. reverse engineer, disassemble or decompile the Software used to provide or access the Service, including the Software, or attempt to discover or recreate the source code used to provide or access the Service, except and only to the extent that that permission is granted in a license or applicable law expressly permits doing so; III. use the Service in any manner or for any purpose other than as expressly permitted by these Terms, the Privacy Policy, any User Guides or any other policy, instruction or terms applicable to the Service that are available on the Service (\u201cPolicies\u201d); IV. sell, lend, rent, resell, lease, sublicense or otherwise transfer any of the rights granted to you with respect to the Services to any third party; V. remove, obscure or alter any proprietary rights notice pertaining to the Service; VI. use the Service in connection with the operation of nuclear facilities, aircraft navigation, communication systems, medical devices, air traffic control devices, real time control systems or other situations in which the failure of the Service could lead to death, personal injury, or physical property or environmental damage; VII. use the Service to: (i) engage in any unlawful or fraudulent activity or perpetrate a hoax or engage in phishing schemes or forgery or other similar falsification or manipulation of data; (ii) send unsolicited or unauthorized junk mail, spam, chain letters, pyramid schemes or any other form of duplicative or unsolicited messages, whether commercial or otherwise; (iii) store or transmit any inappropriate content, such as content: (1) containing unlawful, defamatory, threatening, abusive, libelous or otherwise objectionable material of any kind or nature, (2) containing any material that encourages conduct that could constitute a criminal offense, or (3) in a way that violates or infringes upon the intellectual property rights or the privacy or publicity rights of any person or entity or that may otherwise be unlawful or give rise to civil or criminal liability; (iv) store or transmit any content that contains or is used to initiate a denial of service attack, software viruses or other harmful or deleterious computer code, files or programs such as Trojan horses, worms, time bombs, cancelbots, or spyware; or (v) abuse, harass, stalk or otherwise violate the legal rights of a third party; VIII. interfere with or disrupt servers or networks used by Textile to provide the Service or used by other users\u2019 to access the Service, or violate any third party regulations, policies or procedures of such servers or networks or harass or interfere with another user\u2019s full use and enjoyment of any Software or the Service; IX. access or attempt to access Textile\u2019s other accounts, computer systems or networks not covered by these Terms, through password mining or any other means; X. cause, in Textile\u2019s sole discretion, inordinate burden on the Service or Textile\u2019s system resources or capacity; or XI. share passwords or other access information or devices or otherwise authorize any third party to access or use the Software or the Service. Textile reserves the right, in its sole discretion, to deactivate, change and/or require you to change your Textile user ID and any custom or vanity URLs, custom links, or vanity domains you may obtain through the Services for any reason or for no reason. Textile may exercise such right at any time, with or without prior notice. We will make all judgments concerning the applicability of these guidelines in our sole and exclusive discretion. We reserve the right, in our sole discretion, to determine whether and what action to take in response to each such notification, and any action or inaction in a particular instance will not dictate or limit our response to a future complaint. We will not assume or have any liability for any action or inaction with respect to any Your Content.","title":"8. Acceptable Use"},{"location":"policies/terms/#9-updates-to-the-service","text":"Textile reserves the right, in its sole discretion, to make necessary unscheduled deployments of changes, updates or enhancements to the Service at any time. We may add or remove functionalities or features, and we may suspend or stop the Service altogether.","title":"9. Updates to the Service"},{"location":"policies/terms/#10-software","text":"If you receive Software from us, its use is governed in one of two ways: If you\u2019re presented with license terms that you must accept in order to use the Software, those terms apply; if no license is presented to you, these Terms apply. We reserve all other rights to the Software. We may automatically check your version of the Software. We may also automatically download to your computer or device new versions of the Software. Any Software is licensed, not sold. Unless we notify you otherwise, the Software license ends when your Service ends. You must then promptly uninstall the Software, or we may disable it. You must not work around any technical limitations in the Software. The Software is subject to applicable U.S. export laws and regulations. You must comply with all domestic and international export laws and regulations that apply to the Software. These laws include restrictions on destinations, end users, and end use. Without limitation, you may not transfer the Software or Service without U.S. government permission to anyone on U.S. government exclusion lists (see the Commerce Department\u2019s compliance list at http://www.bis.doc.gov/index.php/policy-guidance/lists-of-parties-of-concern . You represent and warrant that you\u2019re not on any of those lists or under the control of or an agent for anyone on those lists or the entities listed above.","title":"10. Software"},{"location":"policies/terms/#11-third-party-services-and-content","text":"All transactions using the Services are between the transacting parties only. The Services may contain features and functionalities linking you or providing you with certain functionality and access to third party content, including Web sites, directories, servers, networks, systems, information and databases, applications, software, programs, products or services, and the Internet as a whole; you acknowledge that we are not responsible for such content or services. We may also provide some content to you as part of the Services. However, Textile is not an agent of any transacting party, nor or we a direct party in any such transaction. Any such activities, and any terms associated with such activities, are solely between you and the applicable third-party. Similarly, we are not responsible for any third party content you access with the Services, and you irrevocably waive any claim against us with respect to such sites and third-party content. Textile shall have no liability, obligation or responsibility for any such correspondence, purchase or promotion between you and any such third-party. You should make whatever investigation you feel necessary or appropriate before proceeding with any online or offline transaction with any of these third parties. You are solely responsible for your dealings with any third party related to the Services, including the delivery of and payment for goods and services.","title":"11. Third Party Services and Content"},{"location":"policies/terms/#12-textile-proprietary-rights","text":"As between Textile and you, Textile or its licensors own and reserve all right, title and interest in and to the Service and all hardware, software and other items used to provide the Service, other than the rights explicitly granted to you to use the Service in accordance with this Terms. No title to or ownership of any proprietary rights related to the Service is transferred to you pursuant to these Terms. All rights not explicitly granted to you are reserved by Textile. In the event that you provide comments, suggestions and recommendations to Textile with respect to the Service (including, without limitation, with respect to modifications, enhancements, improvements and other changes to the Service) (collectively, \u201cFeedback\u201d), you hereby grant to Textile a world-wide, royalty free, irrevocable, perpetual license to use and otherwise incorporate any Feedback in connection with the Service.","title":"12. Textile Proprietary Rights"},{"location":"policies/terms/#13-privacy","text":"In order to operate and provide the Service, we collect certain information about you. We use that information as described in the privacy policy located at https://docs.textile.io/policies/privacy (\u201c Privacy Policy \u201d).","title":"13. Privacy"},{"location":"policies/terms/#14-no-warranty","text":"TEXTILE PROVIDES THE SERVICE \u201cAS IS\u201d, \u201cWITH ALL FAULTS\u201d AND \u201cAS AVAILABLE\u201d. TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, TEXTILE MAKES NO (AND SPECIFICALLY DISCLAIMS ALL) REPRESENTATIONS OR WARRANTIES OF ANY KIND, WHETHER EXPRESS, IMPLIED, STATUTORY OR OTHERWISE, INCLUDING, WITHOUT LIMITATION, ANY WARRANTY THAT THE SERVICE WILL BE UNINTERRUPTED, ERROR-FREE OR FREE OF HARMFUL COMPONENTS, THAT YOUR CONTENT WILL BE SECURE OR NOT OTHERWISE LOST OR DAMAGED, OR ANY IMPLIED WARRANTY OF MERCHANTABILITY, SATISFACTORY QUALITY, FITNESS FOR A PARTICULAR PURPOSE, OR NON-INFRINGEMENT, AND ANY WARRANTY ARISING OUT OF ANY COURSE OF PERFORMANCE, COURSE OF DEALING OR USAGE OF TRADE. SOME JURISDICTIONS DO NOT ALLOW THE FOREGOING EXCLUSIONS. IN SUCH AN EVENT SUCH EXCLUSION WILL NOT APPLY SOLELY TO THE EXTENT PROHIBITED BY APPLICABLE LAW. You hereby acknowledge and agree that this disclaimer of warranties is a fundamental part of the agreement between you and Textile contained in these Terms and that Textile would not agree to enter these Terms or allow you access or use the Service without such disclaimers.","title":"14. No Warranty"},{"location":"policies/terms/#15-indemnification","text":"You will defend Textile against any cost, loss, damage, or other liability arising from any third party demand or claim that any Your Content, or your use of the Service, in breach of these Terms: (a) infringes a registered patent, registered trademark, or copyright of a third party, or misappropriates a trade secret (to the extent that such misappropriation is not the result of Textile\u2019s actions); or (b) violates applicable law or these Terms. Textile will reasonably notify you of any such claim or demand that is subject to your indemnification obligation.","title":"15. Indemnification"},{"location":"policies/terms/#16-limitation-of-liability","text":"TO THE FULLEST EXTENT PERMITTED BY LAW, IN NO EVENT WILL TEXTILE, ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE FOR: ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, PUNITIVE, COVER OR CONSEQUENTIAL DAMAGES, OR DAMAGES FOR LOST PROFITS, REVENUE, GOODWILL, USE OR CONTENT, HOWEVER CAUSED, UNDER ANY THEORY OF LIABILITY, INCLUDING, WITHOUT LIMITATION, CONTRACT, TORT, WARRANTY, NEGLIGENCE OR OTHERWISE, EVEN IF TEXTILE HAS BEEN ADVISED AS TO THE POSSIBILITY OF SUCH DAMAGES. TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, THE AGGREGATE LIABILITY OF TEXTILE AND ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS, RELATING TO THE SERVICES WILL BE LIMITED TO FIFTY DOLLARS ($50.00). THE LIMITATIONS AND EXCLUSIONS ALSO APPLY IF THIS REMEDY DOES NOT FULLY COMPENSATE YOU FOR ANY LOSSES OR FAILS OF ITS ESSENTIAL PURPOSE. SOME JURISDICTIONS DO NOT ALLOW THE LIMITATION OF INCIDENTAL, CONSEQUENTIAL OR OTHER DAMAGES. IN SUCH AN EVENT THIS LIMITATION WILL NOT APPLY TO YOU TO THE EXTENT PROHIBITED BY LAW. You acknowledge that the foregoing limitations are an essential element of the agreement between you and Textile and that in the absence of such limitations the terms and conditions set forth in these Terms would be substantially different.","title":"16. Limitation of Liability"},{"location":"policies/terms/#17-arbitration-class-action-waiver","text":"17.1 Introduction Introduction. This Section 17 includes an arbitration agreement and an agreement that all claims will be brought only in an individual capacity (and not as a class action or other representative proceeding). Please read it carefully. You may opt out of the arbitration agreement by following the opt out procedure described below. 17.2 Process Informal Process First You agree that in the event of any dispute between you and Textile, you will first contact Textile and make a good faith sustained effort to resolve the dispute before resorting to more formal means of resolution, including without limitation any court action. 17.3 Arbitration Agreement After the informal dispute resolution process any remaining dispute, controversy, or claim (collectively, \u201cClaim\u201d) relating in any way to your use of Textile\u2019s services and/or products, including the Service, or relating in any way to the communications between you and Textile or any other user of the Service, will be finally resolved by binding arbitration. This mandatory arbitration agreement applies equally to you and Textile. However, this arbitration agreement does not (a) govern any Claim by Textile for infringement of its intellectual property or access to the Service that is unauthorized or exceeds authorization granted in these Terms or (b) bar you from making use of applicable small claims court procedures in appropriate cases. If you are an individual you may opt out of this arbitration agreement within thirty (30) days of the first date you access or use this Service by following the procedure described below. Arbitration is more informal than a lawsuit in court. There is no judge or jury in arbitration. Instead, the dispute is resolve by a neutral arbitrator. Court review of an arbitration award is limited. Except to the extent the parties agree otherwise, arbitrators can award the same damages and relief that a court can award. You agree that the U.S. Federal Arbitration Act governs the interpretation and enforcement of this provision, and that you and Textile are each waiving the right to a trial by jury or to participate in a class action. This arbitration provision will survive any termination of these Terms. If you wish to begin an arbitration proceeding, after following the informal dispute resolution procedure, you must send a letter requesting arbitration and describing your claim to Textile, Inc., Attn: President, 85 Broad St., 18 th Floor - NY, NY 10004. The arbitration will be administered by the American Arbitration Association (AAA) under its rules including, if you are an individual, the AAA's Supplementary Procedures for Consumer-Related Disputes. If you are not an individual or have used the Services on behalf of an entity, the AAA's Supplementary Procedures for Consumer-Related Disputes will not be used. The AAA's rules are available at www.adr.org or by calling 1-800-778-7879. The number of arbitrators will be one. You may choose to have the arbitration conducted by telephone, based on written submissions, or in person in the county where you live or at another mutually agreed location. The arbitration will be conducted in the English language and California law will apply. Judgment on the award rendered by the arbitrator may be entered in any court having jurisdiction thereof. Payment of all filing, administration and arbitrator fees will be governed by the AAA's rules. If you are an individual and have not accessed or used the Service on behalf of an entity, we will reimburse those fees for claims totaling less than $10,000, unless the arbitrator determines the claims are frivolous, and we will not seek attorneys\u2019 fees and costs in arbitration unless the arbitrator determines the claims are frivolous. The arbitrator, and not any federal, state, or local court, will have exclusive authority to resolve any dispute relating to the interpretation, applicability, unconscionability, arbitrability, enforceability, or formation of this arbitration agreement, including any claim that all or any part of this arbitration agreement is void or voidable. However, the preceding sentence will not apply to the \u201cClass Action Waiver\u201d section below. If you do not want to arbitrate disputes with Textile and you are an individual, you may opt out of this arbitration agreement by sending an email to [ legal@textile.io ] within thirty (30) days of the first date you access or use the Service. CLASS ACTION WAIVER Any Claim must be brought in the respective party\u2019s individual capacity, and not as a plaintiff or class member in any purported class, collective, representative, multiple plaintiff, or similar proceeding (\u201cClass Action\u201d). The parties expressly waive any ability to maintain any Class Action in any forum. If the Claim is subject to arbitration, the arbitrator will not have authority to combine or aggregate similar claims or conduct any Class Action nor make an award to any person or entity not a party to the arbitration. Any claim that all or part of this Class Action Waiver is unenforceable, unconscionable, void, or voidable may be determined only by a court of competent jurisdiction and not by an arbitrator. The parties understand that any right to litigate in court, to have a judge or jury decide their case, or to be a party to a class or representative action, is waived, and that any claims must be decided individually, through arbitration. If this class action waiver is found to be unenforceable, then the entirety of the Arbitration Agreement, if otherwise effective, will be null and void. The arbitrator may award declaratory or injunctive relief only in favor of the individual party seeking relief and only to the extent necessary to provide relief warranted by that party's individual claim. If for any reason a claim proceeds in court rather than in arbitration, you and Textile each waive any right to a jury trial and each submit to the exclusive jurisdiction of the federal courts located in San Francisco, California.","title":"17. Arbitration; Class Action Waiver"},{"location":"policies/terms/#18-notices","text":"We may send you, in electronic form, information about the Service, additional information, and information the law requires us to provide. We may provide required information to you by email at the address you specified when you signed up for the Service or by access to a website that we identify. Notices emailed to you will be deemed given and received when the email is sent. If you don\u2019t consent to receive notices electronically, you must stop using the Service. You may provide legal noticed to us via email to legal@textile.io , with a duplicate copy sent via registered mail, return receipt requested, to the following address: Textile, Attn: President, 206 Jackson Street. Sunnyvale, CA 94086, USA. Any such notice, in either case, must specifically reference that it is a notice given under these Terms.","title":"18. Notices"},{"location":"policies/terms/#19-miscellaneous","text":"19.1. Severability; Entire Agreement These Terms apply to the maximum extent permitted by relevant law. If a court holds that we cannot enforce a part of these Terms as written, you and we will replace those terms with similar terms to the extent enforceable under the relevant law, but the rest of these Terms will remain in effect. This is the entire contract between you and us regarding the Service. It supersedes any prior contract or oral or written statements regarding your use of the Service. 19.2. Assignment and transfer We may assign, transfer, or otherwise dispose our rights and obligations under these Terms, in whole or in part, at any time without notice. You may not assign these Terms or transfer any rights to use the Service. 19.3. Independent Contractors; No third-party beneficiaries Textile and you are not legal partners or agents; instead, our relationship is that of independent contractors. These Terms are solely for your and our benefit. It is not for the benefit of any other person, except for permitted successors. 19.4. Claims You must bring any claim related to these Terms or the Service within one year of the date you could first bring the claim, unless your local law requires a longer time to file claims. If it isn\u2019t filed in time, the claim is permanently barred. 19.5. Waiver The failure of you or Textile to insist upon or enforce strict performance of any of the provisions of these Terms or to exercise any rights or remedies under these Terms will not be construed as a waiver or relinquishment to any extent of your right or Textile\u2019s right to assert or rely upon any such provision, right or remedy in that or any other instance; rather, the same will remain in full force and effect. 19.6. Government Use If you are a U.S. government entity, you acknowledge that any Software and User Guides that are provided are \u201cCommercial Items\u201d as defined at 48 C.F.R. 2.101, and are being provided as commercial computer software subject to the restricted rights described in 48 C.F.R. 2.101 and 12.212.","title":"19. Miscellaneous"},{"location":"policies/terms/#20-copyright-complaints-and-removal-policy","text":"We reserve the right to delete or disable Content alleged to violate these Terms and to terminate repeat offenders. 20.1 DMCA Take-down Notices If you are a copyright owner or an agent thereof and believe, in good faith, that any materials on the Service infringe upon your copyrights, you may submit a notification pursuant to the Digital Millennium Copyright Act (see 17 U.S.C. 512) (the \u201cDMCA\u201d) by sending the following information in writing to Textile\u2019s designated copyright agent at [ legal@textile.io ]: (a) The date of your notification; (b) A physical or electronic signature of a person authorized to act on behalf of the owner of an exclusive right that is allegedly infringed; \u00a9 A description of the copyrighted work claimed to have been infringed, or, if multiple copyrighted works at a single online site are covered by a single notification, a representative list of such works at that site; (d) A description of the material that is claimed to be infringing or to be the subject of infringing activity and that is to be removed or access to which is to be disabled, and information reasonably sufficient to enable Textile to locate the material; (e) Information reasonably sufficient to permit Textile to contact you, such as an address, telephone number and/or email address; (f) A statement that you have a good faith belief that use of the material in the manner complained of is not authorized by the copyright owner, its agent or the law; and (g) A statement that the information in the notification is accurate, and under penalty of perjury, that you are authorized to act on behalf of the owner of an exclusive right that is allegedly infringed. The failure to send proper notification pursuant to the DMCA may result in our taking incomplete or no action with respect to the allegedly infringing material described in such improper notification, and under some circumstances may even result in liability to the person(s) submitting such improper notifications. 20.2 Counter-Notices If you believe that your content that has been removed from the Service is not infringing, or that you have authorization from the copyright owner, the copyright owner\u2019s agent or pursuant to the law, to post and use the content, you may send a counter-notice containing the following information to our copyright agent using the contact information set forth above: (i) Your physical or electronic signature; (ii) A description of the content that has been removed and the location at which the content appeared before it was removed; (iii) A statement that you have a good faith belief that the content was removed as a result of mistake or a misidentification of the content; and (iv) Your name, address, telephone number and email address, a statement that you consent to the jurisdiction of the federal court in the Northern District Court of California and a statement that you will accept service of process from the person who provided notification of the alleged infringement. If a counter-notice is received by the Textile copyright agent, Textile may send a copy of the counter-notice to the original complaining party informing such person that it may reinstate the removed content in 10 business days. Unless the copyright owner files an action seeking a court order against the content provider or user, the removed content may (in Textile\u2019s discretion) be reinstated on the Service within 10 to 14 business days after receipt of the counter-notice.","title":"20. Copyright Complaints and Removal Policy"},{"location":"policies/terms/#21-intellectual-property-notices","text":"All contents of the Site and Services including but not limited to design, text, software, technical drawings, configurations, graphics, other files, and their selection and arrangement are: Copyright \u00a9 Textile, and/or the proprietary property of its suppliers, affiliates, or licensors. All Rights Reserved. Textile and the Textile logo are including without limitation, either trademarks, service marks or registered trademarks of Textile, Inc., and may not be copied, imitated, or used, in whole or in part, without Textile\u2019s prior written permission or that of our suppliers or licensors. Other product and company names may be trade or service marks of their respective owners. Textile may have patents, patent applications, trademarks, copyrights, or other intellectual property rights covering subject matter that is part of the Service. Unless we have granted you licenses to our intellectual property in these Terms, our providing you with the Service does not give you any license to our intellectual property. Any rights not expressly granted herein are reserved.","title":"21. Intellectual Property Notices"},{"location":"powergate/","text":"Introduction to the Powergate \u00b6 The Powergate is an API driven solution for deploying multitiered storage across Filecoin and IPFS . Persistent storage on Filecoin allows rich storage configuration for data such as replication factor, miner selection, deal renewal, and repair. Network available storage is configurable and provided through a connected IPFS peer or pinning network. Warning The Powergate will remain in rapid development until close to the Filecoin Mainnet launch. During this time, will likely encounter bugs and unannounced API changes. Do not run the Powergate in production systems. Overview \u00b6 Powergate is a collection of libraries, modules, and configurations that can used independently, and composed together to integrate Filecoin into your application or storage system. The Powergate is designed to manage one or many Filecoin wallet addresses. Each address in Powergate can be independently managed through the FFS API (or grouped together into a single FFS instance ). Some benefits of using the Powergate include: Ensure data stored on Filecoin is available on the IPFS network easily. Handle long-term storage deal management, including automated renew and repair. Make use of network indices to improve miner selection and deal creation. Manage Filecoin wallet addresses for one or many users. Easily configure, connect, and deploy Powergate, Lotus , and IPFS together. Much more! Libraries \u00b6 Powergate Repo Open source multi-tiered file storage API built on Filecoin and IPFS. POW JS Client Typescript/Javascript client for Textile's Powergate . POW Golang Client Golang client for the Powergate. POW CLI A command-line interface to work directly with a running Powergate. Filecoin Local Devnet A fast development node for working with Filecoin APIs. Getting started \u00b6 Command-line Interface \u00b6 The Powergate includes the full set of features through the binary command-line interface. Install the CLI You can build and install the Powergate CLI from the Powergate Repo . git clone git@github.com:textileio/powergate.git cd powergate make build Using the CLI Powergate CLI commands are just pow . Multi-tiered storage \u00b6 The workhorse of APIs in the Powergate is called, the FFS (Filecoin File System). This module provides a multi-tiered file storage API built on Filecoin and IPFS. Storing data on IPFS and Filecoin is as easy as expressing your desired configuration for storing a Cid. The FFS is where the Powergate handles Filecoin wallet addresses, long-term deal management, and connecting Filecoin to IPFS. Access to the FFS is enabled through a basic token, allowing you to create many FFS Instances, and map Powergate API access to user(s) in your system. Read about the FFS here . Network Indices \u00b6 Indices A running Powergate deployment will collect a number of useful indices about the network. Some of the data collected in these indices are used by the FFS to streamline miner selection when creating new deals. You can use the indices directly to build other features into your own system. Miners index . Provides processed data regarding registered miners (on-chain and off-chain), such as: total miner power, relative power, online status, geolocation, and more! Ask index . Provides a fast-retrieval up to date snapshot of miner's asking prices for data storage. Slashing index . Provides history data about miners faults while proving their storage on-chain. Reputation Module Built on top of the previous indexes, a Reputation module constructs a weighted-scoring system that allows to sort miners considering multiple on-chain and off-chain data, such as: compared price to the median of the market, low storage-fault history, power on network, and external sources (soon!). Powergate APIs \u00b6 The Powergate APIs are available as gRPC endpoints. There are three ways to get familiar with the broad set of APIs available to start using on the Powergate. Explore the CLI . The CLI runs on the Powergate API, so in general, anything you can do in the CLI you can also do over the API. Use the JS Client . We have provided an easy to use JavaScript client for the Powergate APIs . User the Go Client . You can use the Powergate APIs from your go app by building directly on the Powergate Go Client . Browse the Protocols . The API is typed with Protocol Buffers and you can quickly view all capabilities by looking at the .proto files in the Powergate repo . The best place to start is the FFS API . Additional Tools \u00b6 The Powergate comes packed with a number of additional tools that will be useful to you as you integrate it into your system. Lotus . A Lotus node running on the current Testnet. IPFS . A full IPFS node running to back Powergate FFS. Prometheus . The backend for metrics processing. Grafana . Providing metrics dashboard. cAdvisor . Providing container metrics. Running the Powergate \u00b6 You can run the Powergate on the Filecoin testnet or using an embedded devnet we make available as part of the Powergate stack. We recommend starting out with the devnet as you'll get access to the full set of APIs and capabilities without having to start syncing the network right away. When ready, you can update your Powergate to connect to the live testnet and in the future mainnet . Devnet \u00b6 The devnet provides a fast, fully functional, embedded Filecoin network that can be used for testing, building, or running continuous integratin. Read more about running the Powergate on devnet or running the devnet to use the Lotus client directly . Testnet \u00b6 Once you are ready to start using the Powergate with the Filecoin Testnet, it's just a single line. git clone git@github.com:textileio/powergate.git cd powergate/docker make up Read the latest setup instructions . Mainnet \u00b6 When Filecoin Mainnet launches, we'll provide setup steps like the Testnet steps above. Learn more \u00b6 Walk-through Video \u00b6 In the above presentation, we'll give a high-level overview of how the Powergate fits into the Filecoin and IPFS networks and a detailed walk-through of system components. Running System Video \u00b6 The above video shows the Powergate startup including IPFS and Lotus nodes. Next, the admin uses the Powergate CLI to create a deal on the Filecoin network. Keep up-to-date \u00b6 Follow the project on our blog and on our GitHub repo and give us your feedback.","title":"Introduction"},{"location":"powergate/#introduction-to-the-powergate","text":"The Powergate is an API driven solution for deploying multitiered storage across Filecoin and IPFS . Persistent storage on Filecoin allows rich storage configuration for data such as replication factor, miner selection, deal renewal, and repair. Network available storage is configurable and provided through a connected IPFS peer or pinning network. Warning The Powergate will remain in rapid development until close to the Filecoin Mainnet launch. During this time, will likely encounter bugs and unannounced API changes. Do not run the Powergate in production systems.","title":"Introduction to the Powergate"},{"location":"powergate/#overview","text":"Powergate is a collection of libraries, modules, and configurations that can used independently, and composed together to integrate Filecoin into your application or storage system. The Powergate is designed to manage one or many Filecoin wallet addresses. Each address in Powergate can be independently managed through the FFS API (or grouped together into a single FFS instance ). Some benefits of using the Powergate include: Ensure data stored on Filecoin is available on the IPFS network easily. Handle long-term storage deal management, including automated renew and repair. Make use of network indices to improve miner selection and deal creation. Manage Filecoin wallet addresses for one or many users. Easily configure, connect, and deploy Powergate, Lotus , and IPFS together. Much more!","title":"Overview"},{"location":"powergate/#libraries","text":"","title":"Libraries"},{"location":"powergate/#getting-started","text":"","title":"Getting started"},{"location":"powergate/#command-line-interface","text":"The Powergate includes the full set of features through the binary command-line interface. Install the CLI You can build and install the Powergate CLI from the Powergate Repo . git clone git@github.com:textileio/powergate.git cd powergate make build Using the CLI Powergate CLI commands are just pow .","title":"Command-line Interface"},{"location":"powergate/#multi-tiered-storage","text":"The workhorse of APIs in the Powergate is called, the FFS (Filecoin File System). This module provides a multi-tiered file storage API built on Filecoin and IPFS. Storing data on IPFS and Filecoin is as easy as expressing your desired configuration for storing a Cid. The FFS is where the Powergate handles Filecoin wallet addresses, long-term deal management, and connecting Filecoin to IPFS. Access to the FFS is enabled through a basic token, allowing you to create many FFS Instances, and map Powergate API access to user(s) in your system. Read about the FFS here .","title":"Multi-tiered storage"},{"location":"powergate/#network-indices","text":"Indices A running Powergate deployment will collect a number of useful indices about the network. Some of the data collected in these indices are used by the FFS to streamline miner selection when creating new deals. You can use the indices directly to build other features into your own system. Miners index . Provides processed data regarding registered miners (on-chain and off-chain), such as: total miner power, relative power, online status, geolocation, and more! Ask index . Provides a fast-retrieval up to date snapshot of miner's asking prices for data storage. Slashing index . Provides history data about miners faults while proving their storage on-chain. Reputation Module Built on top of the previous indexes, a Reputation module constructs a weighted-scoring system that allows to sort miners considering multiple on-chain and off-chain data, such as: compared price to the median of the market, low storage-fault history, power on network, and external sources (soon!).","title":"Network Indices"},{"location":"powergate/#powergate-apis","text":"The Powergate APIs are available as gRPC endpoints. There are three ways to get familiar with the broad set of APIs available to start using on the Powergate. Explore the CLI . The CLI runs on the Powergate API, so in general, anything you can do in the CLI you can also do over the API. Use the JS Client . We have provided an easy to use JavaScript client for the Powergate APIs . User the Go Client . You can use the Powergate APIs from your go app by building directly on the Powergate Go Client . Browse the Protocols . The API is typed with Protocol Buffers and you can quickly view all capabilities by looking at the .proto files in the Powergate repo . The best place to start is the FFS API .","title":"Powergate APIs"},{"location":"powergate/#additional-tools","text":"The Powergate comes packed with a number of additional tools that will be useful to you as you integrate it into your system. Lotus . A Lotus node running on the current Testnet. IPFS . A full IPFS node running to back Powergate FFS. Prometheus . The backend for metrics processing. Grafana . Providing metrics dashboard. cAdvisor . Providing container metrics.","title":"Additional Tools"},{"location":"powergate/#running-the-powergate","text":"You can run the Powergate on the Filecoin testnet or using an embedded devnet we make available as part of the Powergate stack. We recommend starting out with the devnet as you'll get access to the full set of APIs and capabilities without having to start syncing the network right away. When ready, you can update your Powergate to connect to the live testnet and in the future mainnet .","title":"Running the Powergate"},{"location":"powergate/#devnet","text":"The devnet provides a fast, fully functional, embedded Filecoin network that can be used for testing, building, or running continuous integratin. Read more about running the Powergate on devnet or running the devnet to use the Lotus client directly .","title":"Devnet"},{"location":"powergate/#testnet","text":"Once you are ready to start using the Powergate with the Filecoin Testnet, it's just a single line. git clone git@github.com:textileio/powergate.git cd powergate/docker make up Read the latest setup instructions .","title":"Testnet"},{"location":"powergate/#mainnet","text":"When Filecoin Mainnet launches, we'll provide setup steps like the Testnet steps above.","title":"Mainnet"},{"location":"powergate/#learn-more","text":"","title":"Learn more"},{"location":"powergate/#walk-through-video","text":"In the above presentation, we'll give a high-level overview of how the Powergate fits into the Filecoin and IPFS networks and a detailed walk-through of system components.","title":"Walk-through Video"},{"location":"powergate/#running-system-video","text":"The above video shows the Powergate startup including IPFS and Lotus nodes. Next, the admin uses the Powergate CLI to create a deal on the Filecoin network.","title":"Running System Video"},{"location":"powergate/#keep-up-to-date","text":"Follow the project on our blog and on our GitHub repo and give us your feedback.","title":"Keep up-to-date"},{"location":"powergate/cidconfig/","text":"Managing Storage with the CidConfig \u00b6 Every FFS instance can manage how data is stored on IPFS and Filecoin using the CidConfig ( details below ). The CidConfig is a powerful tool to customize all the details of how you store data on Filecoin, make it available over IPFS, enforce replication, manage expiring deals, and more. Setting the CidConfig \u00b6 In every Powergate deployment there are three ways to manage CidConfigs throughout the system. The FFS instance default CidConfig. This is initially set by the system default CidConfig. It can be modified by the FFS instance owner after creation. The storage request CidConfig. This will use the FFS instance default, but a custom CidConfig can also be supplied at request time. A storage update CidConfig. Any CidConfigs attached to existing stored data can be updated with a new CidConfig. The FFS instance will then work to modify the way data is stored to match the new configuration Get the default CidConfig of an FFS instance \u00b6 View the current default CidConfig of an FFS instance. pow ffs config default -t <token> Set the default CidConfig of an FFS instance \u00b6 To set the default config to one stored in new-config.json . pow ffs config set new-config.json -t <token> Set a custom CidConfig at storage time \u00b6 You can provide a flag ( -c ) to include a custom CidConfig for a new storage request. Storage requests without a custom CidConfig will use the instance default storage config. pow ffs push <cid> -t <token> -c custom-config.json Get the CidConfig of previously stored data \u00b6 To pull the CidConfig associated with data already managed by the FFS instance, use the of the stored data. pow ffs pull <cid> -t <token> Update the CidConfig of existing data \u00b6 To update the CidConfig of data already stored and managed by the Powergate with a new config stored in updated-config.json . This command requires the override flag ( -o ) to confirm that you understand that the command will replace an existing config. pow ffs push <cid> -t <token> -o -c updated-config.json CidConfig Details \u00b6 Here is an example of the default CidConfig . { // Hot has this desired storing configuration in Hot Storage. \"Hot\" : { // Enable indicates if Cid data is stored. If true, it will // consider further configurations to execute actions. \"Enabled\" : true , // AllowUnfreeze indicates that if data isn't available in the // Hot Storage, it's allowed to be feeded by Cold Storage if // available. \"AllowUnfreeze\" : false , \"Ipfs\" : { // AddTimeout is an upper bound on adding data to IPFS node from // the network before failing. \"AddTimeout\" : 30 } }, // Cold has desired storing configuration in the Cold Storage. \"Cold\" : { // Enabled indicates that data will be saved in Cold storage. // If is switched from false->true, it will consider the other // attributes as the desired state of the data in this Storage. \"Enabled\" : true , // Filecoin describes the desired Filecoin configuration for a // Cid in the Filecoin network. \"Filecoin\" : { // RepFactor indicates the desired amount of active deals // with different miners to store the data. While making deals // the other attributes of FilConfig are considered for miner // selection. \"RepFactor\" : 1 , // DealDuration indicates the duration to be used when making // new deals. \"DealDuration\" : 1000 , // ExcludedMiners is a set of miner addresses won't be ever be // selected when making new deals, even if they comply to other // filters. \"ExcludedMiners\" : null , // TrustedMiners is a set of miner addresses which will be // forcibly used when making new deals. An empty/nil list // disables this feature. \"TrustedMiners\" : null , // CountryCodes indicates that new deals should select miners // on specific countries. \"CountryCodes\" : null , // Renew indicates deal-renewal configuration. \"Renew\" : { // Enabled indicates that deal-renewal is enabled for this // Cid. \"Enabled\" : false , // Threshold indicates how many epochs before expiring should // trigger deal renewal. e.g: 100 epoch before expiring. \"Threshold\" : 0 }, // Addr is the wallet address used to store the data in filecoin \"Addr\" : \"<unique>\" , \"MaxPrice\" : 0 } }, \"Repairable\" : false }","title":"Storage Config"},{"location":"powergate/cidconfig/#managing-storage-with-the-cidconfig","text":"Every FFS instance can manage how data is stored on IPFS and Filecoin using the CidConfig ( details below ). The CidConfig is a powerful tool to customize all the details of how you store data on Filecoin, make it available over IPFS, enforce replication, manage expiring deals, and more.","title":"Managing Storage with the CidConfig"},{"location":"powergate/cidconfig/#setting-the-cidconfig","text":"In every Powergate deployment there are three ways to manage CidConfigs throughout the system. The FFS instance default CidConfig. This is initially set by the system default CidConfig. It can be modified by the FFS instance owner after creation. The storage request CidConfig. This will use the FFS instance default, but a custom CidConfig can also be supplied at request time. A storage update CidConfig. Any CidConfigs attached to existing stored data can be updated with a new CidConfig. The FFS instance will then work to modify the way data is stored to match the new configuration","title":"Setting the CidConfig"},{"location":"powergate/cidconfig/#get-the-default-cidconfig-of-an-ffs-instance","text":"View the current default CidConfig of an FFS instance. pow ffs config default -t <token>","title":"Get the default CidConfig of an FFS instance"},{"location":"powergate/cidconfig/#set-the-default-cidconfig-of-an-ffs-instance","text":"To set the default config to one stored in new-config.json . pow ffs config set new-config.json -t <token>","title":"Set the default CidConfig of an FFS instance"},{"location":"powergate/cidconfig/#set-a-custom-cidconfig-at-storage-time","text":"You can provide a flag ( -c ) to include a custom CidConfig for a new storage request. Storage requests without a custom CidConfig will use the instance default storage config. pow ffs push <cid> -t <token> -c custom-config.json","title":"Set a custom CidConfig at storage time"},{"location":"powergate/cidconfig/#get-the-cidconfig-of-previously-stored-data","text":"To pull the CidConfig associated with data already managed by the FFS instance, use the of the stored data. pow ffs pull <cid> -t <token>","title":"Get the CidConfig of previously stored data"},{"location":"powergate/cidconfig/#update-the-cidconfig-of-existing-data","text":"To update the CidConfig of data already stored and managed by the Powergate with a new config stored in updated-config.json . This command requires the override flag ( -o ) to confirm that you understand that the command will replace an existing config. pow ffs push <cid> -t <token> -o -c updated-config.json","title":"Update the CidConfig of existing data"},{"location":"powergate/cidconfig/#cidconfig-details","text":"Here is an example of the default CidConfig . { // Hot has this desired storing configuration in Hot Storage. \"Hot\" : { // Enable indicates if Cid data is stored. If true, it will // consider further configurations to execute actions. \"Enabled\" : true , // AllowUnfreeze indicates that if data isn't available in the // Hot Storage, it's allowed to be feeded by Cold Storage if // available. \"AllowUnfreeze\" : false , \"Ipfs\" : { // AddTimeout is an upper bound on adding data to IPFS node from // the network before failing. \"AddTimeout\" : 30 } }, // Cold has desired storing configuration in the Cold Storage. \"Cold\" : { // Enabled indicates that data will be saved in Cold storage. // If is switched from false->true, it will consider the other // attributes as the desired state of the data in this Storage. \"Enabled\" : true , // Filecoin describes the desired Filecoin configuration for a // Cid in the Filecoin network. \"Filecoin\" : { // RepFactor indicates the desired amount of active deals // with different miners to store the data. While making deals // the other attributes of FilConfig are considered for miner // selection. \"RepFactor\" : 1 , // DealDuration indicates the duration to be used when making // new deals. \"DealDuration\" : 1000 , // ExcludedMiners is a set of miner addresses won't be ever be // selected when making new deals, even if they comply to other // filters. \"ExcludedMiners\" : null , // TrustedMiners is a set of miner addresses which will be // forcibly used when making new deals. An empty/nil list // disables this feature. \"TrustedMiners\" : null , // CountryCodes indicates that new deals should select miners // on specific countries. \"CountryCodes\" : null , // Renew indicates deal-renewal configuration. \"Renew\" : { // Enabled indicates that deal-renewal is enabled for this // Cid. \"Enabled\" : false , // Threshold indicates how many epochs before expiring should // trigger deal renewal. e.g: 100 epoch before expiring. \"Threshold\" : 0 }, // Addr is the wallet address used to store the data in filecoin \"Addr\" : \"<unique>\" , \"MaxPrice\" : 0 } }, \"Repairable\" : false }","title":"CidConfig Details"},{"location":"powergate/devnet/","text":"Filecoin Local Devnet \u00b6 Having a fully synced Lotus node can take a considerable amount of time and effort to maintain. The required effort is normal on live blockchain networks, but isn't ideal in some scenarios. Scenarios such as application development, testing, and continuous integration can be enhanced by having access to Lotus nodes and APIs that don't require connection to the live network. For those cases, we have built the devnet . Speed The devnet is tuned for speed. After you have the docker instances installed, starting the devnet should take under a minute and storing a file in a new deal should take about a minute with the default settings and faster with custom settings. The devnet runs a local devnet with a mock sector-builder. This enables fast deployment of a development Filecoin network containing miners with mocked sealing but the rest of the network logic remaining the same as that of the production Filecoin network. The miners are configured to accept and store all incoming deals. Configurable Depending on your use case you can change settings such as block generation speed and sector sizes. For CI environments you may set block production speeds to the order of ~100ms and disable --bigsectors . This devnet setup would be optimized for minimum CPU usage and very fast chain progress, which can confirm deals in seconds. If you require more realistic scenarios (e.g. during product demos), you can change to block production speed to ~1s and enable --bigsectors . This would progress deal slow enough that you can observe updates in the status of confirmed deals at the rate of ~1 minute and also store larger files if required. Production compatible storage The devnet is designed so that you can build and test your system quickly but function the exact same way as the production Filecoin network, except faster and entirely local. The devnet supports both 2KiB and 512MiB sectors, and the speed of block production is configurable. For advanced features, refer to the devnet Readme . Devnet Miners \u00b6 Miners are generated deterministically when you start the devnet. If you run the devnet with a single miner, the miner's address will be t01000 . If you start the devnet with two miners, the addresses will be t01000 and t01001 . And so on. When running the devnet within the Powergate, you can also fetch miner details from the miner API endpoints and CLI. Getting Started \u00b6 There are a few resources you'll need before you start running any nodes. Docker Desktop . In the examples below, you'll run node instances using local Docker containers. You can do the same with any Docker enabled system, but to get started we recommend Docker Desktop and the default configurations we provide. Powergate . If you run the devnet as part of the Powergate, you should get the latest version of the Powergate source code. Golang . Building the Powergate CLI from code requires that you can run commands with Go. Other sections of the tutorials below don't have any Go requirement. Devnet with Powergate \u00b6 If you're interested in running Powergate to experiment with the CLI or APIs, the fastest way is to replace the Lotus client dependency with a running devnet. This will run the Powergate on a Lotus client connected to an embedded network of miners. Installation \u00b6 Clone the Powergate and cd into the project git clone git@github.com:textileio/powergate.git cd powergate Setup \u00b6 A default setup is available in a docker-compose configuration shipped with the Powergate. With the default setup, you will run Powergate connected to a local devnet with 512Mib sectors and instantly available gRPC API or CLI that don't require any extra config flags \ud83c\udf8a Run the docker-compose Docker files for the Powergate are all contained in the folder, /docker . cd docker make devnet If this is your first time running the Powergate, Docker will download the required instances before any Powergate setup begins. Downloads are dependent on your bandwidth and may take a few minutes , but wont be required for subsequent runs of the Powergate. Once running, you will begin to see log outputs, including those of the embedded miner. lotus_1 | 2020 -05-29T20:35:08.644Z WARN miner miner/miner.go:177 \\ mined block in the past { \"block-time\" : \"2009-01-01T04:44:30.000Z\" , \\ \"time\" : \"2020-05-29T20:35:08.644Z\" , \"duration\" : 359999438 .64444387 } When complete, you will have a fully functional Powergate ( powd ), a Lotus devnet, and an IPFS node wired correctly together to start using. Create a deal and store a file \u00b6 Now that your Powergate is running on devnet, all the CLI and API commands are the same as using it in production mode, just your deals will store faster (and disappear when you delete the devnet). Install the CLI From the root of the powergate repo, you can build the CLI from the latest code. This will install the Powergate CLI, pow , on your machine. make build Test your installation. pow --help Create an FFS instance FFS is the most common API for interacting with the Powergate. To use the API, you must first create an empty FFS instance, which will, Create a new wallet address on Lotus. You can configure the Powergate to automatically fund new wallets from a master address. Track and manage deals associated with that address in the Powergate FFS. Create an API token for using that FFS (and address) over the Powergate API. pow ffs create Success Instance created with id 0ac0fb4d-581c-4276-bd90-a9aa30dd4cb4 and token 883f57b1-4e66-47f8-b291-7cf8b10f6370 Generate a CID for your file on IPFS To store data on the cold layer (Filecoin), you first need to make it available on IPFS. You can do that quickly by using the Powergate to temporarily add it to the embedded IPFS node. pow ffs addToHot -t 883f57b1-4e66-47f8-b291-7cf8b10f6370 myfile Success Success! Added file to FFS hot storage with cid: QmYaAK8SSsKJsJdtahCbUe7MZzQdkPBybFCcQJJ3dKZpfm Note: addToHot does not store your data in the Powergate FFS. It simply caches your data in the IPFS node in preparation for being stored in the Powergate FFS in the following steps. This is technically equivalent to ipfs add , which is adding data without pinning it. Add environmental variable (optional) For the rest of the commands, the --token is used to scope the requests to the FFS instance we created. You can skip setting the --token flag on every command by adding your new token as an environmental variable. We won't do this and our following examples will continue to use the --token flag. export POW_TOKEN = 883f57b1-4e66-47f8-b291-7cf8b10f6370 Push a CidConfig How the Powergate manages each file stored in the FFS is defined by a CidConfig . To tell the Powergate to start managing a new file by moving it from the cached state we created above to the Hot and/or Cold layers, we must push a new CidConfig for the CID we generated above. Every FFS instance has a default CidConfig that will be used for every new deal unless overridden. \u276f pow ffs push --watch --token 883f57b1-4e66-47f8-b291-7cf8b10f6370 QmYaAK8SSsKJsJdtahCbUe7MZzQdkPBybFCcQJJ3dKZpfm Success Success! Pushed cid config for QmYaAK8SSsKJsJdtahCbUe7MZzQdkPBybFCcQJJ3dKZpfm to FFS with job id: 966dcb44-9ef4-4d2a-9c90-a8103c77c354 JOB ID STATUS 966dcb44-9ef4-4d2a-9c90-a8103c77c354 Success Retrieve file from network Finally, you can verify that the file was stored on the devnet by making a request to get it back out. \u276f pow ffs get -t 883f57b1-4e66-47f8-b291-7cf8b10f6370 QmYaAK8SSsKJsJdtahCbUe7MZzQdkPBybFCcQJJ3dKZpfm myfile2 Success Success! Data written to myfile2 Devnet with Lotus Client \u00b6 You can run the devnet to make use of the Lotus Client with all the benefits described in the introduction but no Powergate or IPFS components. Run from Docker image \u00b6 You can run devnet with the Docker image we maintain. Running the image is just a single line. docker run --name texdevnet -e TEXLOTUSDEVNET_SPEED = 1500 \\ -e TEXLOTUSDEVNET_BIGSECTORS = true -p 1234 :7777 \\ -v /tmp/import:/tmp/import textile/lotus-devnet After running the container, the Lotus API endpoint is available at the default port which lets you use the Lotus CLI without any extra configuration. Recall that devnets should be used as ephemeral networks, so be sure to stop and remove the texdevnet container if you re-rerun the above command again. If you plan to use the ClientImport API or lotus client import command, your target file to import should be in the /tmp/import path on your host machine. This folder is bound to the docker image and the devnet, so the Lotus node can find it under the same path. Finally, notice that the above command doesn't specify the textile/lotus-devnet tag, so it's recommended that you consider updating your cached latest tag. Configuration parameters In the above we use the environmental variables to set the speed and bigsectors flags. The complete mapping of options is, TEXLOTUSDEVNET_SPEED: time in milliseconds of blocks/tipset generation. TEXLOTUSDEVNET_BIGSECTORS: If true, the devnet will run on 512Mib sectors, but 2Kib otherwise. TEXLOTUSDEVNET_NUMMINERS: The number of miners in the devnet. This is an experimental feature, which seems stable for <=3. TEXLOTUSDEVNET_IPFSADDR: Optional multiaddr of an IPFS node to enable the Lotus node be connected to an IPFS node to avoid importing deals data, and storing retrievals. Run from source code \u00b6 Requirements Devnet . If you run the devnet with a stand-alone Lotus node, you should get the latest version of the devnet source code. Installation \u00b6 Clone the lotus-devnet repo and cd into the project git clone git@github.com:textileio/lotus-devnet.git cd lotus-devnet Setup \u00b6 Install the dependencies: make build Run the devnet with: go run main.go If you've previously compiled a prior version of lotus-devnet , running make clean is recommended before building again. For full configuration options, see the project Readme","title":"Run Devnet"},{"location":"powergate/devnet/#filecoin-local-devnet","text":"Having a fully synced Lotus node can take a considerable amount of time and effort to maintain. The required effort is normal on live blockchain networks, but isn't ideal in some scenarios. Scenarios such as application development, testing, and continuous integration can be enhanced by having access to Lotus nodes and APIs that don't require connection to the live network. For those cases, we have built the devnet . Speed The devnet is tuned for speed. After you have the docker instances installed, starting the devnet should take under a minute and storing a file in a new deal should take about a minute with the default settings and faster with custom settings. The devnet runs a local devnet with a mock sector-builder. This enables fast deployment of a development Filecoin network containing miners with mocked sealing but the rest of the network logic remaining the same as that of the production Filecoin network. The miners are configured to accept and store all incoming deals. Configurable Depending on your use case you can change settings such as block generation speed and sector sizes. For CI environments you may set block production speeds to the order of ~100ms and disable --bigsectors . This devnet setup would be optimized for minimum CPU usage and very fast chain progress, which can confirm deals in seconds. If you require more realistic scenarios (e.g. during product demos), you can change to block production speed to ~1s and enable --bigsectors . This would progress deal slow enough that you can observe updates in the status of confirmed deals at the rate of ~1 minute and also store larger files if required. Production compatible storage The devnet is designed so that you can build and test your system quickly but function the exact same way as the production Filecoin network, except faster and entirely local. The devnet supports both 2KiB and 512MiB sectors, and the speed of block production is configurable. For advanced features, refer to the devnet Readme .","title":"Filecoin Local Devnet"},{"location":"powergate/devnet/#devnet-miners","text":"Miners are generated deterministically when you start the devnet. If you run the devnet with a single miner, the miner's address will be t01000 . If you start the devnet with two miners, the addresses will be t01000 and t01001 . And so on. When running the devnet within the Powergate, you can also fetch miner details from the miner API endpoints and CLI.","title":"Devnet Miners"},{"location":"powergate/devnet/#getting-started","text":"There are a few resources you'll need before you start running any nodes. Docker Desktop . In the examples below, you'll run node instances using local Docker containers. You can do the same with any Docker enabled system, but to get started we recommend Docker Desktop and the default configurations we provide. Powergate . If you run the devnet as part of the Powergate, you should get the latest version of the Powergate source code. Golang . Building the Powergate CLI from code requires that you can run commands with Go. Other sections of the tutorials below don't have any Go requirement.","title":"Getting Started"},{"location":"powergate/devnet/#devnet-with-powergate","text":"If you're interested in running Powergate to experiment with the CLI or APIs, the fastest way is to replace the Lotus client dependency with a running devnet. This will run the Powergate on a Lotus client connected to an embedded network of miners.","title":"Devnet with Powergate"},{"location":"powergate/devnet/#installation","text":"Clone the Powergate and cd into the project git clone git@github.com:textileio/powergate.git cd powergate","title":"Installation"},{"location":"powergate/devnet/#setup","text":"A default setup is available in a docker-compose configuration shipped with the Powergate. With the default setup, you will run Powergate connected to a local devnet with 512Mib sectors and instantly available gRPC API or CLI that don't require any extra config flags \ud83c\udf8a Run the docker-compose Docker files for the Powergate are all contained in the folder, /docker . cd docker make devnet If this is your first time running the Powergate, Docker will download the required instances before any Powergate setup begins. Downloads are dependent on your bandwidth and may take a few minutes , but wont be required for subsequent runs of the Powergate. Once running, you will begin to see log outputs, including those of the embedded miner. lotus_1 | 2020 -05-29T20:35:08.644Z WARN miner miner/miner.go:177 \\ mined block in the past { \"block-time\" : \"2009-01-01T04:44:30.000Z\" , \\ \"time\" : \"2020-05-29T20:35:08.644Z\" , \"duration\" : 359999438 .64444387 } When complete, you will have a fully functional Powergate ( powd ), a Lotus devnet, and an IPFS node wired correctly together to start using.","title":"Setup"},{"location":"powergate/devnet/#create-a-deal-and-store-a-file","text":"Now that your Powergate is running on devnet, all the CLI and API commands are the same as using it in production mode, just your deals will store faster (and disappear when you delete the devnet). Install the CLI From the root of the powergate repo, you can build the CLI from the latest code. This will install the Powergate CLI, pow , on your machine. make build Test your installation. pow --help Create an FFS instance FFS is the most common API for interacting with the Powergate. To use the API, you must first create an empty FFS instance, which will, Create a new wallet address on Lotus. You can configure the Powergate to automatically fund new wallets from a master address. Track and manage deals associated with that address in the Powergate FFS. Create an API token for using that FFS (and address) over the Powergate API. pow ffs create Success Instance created with id 0ac0fb4d-581c-4276-bd90-a9aa30dd4cb4 and token 883f57b1-4e66-47f8-b291-7cf8b10f6370 Generate a CID for your file on IPFS To store data on the cold layer (Filecoin), you first need to make it available on IPFS. You can do that quickly by using the Powergate to temporarily add it to the embedded IPFS node. pow ffs addToHot -t 883f57b1-4e66-47f8-b291-7cf8b10f6370 myfile Success Success! Added file to FFS hot storage with cid: QmYaAK8SSsKJsJdtahCbUe7MZzQdkPBybFCcQJJ3dKZpfm Note: addToHot does not store your data in the Powergate FFS. It simply caches your data in the IPFS node in preparation for being stored in the Powergate FFS in the following steps. This is technically equivalent to ipfs add , which is adding data without pinning it. Add environmental variable (optional) For the rest of the commands, the --token is used to scope the requests to the FFS instance we created. You can skip setting the --token flag on every command by adding your new token as an environmental variable. We won't do this and our following examples will continue to use the --token flag. export POW_TOKEN = 883f57b1-4e66-47f8-b291-7cf8b10f6370 Push a CidConfig How the Powergate manages each file stored in the FFS is defined by a CidConfig . To tell the Powergate to start managing a new file by moving it from the cached state we created above to the Hot and/or Cold layers, we must push a new CidConfig for the CID we generated above. Every FFS instance has a default CidConfig that will be used for every new deal unless overridden. \u276f pow ffs push --watch --token 883f57b1-4e66-47f8-b291-7cf8b10f6370 QmYaAK8SSsKJsJdtahCbUe7MZzQdkPBybFCcQJJ3dKZpfm Success Success! Pushed cid config for QmYaAK8SSsKJsJdtahCbUe7MZzQdkPBybFCcQJJ3dKZpfm to FFS with job id: 966dcb44-9ef4-4d2a-9c90-a8103c77c354 JOB ID STATUS 966dcb44-9ef4-4d2a-9c90-a8103c77c354 Success Retrieve file from network Finally, you can verify that the file was stored on the devnet by making a request to get it back out. \u276f pow ffs get -t 883f57b1-4e66-47f8-b291-7cf8b10f6370 QmYaAK8SSsKJsJdtahCbUe7MZzQdkPBybFCcQJJ3dKZpfm myfile2 Success Success! Data written to myfile2","title":"Create a deal and store a file"},{"location":"powergate/devnet/#devnet-with-lotus-client","text":"You can run the devnet to make use of the Lotus Client with all the benefits described in the introduction but no Powergate or IPFS components.","title":"Devnet with Lotus Client"},{"location":"powergate/devnet/#run-from-docker-image","text":"You can run devnet with the Docker image we maintain. Running the image is just a single line. docker run --name texdevnet -e TEXLOTUSDEVNET_SPEED = 1500 \\ -e TEXLOTUSDEVNET_BIGSECTORS = true -p 1234 :7777 \\ -v /tmp/import:/tmp/import textile/lotus-devnet After running the container, the Lotus API endpoint is available at the default port which lets you use the Lotus CLI without any extra configuration. Recall that devnets should be used as ephemeral networks, so be sure to stop and remove the texdevnet container if you re-rerun the above command again. If you plan to use the ClientImport API or lotus client import command, your target file to import should be in the /tmp/import path on your host machine. This folder is bound to the docker image and the devnet, so the Lotus node can find it under the same path. Finally, notice that the above command doesn't specify the textile/lotus-devnet tag, so it's recommended that you consider updating your cached latest tag. Configuration parameters In the above we use the environmental variables to set the speed and bigsectors flags. The complete mapping of options is, TEXLOTUSDEVNET_SPEED: time in milliseconds of blocks/tipset generation. TEXLOTUSDEVNET_BIGSECTORS: If true, the devnet will run on 512Mib sectors, but 2Kib otherwise. TEXLOTUSDEVNET_NUMMINERS: The number of miners in the devnet. This is an experimental feature, which seems stable for <=3. TEXLOTUSDEVNET_IPFSADDR: Optional multiaddr of an IPFS node to enable the Lotus node be connected to an IPFS node to avoid importing deals data, and storing retrievals.","title":"Run from Docker image"},{"location":"powergate/devnet/#run-from-source-code","text":"Requirements Devnet . If you run the devnet with a stand-alone Lotus node, you should get the latest version of the devnet source code.","title":"Run from source code"},{"location":"powergate/devnet/#installation_1","text":"Clone the lotus-devnet repo and cd into the project git clone git@github.com:textileio/lotus-devnet.git cd lotus-devnet","title":"Installation"},{"location":"powergate/devnet/#setup_1","text":"Install the dependencies: make build Run the devnet with: go run main.go If you've previously compiled a prior version of lotus-devnet , running make clean is recommended before building again. For full configuration options, see the project Readme","title":"Setup"},{"location":"powergate/ffs/","text":"Storing Data with the FFS \u00b6 The Filecoin File System API (FFS) manages all the necessary state and capabilities to provide multi-tiered file storage through the Powergate. The FFS is the primary API for storing and retrieving data, tracking long-term deals on Filecoin, and allowing data persisted on Filecoin to be available on IPFS. To start using the FFS APIs you must first create an FFS Instance . FFS Instance \u00b6 The FFS API is scoped to one or more Filecoin wallet addresses. So to start accessing the FFS API, you must init a new instance at which time the Powergate will: Create a new default wallet address for the FFS Instance. You can configure the Powergate to automatically fund new wallets from a master address. Create a new API token linked to the FFS Instance. Enable access to the FFS API through the use of the supplied token. Anytime you use the FFS API (including use through the CLI), you will supply the token to indicate which FFS Instance your requests are targeting. Since each FFS Instance has its own address, it has its own balance and therefor limits on the Filecoin network. Create an FFS Instance Using the Powergate CLI, you can create new FFS instances easily. pow ffs create Success Instance created with id 0ac0fb4d-581c-4276-bd90-a9aa30dd4cb4 and token 883f57b1-4e66-47f8-b291-7cf8b10f6370 Data storage \u00b6 Powergate provides you API access to a multi-tiered storage system built on IPFS and Filecoin. In many places, we refer to these two tiers of storage as Hot (IFPS) and Cold (Filecoin). Data stored in the Powergate Hot layer is available to the IPFS network (or private network). Data stored only in the Cold layer can be available to the IPFS network, but will require a retrieval deal to pull it from Cold and add it to Hot. This mirrors multi-tiered storage often deployed with a hot storage layer in memory and a cold storage layer on disk . You have a lot of control over how each file is managed on Hot and Cold storage through the use of the Storage CidConfig . Learn more \u00b6 The FFS does a lot of work out of the box. If you'd like to learn more about the components, design, and capabilities of the FFS, we encourage you to read the FFS Design document .","title":"Store Data"},{"location":"powergate/ffs/#storing-data-with-the-ffs","text":"The Filecoin File System API (FFS) manages all the necessary state and capabilities to provide multi-tiered file storage through the Powergate. The FFS is the primary API for storing and retrieving data, tracking long-term deals on Filecoin, and allowing data persisted on Filecoin to be available on IPFS. To start using the FFS APIs you must first create an FFS Instance .","title":"Storing Data with the FFS"},{"location":"powergate/ffs/#ffs-instance","text":"The FFS API is scoped to one or more Filecoin wallet addresses. So to start accessing the FFS API, you must init a new instance at which time the Powergate will: Create a new default wallet address for the FFS Instance. You can configure the Powergate to automatically fund new wallets from a master address. Create a new API token linked to the FFS Instance. Enable access to the FFS API through the use of the supplied token. Anytime you use the FFS API (including use through the CLI), you will supply the token to indicate which FFS Instance your requests are targeting. Since each FFS Instance has its own address, it has its own balance and therefor limits on the Filecoin network. Create an FFS Instance Using the Powergate CLI, you can create new FFS instances easily. pow ffs create Success Instance created with id 0ac0fb4d-581c-4276-bd90-a9aa30dd4cb4 and token 883f57b1-4e66-47f8-b291-7cf8b10f6370","title":"FFS Instance"},{"location":"powergate/ffs/#data-storage","text":"Powergate provides you API access to a multi-tiered storage system built on IPFS and Filecoin. In many places, we refer to these two tiers of storage as Hot (IFPS) and Cold (Filecoin). Data stored in the Powergate Hot layer is available to the IPFS network (or private network). Data stored only in the Cold layer can be available to the IPFS network, but will require a retrieval deal to pull it from Cold and add it to Hot. This mirrors multi-tiered storage often deployed with a hot storage layer in memory and a cold storage layer on disk . You have a lot of control over how each file is managed on Hot and Cold storage through the use of the Storage CidConfig .","title":"Data storage"},{"location":"powergate/ffs/#learn-more","text":"The FFS does a lot of work out of the box. If you'd like to learn more about the components, design, and capabilities of the FFS, we encourage you to read the FFS Design document .","title":"Learn more"},{"location":"threads/","text":"Getting Started \u00b6 ThreadDB is a p2p database built on IPFS and Libp2p . Together, the Threads Protocol and Database provide an alternative architecture for data on the web. ThreadDB aims to help power a new generation of web technologies by combining a novel use of event sourcing, Interplanetary Linked Data ( IPLD ), and access control to provide a distributed, scalable, and flexible database solution for decentralized applications. Developer API \u00b6 ThreadDB is designed to be simple enough for any developer to start using. The API will feel familiar to developers who have worked with technologies like MongoDB. The first three concepts a developer will encounter with ThreadDB are Databases , Collections , and Instances . The organization is simple. Instances are the individual records you create, update, or delete. Instances are stored in a Collection. Collections have one or many Schemas and can only store Instances that match one of those Schemas. Databases can store many Collections. Collections are similar to Tables in other databases. A Thread-based Database is tied to a single Thread (with associated Thread ID). import { Database , JSONSchema , FilterQuery } from '@textile/threads-database' import { ThreadID } from '@textile/threads-id' To start a new, empty database is simple. A new Level Datastore is used as the backing store by default if no datastore is explicitly supplied. See the doc-strings for the Database.constructor for further options. By default, a ThreadDB will connect with a local go-threads Threads Daemon. See the go-threads for details on getting started with local development. The Threads Daemon may be helpful to developers that aim to build their own Thread Services, host replication services, or test advanced Thread usage. The Threads Daemon ( threadsd ) is provided as an installable binary with every release of Threads . Alternatively, it is possible to connect with a remote daemon by specifying the networking component of the Database ( See more for details on connecting to hosted remote services). const db = new Database () // Uses a level datastore by default Next, we simply start the database, and we are ready to take action. Here, we are explicitly providing an 'existing' ThreadID. But default, a random ThreadID will be used. See the doc-strings for Database.open for further options. const threadID = ThreadID . fromRandom () await db . open ({ threadID }) console . log ( db . threadID . toString ()) Collections \u00b6 To handle different data structures, a Database contains Collections, each of which are defined by a json-schema.org schema . These schemas define the 'shape' of Collection Instances. Collections are similar to Tables in other databases. Ultimately, a Collection is a single document store with a set of APIs to make it feel like a local database table . Collections can be created from an existing Schema. // Define a simple person schema const schema : JSONSchema = { $schema : 'http://json-schema.org/draft-07/schema#' , title : 'Person' , type : 'object' , properties : { _id : { type : 'string' }, name : { type : 'string' }, age : { type : 'number' , minimum : 0 , exclusiveMaximum : 100 , }, }, } const Person = await db . newCollection ( 'Person' , schema ) Or from an existing object/instance. const obj = { _id : '' , // All collections have an _id field team : '' , name : '' , points : 0 , } const Player = await db . newCollectionFromObject ( 'Player' , obj ) Instances \u00b6 Instances are the objects you store in your Collection. Instances are JSON documents with schemas that match those defined in your Collection. Updates to an Instance are driven by JSON Patch semantics by default, but will be made to support other types (CRDT-driven documents for instance) in the future (some of which are already under active development). Creating and manipulating them is simple. const beth = new Player ({ _id : '' , name : 'beth' }) // Not yet persisted await beth . save () // Persist changes to db // Modify the `beth` instance beth . points = 1 await beth . save () // Save changes // Modify it again beth . team = 'Astronauts' beth . points = 2 // Save it from the Collection await Player . save ( beth ) // Delete it from the Collection await Player . delete ( beth . _id ) // etc! Query \u00b6 Each Threads implementation supports query and look-up capabilities such as insert , findOne , has , and more. ThreadDB also supports the MongoDB query language . In the JavaScript library, you might write queries like the following. await Player . insert ( { _id : '' , points : 11 , team : 'Astronauts' , name : 'beth' }, { _id : '' , points : 1 , team : 'Astronauts' , name : 'jim' }, { _id : '' , points : 18 , team : 'Astronauts' , name : 'issac' }, { _id : '' , points : 7 , team : 'Astronauts' , name : 'beth' }, ) // Setup a query const query = { $or : [ { points : { $gt : 10 } }, { name : 'jim' }, ] } const all = Player . find ( query , { sort : { points : - 1 } }) Queries return AsyncIterableIterators , so you can loop over them and take appropriate action. import { collect } from 'streaming-iterables' for ( const { key , value } of await collect ( all )) { console . log ( ` ${ key . toString () } : ${ value . name } ` ) } Listen \u00b6 A Database is also an Event Emitter , and listeners can subscribe to events using 'wildcard' syntax. The following database manipulations could be observed via the following simple listener. const _ = db . on ( '**' , ( update : any ) => { console . log ( update ) }) Multi-user Databases \u00b6 Everything above just looks like a database, so what's a Thread? ThreadDB combines the storage and management of data (the Database ) with networking, access control, and replication over IPFS using the Threads Protocol . The Threads protocol has been extensively documented in the whitepaper , but in short, Threads use private-key encryption to manage both security and identity among multiple parties that can access or edit the same Database. Access-control \u00b6 ThreadDB uses a modular role-based access control system that will allow access control lists (ACLs) to be declared in a wide-variety of ways. ACLs are in active development and you can follow the development here . Identity \u00b6 ThreadDB allows you to handle user identities (for access control and security/encryption) in the best way for your app and your users. In order to handle multiple peers collaborating on a single database, as well as the ability to handle storage on behalf of a user, ThreadDB expects a simple Identity interface for singing and validating database updates. See the Hub documentation on user identities for details. Replication with the Hub \u00b6 ThreadDB has been designed to support trustless peers on the network to provide services that improve or enhance performance and experience for end-users. The Hub offers Thread Services for relay, replication, and backup that you can add for your users in a couple of minutes. You can learn more about Identity, Access Control, and other advanced topics, in the Hub documentation. Connect to the Hub \u00b6 Create an Account Create an App Token Add the Textile Hub Library to your App Pinning, Relay, and Replication \u00b6 Thread Services (e.g. pinning encrypted data on IPFS and helping multiple peers relay updates across the network) can be built and deployed to the network using go-threads . Textile offers a number of these functions through the Hub. Attaching the Hub to your databases will allow you to deliver a high-quality user-experience. Installation \u00b6 ThreadDB can be used from many different languages and has libraries written in Javascript and Go. Find documentation on each of those Libraries below. JavaScript Add Threads to NodeJS, React Native or browser apps. Golang Use Threads in Go or compile to many other platforms. Advanced Details \u00b6 The protocols and design of ThreadDB can be explored in detail in the whitepaper: A protocol & event-sourced database for decentralized user-siloed data . For further technical details. the reference implementation of Threads is written in Go and the full implementation details can be found on godocs (jump to go-threads client ).","title":"Introduction"},{"location":"threads/#getting-started","text":"ThreadDB is a p2p database built on IPFS and Libp2p . Together, the Threads Protocol and Database provide an alternative architecture for data on the web. ThreadDB aims to help power a new generation of web technologies by combining a novel use of event sourcing, Interplanetary Linked Data ( IPLD ), and access control to provide a distributed, scalable, and flexible database solution for decentralized applications.","title":"Getting Started"},{"location":"threads/#developer-api","text":"ThreadDB is designed to be simple enough for any developer to start using. The API will feel familiar to developers who have worked with technologies like MongoDB. The first three concepts a developer will encounter with ThreadDB are Databases , Collections , and Instances . The organization is simple. Instances are the individual records you create, update, or delete. Instances are stored in a Collection. Collections have one or many Schemas and can only store Instances that match one of those Schemas. Databases can store many Collections. Collections are similar to Tables in other databases. A Thread-based Database is tied to a single Thread (with associated Thread ID). import { Database , JSONSchema , FilterQuery } from '@textile/threads-database' import { ThreadID } from '@textile/threads-id' To start a new, empty database is simple. A new Level Datastore is used as the backing store by default if no datastore is explicitly supplied. See the doc-strings for the Database.constructor for further options. By default, a ThreadDB will connect with a local go-threads Threads Daemon. See the go-threads for details on getting started with local development. The Threads Daemon may be helpful to developers that aim to build their own Thread Services, host replication services, or test advanced Thread usage. The Threads Daemon ( threadsd ) is provided as an installable binary with every release of Threads . Alternatively, it is possible to connect with a remote daemon by specifying the networking component of the Database ( See more for details on connecting to hosted remote services). const db = new Database () // Uses a level datastore by default Next, we simply start the database, and we are ready to take action. Here, we are explicitly providing an 'existing' ThreadID. But default, a random ThreadID will be used. See the doc-strings for Database.open for further options. const threadID = ThreadID . fromRandom () await db . open ({ threadID }) console . log ( db . threadID . toString ())","title":"Developer API"},{"location":"threads/#collections","text":"To handle different data structures, a Database contains Collections, each of which are defined by a json-schema.org schema . These schemas define the 'shape' of Collection Instances. Collections are similar to Tables in other databases. Ultimately, a Collection is a single document store with a set of APIs to make it feel like a local database table . Collections can be created from an existing Schema. // Define a simple person schema const schema : JSONSchema = { $schema : 'http://json-schema.org/draft-07/schema#' , title : 'Person' , type : 'object' , properties : { _id : { type : 'string' }, name : { type : 'string' }, age : { type : 'number' , minimum : 0 , exclusiveMaximum : 100 , }, }, } const Person = await db . newCollection ( 'Person' , schema ) Or from an existing object/instance. const obj = { _id : '' , // All collections have an _id field team : '' , name : '' , points : 0 , } const Player = await db . newCollectionFromObject ( 'Player' , obj )","title":"Collections"},{"location":"threads/#instances","text":"Instances are the objects you store in your Collection. Instances are JSON documents with schemas that match those defined in your Collection. Updates to an Instance are driven by JSON Patch semantics by default, but will be made to support other types (CRDT-driven documents for instance) in the future (some of which are already under active development). Creating and manipulating them is simple. const beth = new Player ({ _id : '' , name : 'beth' }) // Not yet persisted await beth . save () // Persist changes to db // Modify the `beth` instance beth . points = 1 await beth . save () // Save changes // Modify it again beth . team = 'Astronauts' beth . points = 2 // Save it from the Collection await Player . save ( beth ) // Delete it from the Collection await Player . delete ( beth . _id ) // etc!","title":"Instances"},{"location":"threads/#query","text":"Each Threads implementation supports query and look-up capabilities such as insert , findOne , has , and more. ThreadDB also supports the MongoDB query language . In the JavaScript library, you might write queries like the following. await Player . insert ( { _id : '' , points : 11 , team : 'Astronauts' , name : 'beth' }, { _id : '' , points : 1 , team : 'Astronauts' , name : 'jim' }, { _id : '' , points : 18 , team : 'Astronauts' , name : 'issac' }, { _id : '' , points : 7 , team : 'Astronauts' , name : 'beth' }, ) // Setup a query const query = { $or : [ { points : { $gt : 10 } }, { name : 'jim' }, ] } const all = Player . find ( query , { sort : { points : - 1 } }) Queries return AsyncIterableIterators , so you can loop over them and take appropriate action. import { collect } from 'streaming-iterables' for ( const { key , value } of await collect ( all )) { console . log ( ` ${ key . toString () } : ${ value . name } ` ) }","title":"Query"},{"location":"threads/#listen","text":"A Database is also an Event Emitter , and listeners can subscribe to events using 'wildcard' syntax. The following database manipulations could be observed via the following simple listener. const _ = db . on ( '**' , ( update : any ) => { console . log ( update ) })","title":"Listen"},{"location":"threads/#multi-user-databases","text":"Everything above just looks like a database, so what's a Thread? ThreadDB combines the storage and management of data (the Database ) with networking, access control, and replication over IPFS using the Threads Protocol . The Threads protocol has been extensively documented in the whitepaper , but in short, Threads use private-key encryption to manage both security and identity among multiple parties that can access or edit the same Database.","title":"Multi-user Databases"},{"location":"threads/#access-control","text":"ThreadDB uses a modular role-based access control system that will allow access control lists (ACLs) to be declared in a wide-variety of ways. ACLs are in active development and you can follow the development here .","title":"Access-control"},{"location":"threads/#identity","text":"ThreadDB allows you to handle user identities (for access control and security/encryption) in the best way for your app and your users. In order to handle multiple peers collaborating on a single database, as well as the ability to handle storage on behalf of a user, ThreadDB expects a simple Identity interface for singing and validating database updates. See the Hub documentation on user identities for details.","title":"Identity"},{"location":"threads/#replication-with-the-hub","text":"ThreadDB has been designed to support trustless peers on the network to provide services that improve or enhance performance and experience for end-users. The Hub offers Thread Services for relay, replication, and backup that you can add for your users in a couple of minutes. You can learn more about Identity, Access Control, and other advanced topics, in the Hub documentation.","title":"Replication with the Hub"},{"location":"threads/#connect-to-the-hub","text":"Create an Account Create an App Token Add the Textile Hub Library to your App","title":"Connect to the Hub"},{"location":"threads/#pinning-relay-and-replication","text":"Thread Services (e.g. pinning encrypted data on IPFS and helping multiple peers relay updates across the network) can be built and deployed to the network using go-threads . Textile offers a number of these functions through the Hub. Attaching the Hub to your databases will allow you to deliver a high-quality user-experience.","title":"Pinning, Relay, and Replication"},{"location":"threads/#installation","text":"ThreadDB can be used from many different languages and has libraries written in Javascript and Go. Find documentation on each of those Libraries below.","title":"Installation"},{"location":"threads/#advanced-details","text":"The protocols and design of ThreadDB can be explored in detail in the whitepaper: A protocol & event-sourced database for decentralized user-siloed data . For further technical details. the reference implementation of Threads is written in Go and the full implementation details can be found on godocs (jump to go-threads client ).","title":"Advanced Details"},{"location":"tutorials/react-native-buckets/","text":"User Buckets from React Native \u00b6 The Hub gets really powerful when you allow your app users to leverage IPFS, IPNS, and ThreadDB from inside your applications. In this tutorial, we'll look at how you can let users author, own, and manage buckets right from a mobile app built in React Native. Click here to see an example app built with this tutorial . Preview video \u00b6 Install libraries \u00b6 Textile Libraries npm install --save @textile/hub @textile/threads-client @textile/threads-core @textile/threads-id We'll use the above combination of Textile libraries in our app below. rn-nodify npm install -D rn-nodeify We are going to use rn-nodify and a few other libraries it will install to manage adding Buffer , crypto , and some other tools to our JavaScript environment in React Native. Read about rn-nodify here . Next, you need to run, ./node_modules/.bin/rn-nodeify --install This will install a shim.js into the root of your file. You need to import shim.js at the top of your app's root file (typically index.js ), import './shim' ; This may need to be updated on future package changes, you can make this easier on yourself by adding a postinstall step to your package.json , as follows, \"scripts\" : { ... \"postinstall\" : \"./node_modules/.bin/rn-nodeify --install fs,path,process,buffer,crypto,stream,vm --hack\" } Dot env You will need to add API keys to your app. If you plan to store your sourcecode anywhere public, you should not store those keys publicly. In our example app, we use react-native-dotenv to manage our secrets. npm install --save react-native-dotenv Next, create a .env file in the root of your project. You can find an example .env in our example project here . Be certain that the .env is added to your .gitignore and note checked in with your code. The contents of .env will be, USER_API_SECRET = textile-hub-user-secret USER_API_KEY = textile-hub-user-group-key You can follow the instructions to generate a User Group Key and Secret here, API Access . If you have already generated keys, you can list them by executing hub keys ls . You'll add the values to your .env file on the right side of the equality sign. Typescript The rest of the JavaScript portions of the tutorial will be in TypeScript. You do not need to use TypeScript, but if you don't be sure to strip the typings from any code you copy below. Build your app \u00b6 Hint In the example app, we put all the ThreadDB and Bucket logic into a single component called checklist.ts . You can view that file for reference. Import Textile // Our secrets import { USER_API_SECRET , USER_API_KEY } from 'react-native-dotenv' ; // Database Query method import { Where } from '@textile/threads-client' ; // Buckets client and an API Context helper import { Buckets , Client , ThreadID } from '@textile/hub' ; // A basic Identity provider (PKI from Libp2p) import { Libp2pCryptoIdentity } from '@textile/threads-core' ; Register with remote API \u00b6 Next, we'll connect to the remote API using our Key and Secret. We do this so that the user can later push their bucket for remote persistence on IPFS and publishing on IPNS. db = await Client . withUserKey ({ key : USER_API_KEY , secret : USER_API_SECRET , type : 1 , }) Hint Read more about the Context tool in the Threads Introduction . Generate an Identity \u00b6 Read the basic libp2p identities tutorial now . const id = await Libp2pCryptoIdentity . fromRandom (); Here we are just using a Libp2p helper to generate a private-key identity for the user. Generate user Token \u00b6 await db . getToken ( id ); This will register the user with your remote Hub account, granting them the ability to push data to IPFS through Threads and Buckets. Connect Buckets \u00b6 Now that your user is setup and connected to your API on the Hub, you can start creating Buckets. First, setup a Bucket Client instance. const buckets = Buckets . withUserKey ({ key : USER_API_KEY , secret : USER_API_SECRET , type : 1 , }) In the above, we reuse the Context we already created in our ThreadDB Client because it contains the token, API keys, etc. List all Buckets const roots = await buckets . list (); const existing = roots . find (( bucket ) => bucket . name === 'files' ) Here, we list all the user's Buckets and determine if one exists called files . If it exists, we'll use its key if not, we'll create a new Bucket and key. let bucketKey = '' if ( existing ) { bucketKey = existing . key ; } else { const created = await buckets . init ( 'files' ); bucketKey = created . root ! . key ; } Push files to user Bucket \u00b6 Finally, let's push a simple file to the user's Bucket. In this example, we'll just create a simple HTML file that says, Hello world . const file = { path : '/index.html' , content : Buffer.from ( webpage ) } const raw = await buckets . pushPath ( bucketKey ! , 'index.html' , file ) List the Bucket links \u00b6 Finally, you can list the links to the file on IPFS, IPNS, ThreadDB, and HTTP. Now that the Bucket is created, keep in mind, each time you update the same Bucket for a user: replace the HTTP content. the Bucket head will get a new IPFS address. replace the IPNS content. be appended to the ThreadDB history. This give you a lot of options for how you build apps, deliver content, and do cool things for your users with their data. You can get each of the protocol addresses as follows. HTTP Address Textile give you and your users a public address for each Bucket created. They are created using the Bucket key and you can generate those as follows: https://${bucket-key}.textile.space IPFS Address The IPFS address is contained in the result of pushPath . const raw = await buckets . pushPath ( bucketKey ! , 'index.html' , file ) console . log ( raw . root ) IPNS Address The IPNS Address is always the same and is the Bucket key! If you want to see the Bucket over IPNS from a gateway, you can use the Textile gateway as follows: https://${bucket-key}.ipns.hub.textile.io/ ThreadDB Address You can generate a link to the Bucket with the user thread as follows: https://${thread-id}.thread.hub.textile.io/buckets/${this.state.bucket-key} Warning Remember that at this point in time, Buckets are entirely open, data is available to be viewed or downloaded by anyone your app or user share the link with. Code \u00b6 Check out a complete React Native project on GitHub that generates a user identity, Thread, and Bucket.","title":"Create User Buckets & Threads in React Native"},{"location":"tutorials/react-native-buckets/#user-buckets-from-react-native","text":"The Hub gets really powerful when you allow your app users to leverage IPFS, IPNS, and ThreadDB from inside your applications. In this tutorial, we'll look at how you can let users author, own, and manage buckets right from a mobile app built in React Native. Click here to see an example app built with this tutorial .","title":"User Buckets from React Native"},{"location":"tutorials/react-native-buckets/#preview-video","text":"","title":"Preview video"},{"location":"tutorials/react-native-buckets/#install-libraries","text":"Textile Libraries npm install --save @textile/hub @textile/threads-client @textile/threads-core @textile/threads-id We'll use the above combination of Textile libraries in our app below. rn-nodify npm install -D rn-nodeify We are going to use rn-nodify and a few other libraries it will install to manage adding Buffer , crypto , and some other tools to our JavaScript environment in React Native. Read about rn-nodify here . Next, you need to run, ./node_modules/.bin/rn-nodeify --install This will install a shim.js into the root of your file. You need to import shim.js at the top of your app's root file (typically index.js ), import './shim' ; This may need to be updated on future package changes, you can make this easier on yourself by adding a postinstall step to your package.json , as follows, \"scripts\" : { ... \"postinstall\" : \"./node_modules/.bin/rn-nodeify --install fs,path,process,buffer,crypto,stream,vm --hack\" } Dot env You will need to add API keys to your app. If you plan to store your sourcecode anywhere public, you should not store those keys publicly. In our example app, we use react-native-dotenv to manage our secrets. npm install --save react-native-dotenv Next, create a .env file in the root of your project. You can find an example .env in our example project here . Be certain that the .env is added to your .gitignore and note checked in with your code. The contents of .env will be, USER_API_SECRET = textile-hub-user-secret USER_API_KEY = textile-hub-user-group-key You can follow the instructions to generate a User Group Key and Secret here, API Access . If you have already generated keys, you can list them by executing hub keys ls . You'll add the values to your .env file on the right side of the equality sign. Typescript The rest of the JavaScript portions of the tutorial will be in TypeScript. You do not need to use TypeScript, but if you don't be sure to strip the typings from any code you copy below.","title":"Install libraries"},{"location":"tutorials/react-native-buckets/#build-your-app","text":"Hint In the example app, we put all the ThreadDB and Bucket logic into a single component called checklist.ts . You can view that file for reference. Import Textile // Our secrets import { USER_API_SECRET , USER_API_KEY } from 'react-native-dotenv' ; // Database Query method import { Where } from '@textile/threads-client' ; // Buckets client and an API Context helper import { Buckets , Client , ThreadID } from '@textile/hub' ; // A basic Identity provider (PKI from Libp2p) import { Libp2pCryptoIdentity } from '@textile/threads-core' ;","title":"Build your app"},{"location":"tutorials/react-native-buckets/#register-with-remote-api","text":"Next, we'll connect to the remote API using our Key and Secret. We do this so that the user can later push their bucket for remote persistence on IPFS and publishing on IPNS. db = await Client . withUserKey ({ key : USER_API_KEY , secret : USER_API_SECRET , type : 1 , }) Hint Read more about the Context tool in the Threads Introduction .","title":"Register with remote API"},{"location":"tutorials/react-native-buckets/#generate-an-identity","text":"Read the basic libp2p identities tutorial now . const id = await Libp2pCryptoIdentity . fromRandom (); Here we are just using a Libp2p helper to generate a private-key identity for the user.","title":"Generate an Identity"},{"location":"tutorials/react-native-buckets/#generate-user-token","text":"await db . getToken ( id ); This will register the user with your remote Hub account, granting them the ability to push data to IPFS through Threads and Buckets.","title":"Generate user Token"},{"location":"tutorials/react-native-buckets/#connect-buckets","text":"Now that your user is setup and connected to your API on the Hub, you can start creating Buckets. First, setup a Bucket Client instance. const buckets = Buckets . withUserKey ({ key : USER_API_KEY , secret : USER_API_SECRET , type : 1 , }) In the above, we reuse the Context we already created in our ThreadDB Client because it contains the token, API keys, etc. List all Buckets const roots = await buckets . list (); const existing = roots . find (( bucket ) => bucket . name === 'files' ) Here, we list all the user's Buckets and determine if one exists called files . If it exists, we'll use its key if not, we'll create a new Bucket and key. let bucketKey = '' if ( existing ) { bucketKey = existing . key ; } else { const created = await buckets . init ( 'files' ); bucketKey = created . root ! . key ; }","title":"Connect Buckets"},{"location":"tutorials/react-native-buckets/#push-files-to-user-bucket","text":"Finally, let's push a simple file to the user's Bucket. In this example, we'll just create a simple HTML file that says, Hello world . const file = { path : '/index.html' , content : Buffer.from ( webpage ) } const raw = await buckets . pushPath ( bucketKey ! , 'index.html' , file )","title":"Push files to user Bucket"},{"location":"tutorials/react-native-buckets/#list-the-bucket-links","text":"Finally, you can list the links to the file on IPFS, IPNS, ThreadDB, and HTTP. Now that the Bucket is created, keep in mind, each time you update the same Bucket for a user: replace the HTTP content. the Bucket head will get a new IPFS address. replace the IPNS content. be appended to the ThreadDB history. This give you a lot of options for how you build apps, deliver content, and do cool things for your users with their data. You can get each of the protocol addresses as follows. HTTP Address Textile give you and your users a public address for each Bucket created. They are created using the Bucket key and you can generate those as follows: https://${bucket-key}.textile.space IPFS Address The IPFS address is contained in the result of pushPath . const raw = await buckets . pushPath ( bucketKey ! , 'index.html' , file ) console . log ( raw . root ) IPNS Address The IPNS Address is always the same and is the Bucket key! If you want to see the Bucket over IPNS from a gateway, you can use the Textile gateway as follows: https://${bucket-key}.ipns.hub.textile.io/ ThreadDB Address You can generate a link to the Bucket with the user thread as follows: https://${thread-id}.thread.hub.textile.io/buckets/${this.state.bucket-key} Warning Remember that at this point in time, Buckets are entirely open, data is available to be viewed or downloaded by anyone your app or user share the link with.","title":"List the Bucket links"},{"location":"tutorials/react-native-buckets/#code","text":"Check out a complete React Native project on GitHub that generates a user identity, Thread, and Bucket.","title":"Code"},{"location":"tutorials/static-websites/","text":"Buckets make it simple to publish websites using IPFS. If you are using a static site builder such as Jekyll , Gatsby , Hugo , or Mkdocs you can add Buckets to your build steps for both staging and production site hosting. Site builder tutorials \u00b6 If you are using one of these static site builders, jump to the specific tutorials. Jekyll Site An example Jekyll site published in a Bucket. Gatsby Site An example Gatsby site published in a Bucket. Hugo Site An example Hugo site published in a Bucket. Automation and deployment (CI/CD) \u00b6 Buckets are an ideal tool for persisting your website, source code, or documentation on IPFS using continuous integration. Tools like Travis CI, CircleCI, and GitHub Actions all make it possible to do very easily. If you kepe your website source code on GitHub, we have provided a configurable GitHub Action that allows you to automatically push updates to your Bucket whenever your website changes. View the Textile Buckets GitHub Action . Resources \u00b6 Domain Name Management \u00b6 Fleek Fleek offers domain management tools and soon, Bucket support. Cloudflare Easily add your Bucket IPNS address to Cloudflare with DNSLink. Network Replication \u00b6 Your website may be one of your most important assets on IPFS. Why not pin it on multiple infrastructure providers for added network speed. Pinata Simple and easy to use, Pinata offers a great pinning API for IPFS. Infura Seasoned builders of API portals for the dWeb, pin with confidence on Infura. Temporal Get the stopwatch out, Temporal is your pinning service with speed on the brain . Overview \u00b6 Initialize your Bucket \u00b6 If you are building a static site with an engine such as Jekyll or Gatsyb, or even React you will want to initialize your Bucket in the root of the project, not in the build folder. Your project might look like this. ls ./ build package.json src In this case, we are building the raw site code in src into the build folder. We should initialize the Bucket at the root of the project. hub bucket init Push your Bucket \u00b6 Now, pushing your Bucket is simple. After you build your project so that build contains the latest version of your site ready to deploy you run the bucket push command. hub bucket push build/ . That's it! Your site is now available on the free subdomain and over IPNS. You can easily integrate it into your own DNS using DNSLink. DNSLink \u00b6 You can use Buckets to host websites from your own domain using DNSLink . The easiest way to do this is using your Bucket's IPNS link. On Cloudflare for example, your updated DNS records should look like the following. CNAME <site> www.cloudflare-ipfs.com TXT _dnslink.<site> dnslink = /ipns/<bucket ipns link>","title":"Host a Website in a Bucket"},{"location":"tutorials/static-websites/#site-builder-tutorials","text":"If you are using one of these static site builders, jump to the specific tutorials.","title":"Site builder tutorials"},{"location":"tutorials/static-websites/#automation-and-deployment-cicd","text":"Buckets are an ideal tool for persisting your website, source code, or documentation on IPFS using continuous integration. Tools like Travis CI, CircleCI, and GitHub Actions all make it possible to do very easily. If you kepe your website source code on GitHub, we have provided a configurable GitHub Action that allows you to automatically push updates to your Bucket whenever your website changes. View the Textile Buckets GitHub Action .","title":"Automation and deployment (CI/CD)"},{"location":"tutorials/static-websites/#resources","text":"","title":"Resources"},{"location":"tutorials/static-websites/#domain-name-management","text":"","title":"Domain Name Management"},{"location":"tutorials/static-websites/#network-replication","text":"Your website may be one of your most important assets on IPFS. Why not pin it on multiple infrastructure providers for added network speed.","title":"Network Replication"},{"location":"tutorials/static-websites/#overview","text":"","title":"Overview"},{"location":"tutorials/static-websites/#initialize-your-bucket","text":"If you are building a static site with an engine such as Jekyll or Gatsyb, or even React you will want to initialize your Bucket in the root of the project, not in the build folder. Your project might look like this. ls ./ build package.json src In this case, we are building the raw site code in src into the build folder. We should initialize the Bucket at the root of the project. hub bucket init","title":"Initialize your Bucket"},{"location":"tutorials/static-websites/#push-your-bucket","text":"Now, pushing your Bucket is simple. After you build your project so that build contains the latest version of your site ready to deploy you run the bucket push command. hub bucket push build/ . That's it! Your site is now available on the free subdomain and over IPNS. You can easily integrate it into your own DNS using DNSLink.","title":"Push your Bucket"},{"location":"tutorials/static-websites/#dnslink","text":"You can use Buckets to host websites from your own domain using DNSLink . The easiest way to do this is using your Bucket's IPNS link. On Cloudflare for example, your updated DNS records should look like the following. CNAME <site> www.cloudflare-ipfs.com TXT _dnslink.<site> dnslink = /ipns/<bucket ipns link>","title":"DNSLink"},{"location":"tutorials/hub/libp2p-identities/","text":"Basic identity \u00b6 In this seciton, we're going to focus on identity. Specifically, we're going to create user identities using private-keys. The Textile Hub supports public-key infrastructure (PKI) allowing your app to support many different user identity providers based on PKI (e.g. 3Box, uPort, Blockstack) or derive your own. Key-based identity access \u00b6 Your application can grant users access to your Hub APIs very easily. When doing so, the Hub can also help you verify that the users are who they claim to be using encryption. The general flow is as follows: A user attempts to sign-in by providing their public key . Your app creates a one-time challenge for the users. The user signs the challenge with their private key to generate credentials . Your app verifies the credentials. Below, we will simplify these steps by using the Hub's helpful token generation endpoint that also does credential verification. Generating an identity \u00b6 In this example, we'll use an identity generated by the Libp2p crypto library and made available through the @textile/threads-core library. Install dependency npm install --save @textile/threads-core Generating Identities You can use the Libp2pCryptoIdentity utility to generate random new identities (private and public keys) and later, to sign challenges to prove private key ownership. import { Libp2pCryptoIdentity } from '@textile/threads-core' ; /** Random new identity */ const identity = await Libp2pCryptoIdentity . fromRandom () /** Convert to string. */ const identityString = identity . toString () /** Restore an identity object from a string */ const restored = Libp2pCryptoIdentity . fromString ( identityString ) All of the instances above are different representations of the same user generated by Libp2pCryptoIdentity.fromRandom() . Each instance holds a different copy of the user's private-key and therefore should remain private between your app and your user. Caching user identity \u00b6 You can add simple client-side caching to store a user's identity in the browser and restore it when the user returns to the app. Warning localStorage isn't guaranteed and may be cleared by the browser, the system, or the users. Even more important, localStorage isn't a secure place to store secrets. You should provide alternative storage mechanisms if maintaining identity (and therefore data ownership and access) over time is important. import { Libp2pCryptoIdentity } from '@textile/threads-core' ; const getIdentity = async () : Promise < Libp2pCryptoIdentity > => { /** Restore any cached user identity first */ const cached = localStorage . getItem ( \"user-private-identity\" ) if ( cached !== null ) { /** Convert the cached identity string to a Libp2pCryptoIdentity and return */ return Libp2pCryptoIdentity . fromString ( cached ) } /** No cached identity existed, so create a new one */ const identity = await Libp2pCryptoIdentity . fromRandom () /** Add the string copy to the cache */ localStorage . setItem ( \"identity\" , identity . toString ()) /** Return the random identity */ return identity } Signing transactions \u00b6 The Libp2pCryptoIdentity object contains a signing method, allowing your app to now sign arbitrary bytes for your users. You can create your own identity verification endpoint or use the Hub's token endpoint to verify the credentials. import { Libp2pCryptoIdentity } from '@textile/threads-core' ; const identity = await getIdentity (); const challenge = Buffer . from ( 'Sign this string' ); const credentials = identity . sign ( challenge );","title":"Basic identity"},{"location":"tutorials/hub/libp2p-identities/#basic-identity","text":"In this seciton, we're going to focus on identity. Specifically, we're going to create user identities using private-keys. The Textile Hub supports public-key infrastructure (PKI) allowing your app to support many different user identity providers based on PKI (e.g. 3Box, uPort, Blockstack) or derive your own.","title":"Basic identity"},{"location":"tutorials/hub/libp2p-identities/#key-based-identity-access","text":"Your application can grant users access to your Hub APIs very easily. When doing so, the Hub can also help you verify that the users are who they claim to be using encryption. The general flow is as follows: A user attempts to sign-in by providing their public key . Your app creates a one-time challenge for the users. The user signs the challenge with their private key to generate credentials . Your app verifies the credentials. Below, we will simplify these steps by using the Hub's helpful token generation endpoint that also does credential verification.","title":"Key-based identity access"},{"location":"tutorials/hub/libp2p-identities/#generating-an-identity","text":"In this example, we'll use an identity generated by the Libp2p crypto library and made available through the @textile/threads-core library. Install dependency npm install --save @textile/threads-core Generating Identities You can use the Libp2pCryptoIdentity utility to generate random new identities (private and public keys) and later, to sign challenges to prove private key ownership. import { Libp2pCryptoIdentity } from '@textile/threads-core' ; /** Random new identity */ const identity = await Libp2pCryptoIdentity . fromRandom () /** Convert to string. */ const identityString = identity . toString () /** Restore an identity object from a string */ const restored = Libp2pCryptoIdentity . fromString ( identityString ) All of the instances above are different representations of the same user generated by Libp2pCryptoIdentity.fromRandom() . Each instance holds a different copy of the user's private-key and therefore should remain private between your app and your user.","title":"Generating an identity"},{"location":"tutorials/hub/libp2p-identities/#caching-user-identity","text":"You can add simple client-side caching to store a user's identity in the browser and restore it when the user returns to the app. Warning localStorage isn't guaranteed and may be cleared by the browser, the system, or the users. Even more important, localStorage isn't a secure place to store secrets. You should provide alternative storage mechanisms if maintaining identity (and therefore data ownership and access) over time is important. import { Libp2pCryptoIdentity } from '@textile/threads-core' ; const getIdentity = async () : Promise < Libp2pCryptoIdentity > => { /** Restore any cached user identity first */ const cached = localStorage . getItem ( \"user-private-identity\" ) if ( cached !== null ) { /** Convert the cached identity string to a Libp2pCryptoIdentity and return */ return Libp2pCryptoIdentity . fromString ( cached ) } /** No cached identity existed, so create a new one */ const identity = await Libp2pCryptoIdentity . fromRandom () /** Add the string copy to the cache */ localStorage . setItem ( \"identity\" , identity . toString ()) /** Return the random identity */ return identity }","title":"Caching user identity"},{"location":"tutorials/hub/libp2p-identities/#signing-transactions","text":"The Libp2pCryptoIdentity object contains a signing method, allowing your app to now sign arbitrary bytes for your users. You can create your own identity verification endpoint or use the Hub's token endpoint to verify the credentials. import { Libp2pCryptoIdentity } from '@textile/threads-core' ; const identity = await getIdentity (); const challenge = Buffer . from ( 'Sign this string' ); const credentials = identity . sign ( challenge );","title":"Signing transactions"},{"location":"tutorials/hub/simple-credentials-endpoint/","text":"Create a simple credentials endpoint \u00b6 The simple credentials endpoint requires no user-identity to be sent to the server. It simply receives a request for new API credentials, uses the key and secret, and then returns the credentials to the client. This type of flow is useful for developers or apps with an existing user-validation flow, or who are able to utilize domain whitelisting and/or are hosting their own app. Setup \u00b6 There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A user group key . This is how your users will be able to access your Hub APIs. Consider creating the key in an organization not your personal account so that you can invite collaborators later. A new Typescript project . We recommend using Typescript, as Textile libraries are in a stage rapid of development and type detection is valuable during upgrades. A server framework. The example below uses KoaJS but could just as easily be written for Express or the basic Node server. Install dependencies # Textile libraries npm install --save @textile/hub @textile/threads-core # Other utilities use in example npm install --save dotenv isomorphic-ws # Libraries specific to our server framework, koajs npm install --save koa koa-router koa-logger koa-json koa-bodyparser Environment variables \u00b6 We'll use a .env file in the root of our project repo where you'll add your Hub API key and secret. The .env file should be added to your .gitignore so that your key and secret are never shared. Contents of .env . USER_API_KEY=alk3rlkjvl323r09fqpoweruw34 USER_API_SECRET=balkweop3jflk9f43lkjs9df2jlght94nzlkv93s Replace the example key and secret values with values you create usint the CLI Create the server \u00b6 In our project setup, our main server is defined in src/index.ts . /** Provides nodejs access to a global Websocket value, required by Hub API */ ;( global as any ). WebSocket = require ( 'isomorphic-ws' ) /** Import our server libraries */ import koa from \"koa\" ; import Router from \"koa-router\" ; import logger from \"koa-logger\" ; import json from \"koa-json\" ; import bodyParser from \"koa-bodyparser\" ; /** For using values in our .env */ import dotenv from \"dotenv\" ; /** Textile libraries */ import { Client , createAPISig } from '@textile/hub' ; import { Libp2pCryptoIdentity } from '@textile/threads-core' ; /** Read the values of .env into the environment */ dotenv . config (); /** Port our server will run */ const PORT : number = 3000 ; /** Init Koa */ const app = new koa () /** Middlewares */ app . use ( json () ); app . use ( logger () ); app . use ( bodyParser () ); /** * Start API Routes * * All prefixed with `/api/` */ const api = new Router ({ prefix : '/api' }); /** * Basic foo-bar endpoint * * https://localhost:3000/api/foo */ api . get ( '/foo' , async ( ctx : koa.Context , next : () => Promise < any > ) => { ctx . body = { foo : 'bar' } await next (); }) /** * Add credentials API here */ /** Tell Koa to use the API routes we generate */ app . use ( api . routes () ). use ( api . allowedMethods () ); /** Start the server! */ app . listen ( PORT , () => console . log ( \"Server started.\" ) ); We now have our basic server setup, we can run it and visit http://localhost/api/foo . ts-node src/index.ts Info Follow your Typescript setup guide for specific ways of launching the server. Add the credentials endpoint \u00b6 Next, we'll add an endpoint so the client can get new or refreshed credentials. Note the Add credentials API here location in the server code above. /** * Add credentials API here */ api . get ( '/credentials' , async ( ctx : koa.Context , next : () => Promise < any > ) => { // Custom validation could be done here... /** Get API authorization for the user */ const expiration = new Date ( Date . now () + 60 * seconds ) const auth = await createAPISig ( process . env . USER_API_SECRET , expiration ) /** Include the API KEY in the auth payload */ const credentials = { ... auth , key : process.env.USER_API_KEY , }; /** Return the credentials in a JSON object */ ctx . body = credentials await next (); }); Now when you refresh your locally running server you should be able to visit the following and receive valid credentials. http://localhost:3000/api/credentials Response: { key: \"<your user group api key>\" , msg: \"<your credentials expiration>\" , sig: \"<the api signature>\" } Create a client \u00b6 Back in the browser, you can now make requests to your credentials endpoint. From their, each user can use the Hub token endpoint directly and begin making calls to the Hub APIs. import { Client , UserAuth } from '@textile/hub' import { Libp2pCryptoIdentity } from '@textile/threads-core' ; const createCredentials = async () : Promise < UserAuth > => { const response = await fetch ( `/api/credentials` , { method : 'GET' , }) const userAuth = await response . json () return userAuth ; } /** Use the simple auth REST endpoint to get API access */ let auth = await createCredentials () console . log ( 'Verified on Textile API' ) displayStatus (); /** The simple auth endpoint generates a user's Hub API Token */ const client = Client . withUserAuth ( auth , API ) /** See identity tutorial */ const token = await client . getToken ( identity ) /** Now, full auth object includes the token */ auth = { ... this . auth , token : token , } GitHub Example \u00b6 If you'd like to explore the examples explained above more, we've provided a fully working example on GitHub. The simple credentials endpoint is part of a more complete example, you can see it here. Simple Credentials API Source code for simple Hub credentials endpoint.","title":"Create a simple credentials endpoint"},{"location":"tutorials/hub/simple-credentials-endpoint/#create-a-simple-credentials-endpoint","text":"The simple credentials endpoint requires no user-identity to be sent to the server. It simply receives a request for new API credentials, uses the key and secret, and then returns the credentials to the client. This type of flow is useful for developers or apps with an existing user-validation flow, or who are able to utilize domain whitelisting and/or are hosting their own app.","title":"Create a simple credentials endpoint"},{"location":"tutorials/hub/simple-credentials-endpoint/#setup","text":"There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A user group key . This is how your users will be able to access your Hub APIs. Consider creating the key in an organization not your personal account so that you can invite collaborators later. A new Typescript project . We recommend using Typescript, as Textile libraries are in a stage rapid of development and type detection is valuable during upgrades. A server framework. The example below uses KoaJS but could just as easily be written for Express or the basic Node server. Install dependencies # Textile libraries npm install --save @textile/hub @textile/threads-core # Other utilities use in example npm install --save dotenv isomorphic-ws # Libraries specific to our server framework, koajs npm install --save koa koa-router koa-logger koa-json koa-bodyparser","title":"Setup"},{"location":"tutorials/hub/simple-credentials-endpoint/#environment-variables","text":"We'll use a .env file in the root of our project repo where you'll add your Hub API key and secret. The .env file should be added to your .gitignore so that your key and secret are never shared. Contents of .env . USER_API_KEY=alk3rlkjvl323r09fqpoweruw34 USER_API_SECRET=balkweop3jflk9f43lkjs9df2jlght94nzlkv93s Replace the example key and secret values with values you create usint the CLI","title":"Environment variables"},{"location":"tutorials/hub/simple-credentials-endpoint/#create-the-server","text":"In our project setup, our main server is defined in src/index.ts . /** Provides nodejs access to a global Websocket value, required by Hub API */ ;( global as any ). WebSocket = require ( 'isomorphic-ws' ) /** Import our server libraries */ import koa from \"koa\" ; import Router from \"koa-router\" ; import logger from \"koa-logger\" ; import json from \"koa-json\" ; import bodyParser from \"koa-bodyparser\" ; /** For using values in our .env */ import dotenv from \"dotenv\" ; /** Textile libraries */ import { Client , createAPISig } from '@textile/hub' ; import { Libp2pCryptoIdentity } from '@textile/threads-core' ; /** Read the values of .env into the environment */ dotenv . config (); /** Port our server will run */ const PORT : number = 3000 ; /** Init Koa */ const app = new koa () /** Middlewares */ app . use ( json () ); app . use ( logger () ); app . use ( bodyParser () ); /** * Start API Routes * * All prefixed with `/api/` */ const api = new Router ({ prefix : '/api' }); /** * Basic foo-bar endpoint * * https://localhost:3000/api/foo */ api . get ( '/foo' , async ( ctx : koa.Context , next : () => Promise < any > ) => { ctx . body = { foo : 'bar' } await next (); }) /** * Add credentials API here */ /** Tell Koa to use the API routes we generate */ app . use ( api . routes () ). use ( api . allowedMethods () ); /** Start the server! */ app . listen ( PORT , () => console . log ( \"Server started.\" ) ); We now have our basic server setup, we can run it and visit http://localhost/api/foo . ts-node src/index.ts Info Follow your Typescript setup guide for specific ways of launching the server.","title":"Create the server"},{"location":"tutorials/hub/simple-credentials-endpoint/#add-the-credentials-endpoint","text":"Next, we'll add an endpoint so the client can get new or refreshed credentials. Note the Add credentials API here location in the server code above. /** * Add credentials API here */ api . get ( '/credentials' , async ( ctx : koa.Context , next : () => Promise < any > ) => { // Custom validation could be done here... /** Get API authorization for the user */ const expiration = new Date ( Date . now () + 60 * seconds ) const auth = await createAPISig ( process . env . USER_API_SECRET , expiration ) /** Include the API KEY in the auth payload */ const credentials = { ... auth , key : process.env.USER_API_KEY , }; /** Return the credentials in a JSON object */ ctx . body = credentials await next (); }); Now when you refresh your locally running server you should be able to visit the following and receive valid credentials. http://localhost:3000/api/credentials Response: { key: \"<your user group api key>\" , msg: \"<your credentials expiration>\" , sig: \"<the api signature>\" }","title":"Add the credentials endpoint"},{"location":"tutorials/hub/simple-credentials-endpoint/#create-a-client","text":"Back in the browser, you can now make requests to your credentials endpoint. From their, each user can use the Hub token endpoint directly and begin making calls to the Hub APIs. import { Client , UserAuth } from '@textile/hub' import { Libp2pCryptoIdentity } from '@textile/threads-core' ; const createCredentials = async () : Promise < UserAuth > => { const response = await fetch ( `/api/credentials` , { method : 'GET' , }) const userAuth = await response . json () return userAuth ; } /** Use the simple auth REST endpoint to get API access */ let auth = await createCredentials () console . log ( 'Verified on Textile API' ) displayStatus (); /** The simple auth endpoint generates a user's Hub API Token */ const client = Client . withUserAuth ( auth , API ) /** See identity tutorial */ const token = await client . getToken ( identity ) /** Now, full auth object includes the token */ auth = { ... this . auth , token : token , }","title":"Create a client"},{"location":"tutorials/hub/simple-credentials-endpoint/#github-example","text":"If you'd like to explore the examples explained above more, we've provided a fully working example on GitHub. The simple credentials endpoint is part of a more complete example, you can see it here.","title":"GitHub Example"},{"location":"tutorials/hub/user-login-endpoint/","text":"Create a login system for user public keys \u00b6 The login example shows you how to setup a simple server that will accept a user's public key, verify that they control the private key (via a challenge), and then grant the user access to the Hub APIs. Setup \u00b6 There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A user group key . This is how your users will be able to access your Hub APIs. Consider creating the key in an organization not your personal account so that you can invite collaborators later. A new Typescript project . We recommend using Typescript, as Textile libraries are in a stage rapid of development and type detection is valuable during upgrades. A server framework. The example below uses KoaJS but could just as easily be written for Express or the basic Node server. Install dependencies # Textile libraries npm install --save @textile/hub # Other utilities use in example npm install --save dotenv emittery isomorphic-ws # Libraries specific to our server framework, koajs npm install --save koa koa-router koa-logger koa-json koa-bodyparser koa-route koa-websocket Environment variables \u00b6 We use a .env file in the root of our project repo. The values in the file will be pulled into the app each time it's run. This is where you'll add your Hub API key and secret. Danger The .env file should be added to your .gitignore so that your key and secret are never shared. Contents of .env . USER_API_KEY=<insert user group key> USER_API_SECRET=<insert user group secret> Create the server \u00b6 In our project setup, our main server is defined in src/index.ts . Unlike the simple credentials example , our server needs to handle two-way communication with the client during identity verification. The flow is as follows: First, the client will make a request login. The server will initiate the request with the Hub and get back an identity challenge. The server will pass the challenge to the client . The client will confirm they own their private key by signing the challenge and passing it back to the server The server which passes it on to the Hub. If successful, a token is generated for the user. If successful, the server* generates API credentials and passes credentials, token, and API key back to the **client . Now, the client can use the Hub APIs directly! It sounds complicated, but you'll see it happens very fast with only a few lines of code. In our example, we use websockets to enable the multi-step communication between the server and the client. /** Provides nodejs access to a global Websocket value, required by Hub API */ ;( global as any ). WebSocket = require ( 'isomorphic-ws' ) import koa from \"koa\" ; import Router from \"koa-router\" ; import logger from \"koa-logger\" ; import json from \"koa-json\" ; import bodyParser from \"koa-bodyparser\" ; import route from \"koa-route\" ; import websockify from \"koa-websocket\" ; import Emittery from \"emittery\" ; import dotenv from \"dotenv\" ; import { Client , UserAuth } from \"@textile/hub\" /** Read the values of .env into the environment */ dotenv . config (); /** Port our server will run */ const PORT : number = 3000 ; /** Init Koa with Websocket support */ const app = websockify ( new koa ()); /** Middlewares */ app . use ( json () ); app . use ( logger () ); app . use ( bodyParser () ); /** * Add websocket login endpoint */ /** Start the server! */ app . listen ( PORT , () => console . log ( \"Server started.\" ) ); Add a websocket login handler \u00b6 Next, we'll add a websocket endpoint to our server. Note the Add websocket login endpoint location in the server code above. /** * Add token websocket endpoint */ app . ws . use ( route . all ( '/ws/login' , ( ctx ) => { /** Emittery allows us to wait for the challenge response event */ const emitter = new Emittery (); ctx . websocket . on ( 'message' , async ( msg ) => { try { /** All messages from client contain {type: string} */ const data = JSON . parse ( msg ); switch ( data . type ) { /** The first type is a new token request */ case 'token' : { /** A new token request will contain the user's public key */ if ( ! data . pubkey ) { throw new Error ( 'missing pubkey' ) } /** * Init new Hub API Client with the user group API keys */ const db = await Client . withUserKey ({ key : process.env.USER_API_KEY , secret : process.env.USER_API_SECRET , type : 0 , }) /** Request a token from the Hub based on the user public key */ const token = await db . getTokenChallenge ( data . pubkey , /** The callback passes the challenge back to the client */ ( challenge : Buffer ) => { return new Promise (( resolve , reject ) => { /** Pass the challenge to the client */ ctx . websocket . send ( JSON . stringify ({ type : 'challenge' , value : challenge.toJSON (), })) /** Wait for the challenge event from our event emitter */ emitter . on ( 'challenge' , ( sig ) => { /** Resolve the promise with the challenge response */ resolve ( Buffer . from ( sig )) }); /** Give client a reasonable timeout to respond to the challenge */ setTimeout (() => { reject () }, 1500 ); }) }) /** * The challenge was successfully completed by the client */ /** Get API authorization for the user */ const auth = await getAPISig () /** Include the token in the auth payload */ const payload : UserAuth = { ... auth , token : token , key : process.env.USER_API_KEY , }; /** Return the result to the client */ ctx . websocket . send ( JSON . stringify ({ type : 'token' , value : payload , })) break ; } /** The second type is a challenge response */ case 'challenge' : { /** A new challenge response will contain a signature */ if ( ! data . sig ) { throw new Error ( 'missing signature (sig)' ) } /** * If the timeout hasn't passed there is a waiting promise. * Emit the challenge signature for the waiting listener above. * */ await emitter . emit ( 'challenge' , data . sig ); break ; } } } catch ( error ) { /** Notify our client of any errors */ ctx . websocket . send ( JSON . stringify ({ type : 'error' , value : error.message , })) } }); })); Now when you refresh your locally running server you should have a websocket endpoint for client token creation. Server notes \u00b6 Now that the user is verified in your system, you can keep their public key without any security issues. However, you should never trust an API call only by the public key, the challenge step is critical. The token provided in the response should be considered a secret that only should be shared with a single user. It does not expire. Create a client \u00b6 Back in the browser webapp, you can now make requests to your login endpoint using a websocket. A basic client might make a request like the following. const loginWithChallenge = async ( id : Libp2pCryptoIdentity ) : Promise < UserAuth > => { return new Promise (( resolve , reject ) => { /** * Configured for our development server * * Note: this should be upgraded to wss for production environments. */ const socketUrl = `ws://localhost:3000/ws/login` /** Initialize our websocket connection */ const socket = new WebSocket ( socketUrl ) /** Wait for our socket to open successfully */ socket . onopen = () => { /** Get public key string */ const publicKey = id . public . toString (); /** Send a new token request */ socket . send ( JSON . stringify ({ pubkey : publicKey , type : 'token' })); /** Listen for messages from the server */ socket . onmessage = async ( event ) => { const data = JSON . parse ( event . data ) switch ( data . type ) { /** Error never happen :) */ case 'error' : { reject ( data . value ); break ; } /** The server issued a new challenge */ case 'challenge' : { /** Convert the challenge json to a Buffer */ const buf = Buffer . from ( data . value ) /** User our identity to sign the challenge */ const signed = await id . sign ( buf ) /** Send the signed challenge back to the server */ socket . send ( JSON . stringify ({ type : 'challenge' , sig : signed.toJSON () })); break ; } /** New token generated */ case 'token' : { resolve ( data . value ) break ; } } } } }); }; By passing the user identity to the function above, your app can authenticate and verify the user in one step, granting them access to your Hub resources. GitHub Example \u00b6 If you'd like to explore the example more, we've provided a fully working example on GitHub. The login endpoint is part of a more complete example, you can see it here. Login API Source code for login and Hub credentials endpoint.","title":"Create a login system for user public keys"},{"location":"tutorials/hub/user-login-endpoint/#create-a-login-system-for-user-public-keys","text":"The login example shows you how to setup a simple server that will accept a user's public key, verify that they control the private key (via a challenge), and then grant the user access to the Hub APIs.","title":"Create a login system for user public keys"},{"location":"tutorials/hub/user-login-endpoint/#setup","text":"There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A user group key . This is how your users will be able to access your Hub APIs. Consider creating the key in an organization not your personal account so that you can invite collaborators later. A new Typescript project . We recommend using Typescript, as Textile libraries are in a stage rapid of development and type detection is valuable during upgrades. A server framework. The example below uses KoaJS but could just as easily be written for Express or the basic Node server. Install dependencies # Textile libraries npm install --save @textile/hub # Other utilities use in example npm install --save dotenv emittery isomorphic-ws # Libraries specific to our server framework, koajs npm install --save koa koa-router koa-logger koa-json koa-bodyparser koa-route koa-websocket","title":"Setup"},{"location":"tutorials/hub/user-login-endpoint/#environment-variables","text":"We use a .env file in the root of our project repo. The values in the file will be pulled into the app each time it's run. This is where you'll add your Hub API key and secret. Danger The .env file should be added to your .gitignore so that your key and secret are never shared. Contents of .env . USER_API_KEY=<insert user group key> USER_API_SECRET=<insert user group secret>","title":"Environment variables"},{"location":"tutorials/hub/user-login-endpoint/#create-the-server","text":"In our project setup, our main server is defined in src/index.ts . Unlike the simple credentials example , our server needs to handle two-way communication with the client during identity verification. The flow is as follows: First, the client will make a request login. The server will initiate the request with the Hub and get back an identity challenge. The server will pass the challenge to the client . The client will confirm they own their private key by signing the challenge and passing it back to the server The server which passes it on to the Hub. If successful, a token is generated for the user. If successful, the server* generates API credentials and passes credentials, token, and API key back to the **client . Now, the client can use the Hub APIs directly! It sounds complicated, but you'll see it happens very fast with only a few lines of code. In our example, we use websockets to enable the multi-step communication between the server and the client. /** Provides nodejs access to a global Websocket value, required by Hub API */ ;( global as any ). WebSocket = require ( 'isomorphic-ws' ) import koa from \"koa\" ; import Router from \"koa-router\" ; import logger from \"koa-logger\" ; import json from \"koa-json\" ; import bodyParser from \"koa-bodyparser\" ; import route from \"koa-route\" ; import websockify from \"koa-websocket\" ; import Emittery from \"emittery\" ; import dotenv from \"dotenv\" ; import { Client , UserAuth } from \"@textile/hub\" /** Read the values of .env into the environment */ dotenv . config (); /** Port our server will run */ const PORT : number = 3000 ; /** Init Koa with Websocket support */ const app = websockify ( new koa ()); /** Middlewares */ app . use ( json () ); app . use ( logger () ); app . use ( bodyParser () ); /** * Add websocket login endpoint */ /** Start the server! */ app . listen ( PORT , () => console . log ( \"Server started.\" ) );","title":"Create the server"},{"location":"tutorials/hub/user-login-endpoint/#add-a-websocket-login-handler","text":"Next, we'll add a websocket endpoint to our server. Note the Add websocket login endpoint location in the server code above. /** * Add token websocket endpoint */ app . ws . use ( route . all ( '/ws/login' , ( ctx ) => { /** Emittery allows us to wait for the challenge response event */ const emitter = new Emittery (); ctx . websocket . on ( 'message' , async ( msg ) => { try { /** All messages from client contain {type: string} */ const data = JSON . parse ( msg ); switch ( data . type ) { /** The first type is a new token request */ case 'token' : { /** A new token request will contain the user's public key */ if ( ! data . pubkey ) { throw new Error ( 'missing pubkey' ) } /** * Init new Hub API Client with the user group API keys */ const db = await Client . withUserKey ({ key : process.env.USER_API_KEY , secret : process.env.USER_API_SECRET , type : 0 , }) /** Request a token from the Hub based on the user public key */ const token = await db . getTokenChallenge ( data . pubkey , /** The callback passes the challenge back to the client */ ( challenge : Buffer ) => { return new Promise (( resolve , reject ) => { /** Pass the challenge to the client */ ctx . websocket . send ( JSON . stringify ({ type : 'challenge' , value : challenge.toJSON (), })) /** Wait for the challenge event from our event emitter */ emitter . on ( 'challenge' , ( sig ) => { /** Resolve the promise with the challenge response */ resolve ( Buffer . from ( sig )) }); /** Give client a reasonable timeout to respond to the challenge */ setTimeout (() => { reject () }, 1500 ); }) }) /** * The challenge was successfully completed by the client */ /** Get API authorization for the user */ const auth = await getAPISig () /** Include the token in the auth payload */ const payload : UserAuth = { ... auth , token : token , key : process.env.USER_API_KEY , }; /** Return the result to the client */ ctx . websocket . send ( JSON . stringify ({ type : 'token' , value : payload , })) break ; } /** The second type is a challenge response */ case 'challenge' : { /** A new challenge response will contain a signature */ if ( ! data . sig ) { throw new Error ( 'missing signature (sig)' ) } /** * If the timeout hasn't passed there is a waiting promise. * Emit the challenge signature for the waiting listener above. * */ await emitter . emit ( 'challenge' , data . sig ); break ; } } } catch ( error ) { /** Notify our client of any errors */ ctx . websocket . send ( JSON . stringify ({ type : 'error' , value : error.message , })) } }); })); Now when you refresh your locally running server you should have a websocket endpoint for client token creation.","title":"Add a websocket login handler"},{"location":"tutorials/hub/user-login-endpoint/#server-notes","text":"Now that the user is verified in your system, you can keep their public key without any security issues. However, you should never trust an API call only by the public key, the challenge step is critical. The token provided in the response should be considered a secret that only should be shared with a single user. It does not expire.","title":"Server notes"},{"location":"tutorials/hub/user-login-endpoint/#create-a-client","text":"Back in the browser webapp, you can now make requests to your login endpoint using a websocket. A basic client might make a request like the following. const loginWithChallenge = async ( id : Libp2pCryptoIdentity ) : Promise < UserAuth > => { return new Promise (( resolve , reject ) => { /** * Configured for our development server * * Note: this should be upgraded to wss for production environments. */ const socketUrl = `ws://localhost:3000/ws/login` /** Initialize our websocket connection */ const socket = new WebSocket ( socketUrl ) /** Wait for our socket to open successfully */ socket . onopen = () => { /** Get public key string */ const publicKey = id . public . toString (); /** Send a new token request */ socket . send ( JSON . stringify ({ pubkey : publicKey , type : 'token' })); /** Listen for messages from the server */ socket . onmessage = async ( event ) => { const data = JSON . parse ( event . data ) switch ( data . type ) { /** Error never happen :) */ case 'error' : { reject ( data . value ); break ; } /** The server issued a new challenge */ case 'challenge' : { /** Convert the challenge json to a Buffer */ const buf = Buffer . from ( data . value ) /** User our identity to sign the challenge */ const signed = await id . sign ( buf ) /** Send the signed challenge back to the server */ socket . send ( JSON . stringify ({ type : 'challenge' , sig : signed.toJSON () })); break ; } /** New token generated */ case 'token' : { resolve ( data . value ) break ; } } } } }); }; By passing the user identity to the function above, your app can authenticate and verify the user in one step, granting them access to your Hub resources.","title":"Create a client"},{"location":"tutorials/hub/user-login-endpoint/#github-example","text":"If you'd like to explore the example more, we've provided a fully working example on GitHub. The login endpoint is part of a more complete example, you can see it here.","title":"GitHub Example"},{"location":"tutorials/hub/web-app/","text":"Build a Web App using the Hub \u00b6 In this tutorial, you'll learn how to generate API credentials that can be shared with with web apps so that your app users can leverage the Hub. With credentials, your users will be able to access Thread Services, create and edit Buckets, and use IPFS persistence right from the browser. You'll build it using a user group key so that every user can use your API while maintaining their own ownership over the data they create. Getting Started \u00b6 There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A user group key . This is how your users will be able to access your Hub APIs. Consider creating the key in an organization not your personal account so that you can invite collaborators later. You only need to create one user group key for all the users of your app. A new Typescript web app . We recommend using Typescript, as Textile libraries are in a period rapid of development and type detection is valuable during upgrades. API Access \u00b6 A user group key consists of a key and a secret . You can expose your key but you never want to expose your secret to users or outside of secure environments. You must use your key and secret to create and renew API access credentials for your users on a regular basis. To do this, we'll build a simple auth endpoint accessible only to your app that will generate Hub credentials for users. ( See below ). Building a simple web app \u00b6 We wont cover the details of setting up a webapp with Typescript because it's well documented elsewhere . You can skip to the end and explore our complete example . Info With your basic Typescript web app setup, you should have a primary .ts (or .js if you decided to stick with Javascript) file where your webapp exists. We'll work within this single file to start, but the instructions below should be adaptable to any application architecture. Generating an Identity \u00b6 In our webapp, we will use a custom private-key identity. If you are exploring our libraries or prototyping a new application, this is a great place to start, as you wont need to wrestle with multiple libraries or APIs at the same time. However, as you get close to launch, we recommend using a more common DID provider. We've provided a simple tutorial for creating new identies and caching those identities in the browser. Read the basic libp2p identities tutorial now . Below, we'll use the cached identity example and getIdentity function from the tutorial above. const identity = getIdentity (); Info The Hub is flexible about what identity or authentication system you use for your users. In the future, the Hub will support email-based identities, allowing you to more easily use the APIs with popular email-based user models. Follow progress here . Creating an authentication endpoint \u00b6 Now that your app is using PKI, your users will only ever share their public key with your API (or any API). Therefore, you'll need a way to verify that they hold the private key linked with the public key, otherwise users could spoof your system very easily. Additionally, you'll want to provide Hub API access to your users based on that verification. You should design your system for credentials that expire quickly. This ensures that if credentials are ever leaked the impact will be minimal. Build an authentication endpoint This example will use the Hub to issue the user a challenge (where they prove they own their private key). After the user passes the challenge, the endpoint will give them Hub credentials. This multi-step flow is useful for developers who don't want to design their own user-verification system. Click here to read the credentials setup steps . In the above example, you should have setup a server and API endpoint that your webapp can connect to. Generate API credentials \u00b6 Now that our credentials endpoint is setup, we simply need to generate new credentials for each user's identity. We'll use the createCredentials function provided in the setup above in our client webapp. const auth = await createCredentials () This auth object will allow your app to start creating and editing Buckets and Threads owned by your user. Using the API \u00b6 Now, your users have identities and they've verified themselves. Next, you'll want to start created Buckets and ThreadDBs for your user. Let's start using hte Hub from inside the webapp. Install dependencies # Textile libraries npm install --save @textile/hub Connect to the API Now, you just need to use auth object above to connect to the API. import { Client } from '@textile/hub' ; const client = Client . withUserAuth ( auth ) /** Query for all the user's existing threads (none to start) */ const threads = await client . listThreads () Your user is now setup to start creating Threads and Buckets that replicate on the Hub API! Read more tutorials or jump over to the js-threads docs to keep building. Putting it all together \u00b6 Now you've had a chance to see how identities work with API keys to provide Hub resources to your users. If you'd like to explore the examples explained above more, we've provided a fully working example on GitHub. Completed example \u00b6 git clone git@github.com:textileio/js-examples.git cd js-examples/hub-browser-auth-app Explore the repo Clone the source code for a server and client using the Hub.","title":"Build a Web App using Hub APIs"},{"location":"tutorials/hub/web-app/#build-a-web-app-using-the-hub","text":"In this tutorial, you'll learn how to generate API credentials that can be shared with with web apps so that your app users can leverage the Hub. With credentials, your users will be able to access Thread Services, create and edit Buckets, and use IPFS persistence right from the browser. You'll build it using a user group key so that every user can use your API while maintaining their own ownership over the data they create.","title":"Build a Web App using the Hub"},{"location":"tutorials/hub/web-app/#getting-started","text":"There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A user group key . This is how your users will be able to access your Hub APIs. Consider creating the key in an organization not your personal account so that you can invite collaborators later. You only need to create one user group key for all the users of your app. A new Typescript web app . We recommend using Typescript, as Textile libraries are in a period rapid of development and type detection is valuable during upgrades.","title":"Getting Started"},{"location":"tutorials/hub/web-app/#api-access","text":"A user group key consists of a key and a secret . You can expose your key but you never want to expose your secret to users or outside of secure environments. You must use your key and secret to create and renew API access credentials for your users on a regular basis. To do this, we'll build a simple auth endpoint accessible only to your app that will generate Hub credentials for users. ( See below ).","title":"API Access"},{"location":"tutorials/hub/web-app/#building-a-simple-web-app","text":"We wont cover the details of setting up a webapp with Typescript because it's well documented elsewhere . You can skip to the end and explore our complete example . Info With your basic Typescript web app setup, you should have a primary .ts (or .js if you decided to stick with Javascript) file where your webapp exists. We'll work within this single file to start, but the instructions below should be adaptable to any application architecture.","title":"Building a simple web app"},{"location":"tutorials/hub/web-app/#generating-an-identity","text":"In our webapp, we will use a custom private-key identity. If you are exploring our libraries or prototyping a new application, this is a great place to start, as you wont need to wrestle with multiple libraries or APIs at the same time. However, as you get close to launch, we recommend using a more common DID provider. We've provided a simple tutorial for creating new identies and caching those identities in the browser. Read the basic libp2p identities tutorial now . Below, we'll use the cached identity example and getIdentity function from the tutorial above. const identity = getIdentity (); Info The Hub is flexible about what identity or authentication system you use for your users. In the future, the Hub will support email-based identities, allowing you to more easily use the APIs with popular email-based user models. Follow progress here .","title":"Generating an Identity"},{"location":"tutorials/hub/web-app/#creating-an-authentication-endpoint","text":"Now that your app is using PKI, your users will only ever share their public key with your API (or any API). Therefore, you'll need a way to verify that they hold the private key linked with the public key, otherwise users could spoof your system very easily. Additionally, you'll want to provide Hub API access to your users based on that verification. You should design your system for credentials that expire quickly. This ensures that if credentials are ever leaked the impact will be minimal. Build an authentication endpoint This example will use the Hub to issue the user a challenge (where they prove they own their private key). After the user passes the challenge, the endpoint will give them Hub credentials. This multi-step flow is useful for developers who don't want to design their own user-verification system. Click here to read the credentials setup steps . In the above example, you should have setup a server and API endpoint that your webapp can connect to.","title":"Creating an authentication endpoint"},{"location":"tutorials/hub/web-app/#generate-api-credentials","text":"Now that our credentials endpoint is setup, we simply need to generate new credentials for each user's identity. We'll use the createCredentials function provided in the setup above in our client webapp. const auth = await createCredentials () This auth object will allow your app to start creating and editing Buckets and Threads owned by your user.","title":"Generate API credentials"},{"location":"tutorials/hub/web-app/#using-the-api","text":"Now, your users have identities and they've verified themselves. Next, you'll want to start created Buckets and ThreadDBs for your user. Let's start using hte Hub from inside the webapp. Install dependencies # Textile libraries npm install --save @textile/hub Connect to the API Now, you just need to use auth object above to connect to the API. import { Client } from '@textile/hub' ; const client = Client . withUserAuth ( auth ) /** Query for all the user's existing threads (none to start) */ const threads = await client . listThreads () Your user is now setup to start creating Threads and Buckets that replicate on the Hub API! Read more tutorials or jump over to the js-threads docs to keep building.","title":"Using the API"},{"location":"tutorials/hub/web-app/#putting-it-all-together","text":"Now you've had a chance to see how identities work with API keys to provide Hub resources to your users. If you'd like to explore the examples explained above more, we've provided a fully working example on GitHub.","title":"Putting it all together"},{"location":"tutorials/hub/web-app/#completed-example","text":"git clone git@github.com:textileio/js-examples.git cd js-examples/hub-browser-auth-app","title":"Completed example"},{"location":"tutorials/static-websites/gatsby-site/","text":"Gatsby is an open source, free, and easy to use static site builder. Gatsby uses React and helps you deploy your website or app as a progressive web app with the smallest amount of effort. Gatsby allows you to write your content in Markdown and then compile it to HTML with a command-line tool. When you compile your website, Gatsby will create a single folder containing your final website. When you add that folder to a Textile Bucket, you can simultaneously publishing your Gatsby site to IPFS , IPNS , and HTTP. Getting started \u00b6 The rest of this post assumes that you have a basic familiarity with Gatsby. If you don't, at a minimum, you'll need to complete the Gatsby Quickstart . You should now have a basic webpage setup with Gatsby. If you have run gatsby develop , you should be able to see your website at http://localhost:8000 . Building your website \u00b6 When you run your website on your computer, Gatsby will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Gatsby will build your site into a folder public . The content of public is what you'll want to publish to your Bucket. Publish your Bucket \u00b6 First, you'll need to login to Textile and initialize a Project in the root of your Gatsby folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). CD into your Jekyll directory and initialize a Bucket with textile bucket init . Build your site with gatsby build . That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Gatsby site"},{"location":"tutorials/static-websites/gatsby-site/#getting-started","text":"The rest of this post assumes that you have a basic familiarity with Gatsby. If you don't, at a minimum, you'll need to complete the Gatsby Quickstart . You should now have a basic webpage setup with Gatsby. If you have run gatsby develop , you should be able to see your website at http://localhost:8000 .","title":"Getting started"},{"location":"tutorials/static-websites/gatsby-site/#building-your-website","text":"When you run your website on your computer, Gatsby will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Gatsby will build your site into a folder public . The content of public is what you'll want to publish to your Bucket.","title":"Building your website"},{"location":"tutorials/static-websites/gatsby-site/#publish-your-bucket","text":"First, you'll need to login to Textile and initialize a Project in the root of your Gatsby folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). CD into your Jekyll directory and initialize a Bucket with textile bucket init . Build your site with gatsby build . That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Publish your Bucket"},{"location":"tutorials/static-websites/hugo-site/","text":"Hugo is a static website development framework written in Go, meaning it's fast. In fact, Hugo claims to be the fastest framework for building websites. Like many of the popular static website frameworks, Hugo allows you to write your content in Markdown and then compile it to HTML with a command-line tool. When you compile your website, Hugo will create a single folder containing your final website. When you add that folder to a Textile Bucket, you can simultaneously publishing your Hugo site to IPFS , IPNS , and HTTP. Here's how. Getting started \u00b6 The rest of this post assumes that you have a basic familiarity with Hugo. If you don't, at a minimum, you'll need to complete the Hugo Quickstart tutorial. You should now have a basic webpage setup with Hugo. If you have run hugo server -D , you should be able to see your website at http://localhost:1313 . Building your website \u00b6 When you run your site on your computer, Hugo will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Hugo will build your site into a folder public . The content of public is what you'll want to publish to your Bucket. Publish your Bucket \u00b6 First, you'll need to login to Textile and initialize a Project in the root of your Hugo folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). CD into your Jekyll directory and initialize a Bucket with textile bucket init . Build your site with hugo -D . Now, you are ready to push your Bucket. textile buckets push public/ . That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Hugo site"},{"location":"tutorials/static-websites/hugo-site/#getting-started","text":"The rest of this post assumes that you have a basic familiarity with Hugo. If you don't, at a minimum, you'll need to complete the Hugo Quickstart tutorial. You should now have a basic webpage setup with Hugo. If you have run hugo server -D , you should be able to see your website at http://localhost:1313 .","title":"Getting started"},{"location":"tutorials/static-websites/hugo-site/#building-your-website","text":"When you run your site on your computer, Hugo will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Hugo will build your site into a folder public . The content of public is what you'll want to publish to your Bucket.","title":"Building your website"},{"location":"tutorials/static-websites/hugo-site/#publish-your-bucket","text":"First, you'll need to login to Textile and initialize a Project in the root of your Hugo folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). CD into your Jekyll directory and initialize a Bucket with textile bucket init . Build your site with hugo -D . Now, you are ready to push your Bucket. textile buckets push public/ . That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Publish your Bucket"},{"location":"tutorials/static-websites/jekyll-site/","text":"Jekyll is one of the most popular static website building frameworks around. Bonus, Jekyll is also open-source and free. Jekyll allows you to write your content in Markdown and then compile it to HTML with a command-line tool. When you compile your website, Jekyll will create a single folder containing your final website. When you add that folder to a Textile Bucket, you can simultaneously publishing your Jekyll site to IPFS , IPNS , and HTTP. Getting started \u00b6 The rest of this post assumes that you have a basic familiarity with Jekyll. If you don't, at a minimum, you'll need to complete the Jekyll Quickstart tutorial. You should now have a basic webpage setup with Jekyll. If you have run bundle exec jekyll serve , you should be able to see your website at http://localhost:4000 . Building your website \u00b6 When you run your Jekyll site on your computer, Jekyll will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Jekyll will build your site into a folder _site . The content of _site is what you'll want to publish to your Bucket. Publish your Bucket \u00b6 First, you'll need to login to Textile and initialize a Project in the root of your Jekyll folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). CD into your Jekyll directory and initialize a Bucket with textile bucket init . Build your site with Jekyll build. Now, you are ready to push your Bucket. textile buckets push _site/ . That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Jekyll site"},{"location":"tutorials/static-websites/jekyll-site/#getting-started","text":"The rest of this post assumes that you have a basic familiarity with Jekyll. If you don't, at a minimum, you'll need to complete the Jekyll Quickstart tutorial. You should now have a basic webpage setup with Jekyll. If you have run bundle exec jekyll serve , you should be able to see your website at http://localhost:4000 .","title":"Getting started"},{"location":"tutorials/static-websites/jekyll-site/#building-your-website","text":"When you run your Jekyll site on your computer, Jekyll will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Jekyll will build your site into a folder _site . The content of _site is what you'll want to publish to your Bucket.","title":"Building your website"},{"location":"tutorials/static-websites/jekyll-site/#publish-your-bucket","text":"First, you'll need to login to Textile and initialize a Project in the root of your Jekyll folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). CD into your Jekyll directory and initialize a Bucket with textile bucket init . Build your site with Jekyll build. Now, you are ready to push your Bucket. textile buckets push _site/ . That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Publish your Bucket"}]}