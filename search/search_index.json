{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Textile documentation. Whether you are an expert or an absolute beginner, you'll find your answers here. Pick a starting point below, or use the search box to find documents matching your keywords. Textile is designed to connect and extend Libp2p , IPFS , and Filecoin . Below, you'll find the technologies that makeup Textile: the Hub, ThreadDB, Buckets, and the Powergate. Together, these tools should help you build apps that are only limited by your imagination! The Hub \u00b6 The Hub is a portal to the IPFS network. Use Textile's managed services to persist your data on the IPFS network, enhance the speed and availability of your decentralized databases, and more. The Hub has APIs for developers and teams to push data to the network and it has developer libraries to provide remote IPFS pinning in your apps or simplify the deployment of our decentralized database, ThreadDB. Start building Introduction Learn more about using the Textile Hub. App APIs Use Threads & Buckets to persist data on IPFS from your apps. App Building Read a tutorial on building apps using the Hub. Buckets \u00b6 Buckets are a new way to pin data to IPFS (and soon, store it to Filecoin). Buckets are dynamic folders published simultaneously over IPFS, IPNS, and HTTP. Buckets are designed to make it simple for you to create folders of data and push that data to remote IPFS peers for backup, persistence, or sharing. They can be encrypted or public, they can be single or multi-user, and they can be used from the CLI or with the Go or JavaScript libraries. Push your buckets Introduction Learn more about using the Buckets. Buckets in Apps Read about adding buckets to your app for users. Buckets JavaScript Jump over to the JavaScript documentation. ThreadDB \u00b6 ThreadDB is a secure, decentralized, p2p database built on IPFS and Libp2p. Developers use ThreadDB so they can spend less time configuring encryption or managing content addresses, instead ThreadDB allows them to start building right away. A familiar MongoDB/Mongoose API and simple data hosting services make dynamic data on the DWeb easy! Learn more Introduction Learn about ThreadDB and how to use them in your app. App APIs Use the Hub to help persist and scale your user's databases. JavaScript Docs Start using the ThreadDB in your NodeJS and browser apps. Start building JS Todo App Build a Todo app with Textile Thread pinning services. Go Chat App Build a multi-user chat app in Go. Filecoin Powergate \u00b6 The Powergate is just warming up! The Powergate is an API driven solution to deploy hybrid Filecoin and IPFS storage into your app. If you are eager to learn more about what we are up to, we invite you to follow our regular community updates or follow along in the the open-source repo . If you want to jump right in, follow one of the links below. Dive into Filecoin System overview Multitiered file storage API built on Filecoin and IPFS. Spin-up the Localnet You can test, explore, and build on all the Filecoin APIs today with Localnet POW JS Client Typescript/Javascript client for Textile's Powergate . Other Resources \u00b6 Join our public Slack , visit our GitHub , follow us on Twitter , and check out the Blog ! This site is on /ipns/bafzbeidm2siabgz4imyuk5lldy4wyo7iyxblzzuwbl2ndxucp5nuhsjcly Thanks! \u00b6 To all of the great people who have contributed to the Textile projects recently.","title":"Home"},{"location":"#the-hub","text":"The Hub is a portal to the IPFS network. Use Textile's managed services to persist your data on the IPFS network, enhance the speed and availability of your decentralized databases, and more. The Hub has APIs for developers and teams to push data to the network and it has developer libraries to provide remote IPFS pinning in your apps or simplify the deployment of our decentralized database, ThreadDB. Start building","title":"The Hub"},{"location":"#buckets","text":"Buckets are a new way to pin data to IPFS (and soon, store it to Filecoin). Buckets are dynamic folders published simultaneously over IPFS, IPNS, and HTTP. Buckets are designed to make it simple for you to create folders of data and push that data to remote IPFS peers for backup, persistence, or sharing. They can be encrypted or public, they can be single or multi-user, and they can be used from the CLI or with the Go or JavaScript libraries. Push your buckets","title":"Buckets"},{"location":"#threaddb","text":"ThreadDB is a secure, decentralized, p2p database built on IPFS and Libp2p. Developers use ThreadDB so they can spend less time configuring encryption or managing content addresses, instead ThreadDB allows them to start building right away. A familiar MongoDB/Mongoose API and simple data hosting services make dynamic data on the DWeb easy! Learn more","title":"ThreadDB"},{"location":"#filecoin-powergate","text":"The Powergate is just warming up! The Powergate is an API driven solution to deploy hybrid Filecoin and IPFS storage into your app. If you are eager to learn more about what we are up to, we invite you to follow our regular community updates or follow along in the the open-source repo . If you want to jump right in, follow one of the links below. Dive into Filecoin","title":"Filecoin Powergate"},{"location":"#other-resources","text":"Join our public Slack , visit our GitHub , follow us on Twitter , and check out the Blog ! This site is on /ipns/bafzbeidm2siabgz4imyuk5lldy4wyo7iyxblzzuwbl2ndxucp5nuhsjcly","title":"Other Resources"},{"location":"#thanks","text":"To all of the great people who have contributed to the Textile projects recently.","title":"Thanks!"},{"location":"a-tour-of-textile/","text":"The tour has moved, start here .","title":"A tour of textile"},{"location":"buckets/","text":"Buckets \u00b6 Getting Started \u00b6 If you've used cloud storage before, you'll find buckets easy to understand. Unlike traditional cloud services, buckets are built on open, decentralized protocols including the IPFS and Libp2p. You can serve websites, data, and apps from buckets. Buckets are packed with useful features, including: Explore your Buckets on the Hub gateway . Render web content in your Bucket on a persistent website . Automatically distribute your updates on IPFS using IPNS . Collaboratively manage Buckets as an organization . Create private Buckets where your app users can store data . (Soon) Archive Bucket data on Filecoin to ensure long-term security and access to your files. Initialize a Bucket \u00b6 When working on your local machine, buckets are mapped to working directories. Once you initialize a bucket in a directory, anytime you return to the directory, the Textile CLI will automatically detect the Bucket you are interacting with. To start a Bucket in your current working directory, you must first initialize the Bucket. You can initialize a bucket with an existing UnixFS DAG available in the IPFS network, or import it interactively in an already existing bucket. Read CLI docs for buckets . Info Bucket names are unique to a developer and within an Org. They are not globally unique. Warning Be careful creating a bucket in a root directory, because all children directories are linked to that bucket. To move or remove a bucket's link to a directory, edit, move or delete the .textile/config.yml file (it will be a hidden folder in the bucket's directory) Shared buckets \u00b6 You can create buckets to share with all members of an organization. To do so, simply initialize an Org first and then initialize a Bucket using the HUB_ORG environmental flag, specifying the name of the Org you want to share the bucket with. For example HUB_ORG=astronauts hub bucket init . All members of the Org will be able to push and pull files to and from the shared Bucket. Read more about creating Orgs . Info to check which org a bucket is registered with, examine the .textile/config.yml file (it will be a hidden folder in the bucket's directory) Encrypted buckets \u00b6 It is possible to create encrypted buckets. The contents of encrypted buckets will still exist on IPFS but the contents will be obfuscated to any viewer that doesn't have access to the encryption keys. You can choose to create encrypted buckets in when creating them in the CLI or when initializing them in the JavaScript library . Publishing content \u00b6 Push new files \u00b6 View the Bucket push CLI docs . hub bucket push Diffing and Synching \u00b6 When a bucket is pushed to the remote, its Merkle DAG representation is saved locally as a reference of the latest pushed version. When you execute hub buck status , it compares the persisted Merkle DAG with a generated Merkle DAG of the Bucket local state. As we mentioned in the last section, walking both DAGs and comparing CIDs can quickly provide paths that changed to the last known version. In a nutshell, when a bucket is pushed, the persisted Merkle DAG contains the minimum amount of information about the directory structure and data fingerprints. Read more about this process . Encryption \u00b6 On bucket creation, you can opt-in to encrypt buckets content. The encryption setup is based on AES-CTR + AES-512 HMAC as seen here , a modified version of the encryption lib used by the Google Drive client, which is designed to handle large streams (files). Encrypted buckets have a couple goals: - Obfuscate bucket data / files (the normal goal of encryption) - Obfuscate directory structure, which amounts to encrypting IPLD nodes and their links The AES and HMAC keys used for bucket encryption are stored in the threadDB collection instance. That just means, each bucket has a model entry for key. This setup essentially allows bucket access to be inherited by thread ACL rules. Of course, this also means that if you can break into the thread (you have gained access to the thread read key), you can decrypt bucket content. As a compromise, we have added some convenience methods to the local buck client which allow you to encrypt content locally (protected by a password) before it gets added to the bucket. This has the downside that you must remember the password. Finally, you can run the standalone buckets daemon buckd locally and use a remote peer as a thread replicator (no read key access), meaning there\u2019s really no downside to the keys being stored in the bucket collection instance. Password-based encryption uses the same approach, but also leverages scrypt to derive the keys from the password. This carries the normal tradeoff: The encryption is only as good as the password. Retrieving content \u00b6 Pull files \u00b6 hub bucket init --existing Info By using the --existing flag, you can list buckets already pushed by you or, when using HUB_ORG , your collaborators. Explore on the gateway \u00b6 To inspect your pushed files, explore on the gateway: hub bucket links then open the first result 'Thread links' in your browser. The Hub gateway gives you a static URL where you can explore, download, and share your latest Bucket content. Render on a website \u00b6 If your Bucket contains web content, the Bucket website endpoint will provide you a static URL that will always render the latest content from your Bucket. See HTTP Domains . Render on IPFS gateways \u00b6 Buckets are dynamic folders distributed over IPFS using ThreadDB. Each time you create a new Bucket, you will receive a new IPNS Address that you can use on the IPFS address to fetch the latest Bucket content. The IPNS address will not change, but the content will update each time you push changes to your Bucket. Each time you update your Bucket, you will receive a new IPFS address to fetch that version of your Bucket content. HTTP Domain \u00b6 All public Buckets are automatically provided a subdomain on textile.space that will reflect the latest changes in to your Bucket. Your Bucket's IPNS address is used as the subdomain, such that your Bucket URL will always be: <ipns-address>.textile.space . This is designed to further enhance the interoperability of protocols using Textile Buckets. IPNS Address \u00b6 Each Bucket has a unique IPNS address that will allow you to render or fetch your Bucket on any IPFS peer or gateway that supports IPNS (including ipfs.io and Cloudflare ). Buckets can't change the speed of IPNS propagation through the network, but we recommend you explore and try for yourself. The Hub gateway will always render the latest data right away. Bucket Automation (CI/CD) \u00b6 Buckets are an ideal tool for persisting your website, source code, or documentation on IPFS using continuous integration. Tools like Travis CI, CircleCI, and GitHub Actions all make it possible to do very easily. We have provided a configurable GitHub Action that allows you to: Push or update your Bucket based on pull requests, commits, and merges. Generate IPNS, IPFS, and HTTP addresses for every Bucket creation or update. Create temporary Buckets for staging or review that can be removed automatically when content is merged or pull requests are closed. Example output from Textile Bucket GitHub Action Learn more \u00b6 Bucket Permissions \u00b6 Developer Buckets \u00b6 All buckets you create are scoped to your developer account. You can always find your currently logged in account with hub whoami . Organization Buckets \u00b6 Any buckets you create using the HUB_ORG setting will also be shared with Org members. Here are the steps to create an Org, create a new Bucket in the Org, and invite a collaborator to the Org: Create a new Org \u00b6 hub org create Choose an Org name: nasa\u2588 > The name of your account on Textile will be nasa > Your URL will be http://hub.textile.io/nasa Please confirm: y\u2588 > Success! Created new org nasa with URL http://hub.textile.io/nasa You have now created the nasa Org. Create a new Bucket shared with an Org \u00b6 The default bucket command is simply buck , because it's two letters less to type each time. If you prefer, you can still type bucket mkdir launchpad cd launchpad HUB_ORG = nasa hub buck init You have now created a new Bucket inside of the launchpad directory and owned by your nasa organization. Invite a collaborator \u00b6 hub org invite The final step is to invite collaborators to your Org. Once they accept the invite, they will be able to interact with buckets associated with the Org. App user Buckets \u00b6 If you are building an app using one of our developer libraries you can use buckets from inside your apps. Apps generally will create buckets on behalf of each user, meaning the user should retain control of the Bucket metadata and contents. Buckets in your app View the tutorial on adding Buckets to your JavaScript app. JS Hub Docs Persist user buckets on IPFS from your JS app. React Native tutorial See how to create user buckets & threads in React Native. Bucket Protocols \u00b6 Buckets are designed to be interoperable across protocols and services. Here are a few examples. Buckets and Threads \u00b6 Buckets are built on ThreadDB . In fact, in their most basic form, buckets are just a document in a Thread that is updated each time the directory of data is updated. Since buckets run on Threads, it opens the door to many new integrations that can be built on Buckets! Buckets and HTTP \u00b6 Buckets can be rendered over HTTP through either the Hub Gateway , the Bucket subdomains , or on any IPFS gateway supporting IPNS (see below). Buckets and IPFS \u00b6 Data in a Bucket is stored as IPLD and pinned on IPFS. You can use the underlying content addresses to pin new Bucket content on additional pinning services such as Pinata or Infura . This can be useful if you want additinal replication of your content on the IPFS network. Buckets and IPNS \u00b6 Every Bucket you create has a unique ID associated with it. The Bucket ID is an IPNS address that you can also use to fetch the latest Bucket content from any IPFS peer or view it over IPFS gateways that support the IPNS protocol. More resources \u00b6 Textile Hub CLI Read the full CLI documentation. Textile JavaScript SDK Persist Buckets on IPFS from your JavaScript app. GitHub Action for Buckets Push and updates from your GitHub repos.","title":"Buckets Overview"},{"location":"buckets/#buckets","text":"","title":"Buckets"},{"location":"buckets/#getting-started","text":"If you've used cloud storage before, you'll find buckets easy to understand. Unlike traditional cloud services, buckets are built on open, decentralized protocols including the IPFS and Libp2p. You can serve websites, data, and apps from buckets. Buckets are packed with useful features, including: Explore your Buckets on the Hub gateway . Render web content in your Bucket on a persistent website . Automatically distribute your updates on IPFS using IPNS . Collaboratively manage Buckets as an organization . Create private Buckets where your app users can store data . (Soon) Archive Bucket data on Filecoin to ensure long-term security and access to your files.","title":"Getting Started"},{"location":"buckets/#initialize-a-bucket","text":"When working on your local machine, buckets are mapped to working directories. Once you initialize a bucket in a directory, anytime you return to the directory, the Textile CLI will automatically detect the Bucket you are interacting with. To start a Bucket in your current working directory, you must first initialize the Bucket. You can initialize a bucket with an existing UnixFS DAG available in the IPFS network, or import it interactively in an already existing bucket. Read CLI docs for buckets . Info Bucket names are unique to a developer and within an Org. They are not globally unique. Warning Be careful creating a bucket in a root directory, because all children directories are linked to that bucket. To move or remove a bucket's link to a directory, edit, move or delete the .textile/config.yml file (it will be a hidden folder in the bucket's directory)","title":"Initialize a Bucket"},{"location":"buckets/#shared-buckets","text":"You can create buckets to share with all members of an organization. To do so, simply initialize an Org first and then initialize a Bucket using the HUB_ORG environmental flag, specifying the name of the Org you want to share the bucket with. For example HUB_ORG=astronauts hub bucket init . All members of the Org will be able to push and pull files to and from the shared Bucket. Read more about creating Orgs . Info to check which org a bucket is registered with, examine the .textile/config.yml file (it will be a hidden folder in the bucket's directory)","title":"Shared buckets"},{"location":"buckets/#encrypted-buckets","text":"It is possible to create encrypted buckets. The contents of encrypted buckets will still exist on IPFS but the contents will be obfuscated to any viewer that doesn't have access to the encryption keys. You can choose to create encrypted buckets in when creating them in the CLI or when initializing them in the JavaScript library .","title":"Encrypted buckets"},{"location":"buckets/#publishing-content","text":"","title":"Publishing content"},{"location":"buckets/#push-new-files","text":"View the Bucket push CLI docs . hub bucket push","title":"Push new files"},{"location":"buckets/#diffing-and-synching","text":"When a bucket is pushed to the remote, its Merkle DAG representation is saved locally as a reference of the latest pushed version. When you execute hub buck status , it compares the persisted Merkle DAG with a generated Merkle DAG of the Bucket local state. As we mentioned in the last section, walking both DAGs and comparing CIDs can quickly provide paths that changed to the last known version. In a nutshell, when a bucket is pushed, the persisted Merkle DAG contains the minimum amount of information about the directory structure and data fingerprints. Read more about this process .","title":"Diffing and Synching"},{"location":"buckets/#encryption","text":"On bucket creation, you can opt-in to encrypt buckets content. The encryption setup is based on AES-CTR + AES-512 HMAC as seen here , a modified version of the encryption lib used by the Google Drive client, which is designed to handle large streams (files). Encrypted buckets have a couple goals: - Obfuscate bucket data / files (the normal goal of encryption) - Obfuscate directory structure, which amounts to encrypting IPLD nodes and their links The AES and HMAC keys used for bucket encryption are stored in the threadDB collection instance. That just means, each bucket has a model entry for key. This setup essentially allows bucket access to be inherited by thread ACL rules. Of course, this also means that if you can break into the thread (you have gained access to the thread read key), you can decrypt bucket content. As a compromise, we have added some convenience methods to the local buck client which allow you to encrypt content locally (protected by a password) before it gets added to the bucket. This has the downside that you must remember the password. Finally, you can run the standalone buckets daemon buckd locally and use a remote peer as a thread replicator (no read key access), meaning there\u2019s really no downside to the keys being stored in the bucket collection instance. Password-based encryption uses the same approach, but also leverages scrypt to derive the keys from the password. This carries the normal tradeoff: The encryption is only as good as the password.","title":"Encryption"},{"location":"buckets/#retrieving-content","text":"","title":"Retrieving content"},{"location":"buckets/#pull-files","text":"hub bucket init --existing Info By using the --existing flag, you can list buckets already pushed by you or, when using HUB_ORG , your collaborators.","title":"Pull files"},{"location":"buckets/#explore-on-the-gateway","text":"To inspect your pushed files, explore on the gateway: hub bucket links then open the first result 'Thread links' in your browser. The Hub gateway gives you a static URL where you can explore, download, and share your latest Bucket content.","title":"Explore on the gateway"},{"location":"buckets/#render-on-a-website","text":"If your Bucket contains web content, the Bucket website endpoint will provide you a static URL that will always render the latest content from your Bucket. See HTTP Domains .","title":"Render on a website"},{"location":"buckets/#render-on-ipfs-gateways","text":"Buckets are dynamic folders distributed over IPFS using ThreadDB. Each time you create a new Bucket, you will receive a new IPNS Address that you can use on the IPFS address to fetch the latest Bucket content. The IPNS address will not change, but the content will update each time you push changes to your Bucket. Each time you update your Bucket, you will receive a new IPFS address to fetch that version of your Bucket content.","title":"Render on IPFS gateways"},{"location":"buckets/#http-domain","text":"All public Buckets are automatically provided a subdomain on textile.space that will reflect the latest changes in to your Bucket. Your Bucket's IPNS address is used as the subdomain, such that your Bucket URL will always be: <ipns-address>.textile.space . This is designed to further enhance the interoperability of protocols using Textile Buckets.","title":"HTTP Domain"},{"location":"buckets/#ipns-address","text":"Each Bucket has a unique IPNS address that will allow you to render or fetch your Bucket on any IPFS peer or gateway that supports IPNS (including ipfs.io and Cloudflare ). Buckets can't change the speed of IPNS propagation through the network, but we recommend you explore and try for yourself. The Hub gateway will always render the latest data right away.","title":"IPNS Address"},{"location":"buckets/#bucket-automation-cicd","text":"Buckets are an ideal tool for persisting your website, source code, or documentation on IPFS using continuous integration. Tools like Travis CI, CircleCI, and GitHub Actions all make it possible to do very easily. We have provided a configurable GitHub Action that allows you to: Push or update your Bucket based on pull requests, commits, and merges. Generate IPNS, IPFS, and HTTP addresses for every Bucket creation or update. Create temporary Buckets for staging or review that can be removed automatically when content is merged or pull requests are closed. Example output from Textile Bucket GitHub Action","title":"Bucket Automation (CI/CD)"},{"location":"buckets/#learn-more","text":"","title":"Learn more"},{"location":"buckets/#bucket-permissions","text":"","title":"Bucket Permissions"},{"location":"buckets/#developer-buckets","text":"All buckets you create are scoped to your developer account. You can always find your currently logged in account with hub whoami .","title":"Developer Buckets"},{"location":"buckets/#organization-buckets","text":"Any buckets you create using the HUB_ORG setting will also be shared with Org members. Here are the steps to create an Org, create a new Bucket in the Org, and invite a collaborator to the Org:","title":"Organization Buckets"},{"location":"buckets/#create-a-new-org","text":"hub org create Choose an Org name: nasa\u2588 > The name of your account on Textile will be nasa > Your URL will be http://hub.textile.io/nasa Please confirm: y\u2588 > Success! Created new org nasa with URL http://hub.textile.io/nasa You have now created the nasa Org.","title":"Create a new Org"},{"location":"buckets/#create-a-new-bucket-shared-with-an-org","text":"The default bucket command is simply buck , because it's two letters less to type each time. If you prefer, you can still type bucket mkdir launchpad cd launchpad HUB_ORG = nasa hub buck init You have now created a new Bucket inside of the launchpad directory and owned by your nasa organization.","title":"Create a new Bucket shared with an Org"},{"location":"buckets/#invite-a-collaborator","text":"hub org invite The final step is to invite collaborators to your Org. Once they accept the invite, they will be able to interact with buckets associated with the Org.","title":"Invite a collaborator"},{"location":"buckets/#app-user-buckets","text":"If you are building an app using one of our developer libraries you can use buckets from inside your apps. Apps generally will create buckets on behalf of each user, meaning the user should retain control of the Bucket metadata and contents.","title":"App user Buckets"},{"location":"buckets/#bucket-protocols","text":"Buckets are designed to be interoperable across protocols and services. Here are a few examples.","title":"Bucket Protocols"},{"location":"buckets/#buckets-and-threads","text":"Buckets are built on ThreadDB . In fact, in their most basic form, buckets are just a document in a Thread that is updated each time the directory of data is updated. Since buckets run on Threads, it opens the door to many new integrations that can be built on Buckets!","title":"Buckets and Threads"},{"location":"buckets/#buckets-and-http","text":"Buckets can be rendered over HTTP through either the Hub Gateway , the Bucket subdomains , or on any IPFS gateway supporting IPNS (see below).","title":"Buckets and HTTP"},{"location":"buckets/#buckets-and-ipfs","text":"Data in a Bucket is stored as IPLD and pinned on IPFS. You can use the underlying content addresses to pin new Bucket content on additional pinning services such as Pinata or Infura . This can be useful if you want additinal replication of your content on the IPFS network.","title":"Buckets and IPFS"},{"location":"buckets/#buckets-and-ipns","text":"Every Bucket you create has a unique ID associated with it. The Bucket ID is an IPNS address that you can also use to fetch the latest Bucket content from any IPFS peer or view it over IPFS gateways that support the IPNS protocol.","title":"Buckets and IPNS"},{"location":"buckets/#more-resources","text":"","title":"More resources"},{"location":"hub/","text":"The Hub is the fastest way to start building and experimenting on Textile technologies. It provides hosted Buckets and Threads with persistent IFPS endpoints. It includes developer accounts for individuals and organizations and API keys integration into apps. Security \u00b6 Textile is still under heavy development and no part of it should be used before a thorough review of the underlying code and an understanding APIs and protocols may change rapidly. There may be coding mistakes, and the underlying protocols may contain design flaws. Please let us know immediately if you have discovered a security vulnerability. Please also read the security note for go-ipfs. Overview \u00b6 To get started, you'll be using the Hub client. The layout of the Hub CLI mirrors the services available, for example: hub threads provides limited access to ThreadDB. hub buck provides access to Buckets. hub keys create and expire API keys. hub orgs lets you create multi-developer organizations for collaboration. Once you've setup an account on the Hub, you can start accessing those resources right away. Additionally, you can use the API keys to grant restricted access to your Hub resources to the end-users of your own apps and services. Roles \u00b6 Developers : You. You are a primary account owner. You can create new API keys, create and join new Organizations, and access admin APIs. You can create your own Buckets and Threads. You can use the CLI with your account do all the mentioned. Organizations : You and your collaborators. Members can share admin control of API keys. Members can share access to and synchronize Bucket state across all members. Referenced through docs as simply, Org . Users : Accounts generated by your apps using a User Group API key. Your app can create Threads and Buckets owned by these users. These users can then add or remove content from those assets based on their identity. They cannot use the CLI and cannot create new API keys. Quotas \u00b6 Each entity above has its own quota no matter which role it is (Developer, Org, or User). If these limits are not enough for you, or if you need to talk to us about a custom account, you can reach us at support@textile.io . Threads Max Threads Per Owner 100 Buckets Max Buckets Size 1Gib Max Size All Buckets 1Gib Max Buckets Per Thread 10,000 Install & Create Account \u00b6 The Hub is API driven and available through the command-line tool and developer libraries. To use the Hub, first you need to download the command-line interface and create an account. Textile Hub Accounts Download the CLI and create your free Hub account. ============================= Once you have your Hub account, you can start using the Hub to host your data on the IPFS network. IPFS hosting is offered using a Textile technology called, Buckets. Buckets offer you dynamic, folder-based, directories that you can use to persist data on IPFS. They are editable, sharable, and come with free URLs. Buckets Learn how to create, manage, share, and publish data on IPFS. Another thing you can do with your account on the Hub, is create an app token that will allow you to use the Hub for persisting user Thread data. Think of it as a trustless service that your app's database can rely on to quickly store and access data on IPFS! Thread Services Persist and relay Thread updates for your app users. Other Documentation \u00b6 Next steps \u00b6 Create an Account Start using hosted services by creating your free account. Connect your Apps Learn how to use the Hub's APIs in your app. Hub CLI Read the full CLI documentation.","title":"Accounts Overview"},{"location":"hub/#security","text":"Textile is still under heavy development and no part of it should be used before a thorough review of the underlying code and an understanding APIs and protocols may change rapidly. There may be coding mistakes, and the underlying protocols may contain design flaws. Please let us know immediately if you have discovered a security vulnerability. Please also read the security note for go-ipfs.","title":"Security"},{"location":"hub/#overview","text":"To get started, you'll be using the Hub client. The layout of the Hub CLI mirrors the services available, for example: hub threads provides limited access to ThreadDB. hub buck provides access to Buckets. hub keys create and expire API keys. hub orgs lets you create multi-developer organizations for collaboration. Once you've setup an account on the Hub, you can start accessing those resources right away. Additionally, you can use the API keys to grant restricted access to your Hub resources to the end-users of your own apps and services.","title":"Overview"},{"location":"hub/#roles","text":"Developers : You. You are a primary account owner. You can create new API keys, create and join new Organizations, and access admin APIs. You can create your own Buckets and Threads. You can use the CLI with your account do all the mentioned. Organizations : You and your collaborators. Members can share admin control of API keys. Members can share access to and synchronize Bucket state across all members. Referenced through docs as simply, Org . Users : Accounts generated by your apps using a User Group API key. Your app can create Threads and Buckets owned by these users. These users can then add or remove content from those assets based on their identity. They cannot use the CLI and cannot create new API keys.","title":"Roles"},{"location":"hub/#quotas","text":"Each entity above has its own quota no matter which role it is (Developer, Org, or User). If these limits are not enough for you, or if you need to talk to us about a custom account, you can reach us at support@textile.io . Threads Max Threads Per Owner 100 Buckets Max Buckets Size 1Gib Max Size All Buckets 1Gib Max Buckets Per Thread 10,000","title":"Quotas"},{"location":"hub/#install-create-account","text":"The Hub is API driven and available through the command-line tool and developer libraries. To use the Hub, first you need to download the command-line interface and create an account.","title":"Install &amp; Create Account"},{"location":"hub/#other-documentation","text":"","title":"Other Documentation"},{"location":"hub/#next-steps","text":"","title":"Next steps"},{"location":"hub/accounts/","text":"Installation and Account Setup \u00b6 To create an account, you need first to install the Hub CLI. The CLI is where you are going to do all account management, create orgs, create API keys, etc. The first step is to download and install the application. Install the Command-line Interface \u00b6 Download \u00b6 Download the Hub CLI binary for your platform from the latest releases . Info You'll see two binaries available for download on the Textile releases page, hub , and buck . Ignore the buck binary for now. buck is used to interact with buckets in a stand-alone manner, independent of Textile Hub. hub provides all the functionality you'll need to interact with the Textile Hub and Buckets together. Install \u00b6 Open the contents of the downloaded archive and run the install script. This should install the hub tool on your computer. You can verify with hub --help . Mac Installation \u00b6 On MacOS you will need to confirm that it is okay to run the hub binary before it runs successfully. You will see this warning: Select 'Cancel' Go to 'System Settings' => 'General' where you will be able to click, 'Allow Anyway' Run hub --help again and this time select, 'Open` when prompted. You will now be able to continue using the CLI without issue. When you update the binary, you may need to repeat the above steps. We will add developer signing to our MacOS binaries soon. Successfully running hub --help to print out the command docs. Account setup \u00b6 The next step is to initialize an account. The Hub CLI use magic-link signin, so it only requires you to enter and verify a valid email. Initialize \u00b6 hub init You have now created an account on the Textile Hub! You can now run all the available commands, such as hub --help , hub whoami , hub buckets , hub keys ls , hub logout , and hub login . Login \u00b6 Now that your account exists, the next time you use the CLI on a new computer, or after logging out, you simply need to login . hub login Organizations \u00b6 Orgs allow multiple developers to work together using shared resources. Members of an organization can collaboratively manage, create, or remove API keys , and more. You can create an org easily. hub org create Next, you can begin inviting collaborators by email addresses. hub org invite You can now share and collaborate with all org members. For example, when creating new buckets, you can create them in the org and immediately be available to your collaborators. Additionally, you can create and share API key admin. Org bucket init HUB_ORG = <org name> hub buck init Org keys create HUB_ORG = <org name> hub keys create Info You can create , invite , and leave organizations easily. Read more about all Org methods on the CLI docs . To learn more about sharing Buckets with an organization, read the intro on Organization Buckets . Enterprise users \u00b6 If you are interested in enterprise support from Textile, please email us at support@textile.io . Account deletion \u00b6 If you delete your account or organization, data replicated on IPFS through any API will also be removed . So if you remove your account, we highly encourage you to replicate the data on an external IPFS node, provide tools for your users to export or replicate their account data, or host external Thread Services to migrate your user Thread replication to. window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'AW-856649624');","title":"Installation & Setup"},{"location":"hub/accounts/#installation-and-account-setup","text":"To create an account, you need first to install the Hub CLI. The CLI is where you are going to do all account management, create orgs, create API keys, etc. The first step is to download and install the application.","title":"Installation and Account Setup"},{"location":"hub/accounts/#install-the-command-line-interface","text":"","title":"Install the Command-line Interface"},{"location":"hub/accounts/#download","text":"Download the Hub CLI binary for your platform from the latest releases . Info You'll see two binaries available for download on the Textile releases page, hub , and buck . Ignore the buck binary for now. buck is used to interact with buckets in a stand-alone manner, independent of Textile Hub. hub provides all the functionality you'll need to interact with the Textile Hub and Buckets together.","title":"Download"},{"location":"hub/accounts/#install","text":"Open the contents of the downloaded archive and run the install script. This should install the hub tool on your computer. You can verify with hub --help .","title":"Install"},{"location":"hub/accounts/#mac-installation","text":"On MacOS you will need to confirm that it is okay to run the hub binary before it runs successfully. You will see this warning: Select 'Cancel' Go to 'System Settings' => 'General' where you will be able to click, 'Allow Anyway' Run hub --help again and this time select, 'Open` when prompted. You will now be able to continue using the CLI without issue. When you update the binary, you may need to repeat the above steps. We will add developer signing to our MacOS binaries soon. Successfully running hub --help to print out the command docs.","title":"Mac Installation"},{"location":"hub/accounts/#account-setup","text":"The next step is to initialize an account. The Hub CLI use magic-link signin, so it only requires you to enter and verify a valid email.","title":"Account setup"},{"location":"hub/accounts/#initialize","text":"hub init You have now created an account on the Textile Hub! You can now run all the available commands, such as hub --help , hub whoami , hub buckets , hub keys ls , hub logout , and hub login .","title":"Initialize"},{"location":"hub/accounts/#login","text":"Now that your account exists, the next time you use the CLI on a new computer, or after logging out, you simply need to login . hub login","title":"Login"},{"location":"hub/accounts/#organizations","text":"Orgs allow multiple developers to work together using shared resources. Members of an organization can collaboratively manage, create, or remove API keys , and more. You can create an org easily. hub org create Next, you can begin inviting collaborators by email addresses. hub org invite You can now share and collaborate with all org members. For example, when creating new buckets, you can create them in the org and immediately be available to your collaborators. Additionally, you can create and share API key admin. Org bucket init HUB_ORG = <org name> hub buck init Org keys create HUB_ORG = <org name> hub keys create Info You can create , invite , and leave organizations easily. Read more about all Org methods on the CLI docs . To learn more about sharing Buckets with an organization, read the intro on Organization Buckets .","title":"Organizations"},{"location":"hub/accounts/#enterprise-users","text":"If you are interested in enterprise support from Textile, please email us at support@textile.io .","title":"Enterprise users"},{"location":"hub/accounts/#account-deletion","text":"If you delete your account or organization, data replicated on IPFS through any API will also be removed . So if you remove your account, we highly encourage you to replicate the data on an external IPFS node, provide tools for your users to export or replicate their account data, or host external Thread Services to migrate your user Thread replication to. window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'AW-856649624');","title":"Account deletion"},{"location":"hub/apis/","text":"APIs and API Keys \u00b6 In this section, we'll walk through the basic concepts useful when building your app to use the Hub. We'll break the discussion into a few key parts, shown in the table of contents to the right. A Tour of Available APIs \u00b6 Buckets \u00b6 Buckets provide S3-like data storage on IPFS. Just as you can create Buckets with the Hub CLI , you can create Buckets using JavaScript with js-hub . The js-hub library allows you to create and edit Buckets owned by you or your organization using an account key . Alternatively, you can use Buckets to store your user's data using a user group key . ThreadDB \u00b6 ThreadDB is a mongo-like database that runs on IPFS. You can use js-hub connect to the Hub's hosted thread server ( Client ) to push and persist encrypted data on an IPFS-backed database. Alternatively, you can embed local, p2p databases in your app that use remote IPFS peers for pinning and remote ThreadDB peers to relay updates ( Database ). User Inboxes \u00b6 The Users API provides mechanisms for sending and receiving messages between Hub users. Mailboxes are built on ThreadDB. Hub mailboxes are a unique inboxing and messaging system designed for modern apps where users hold private keys linked to their identity. With just their private and public key, a user can send and receive encrypted messages to other users in your app. API Access \u00b6 When building apps or services, you can access the Hub APIs to push new buckets, relay or persist threads, ensure data from your app is available on the IPFS network, and more. You can access those APIs through the use of API keys. API Keys \u00b6 The Hub has two forms of API key, an Account Key and a User Group Key . Account Keys can grant access to the developers own resources (e.g. Buckets you create using the command-line interface). If Account Keys are generated with the -o (organization) flag, they will grant access to that organization's resources. Example uses include, integrating your Buckets into CI, dashboards, team messaging integration, etc. User Group Keys only grant access to new resources for new identities, not those of the developer. User group keys can be used in an application to allow app users to leverage Hub APIs (e.g. create and push new buckets). User group keys do not have permission to access the developer or organization resources, but threads and buckets created using these keys are counted against API limits . Key Use and Security \u00b6 API keys are project-centric credentials that you can use to provision your Hub resources to end users (either within your organization or in a public app). We recommend reading this thorough overview of API key design and best practices . Access Summary \u00b6 Below is a brief summary of the Hub resources you may create and access with each key type. Resource example Owner CLI Required Key Developer Threads Hub Developer create, access Account Key Developer Buckets Hub Developer create, access Account Key Organization Threads Hub Developer(s) create, access Account Key Organization Buckets Hub Developer(s) create, access Account Key User Threads App User User Group Key User Buckets App User User Group Key Creating Keys \u00b6 Account Key \u00b6 To create a new Account Key using hub key create and selecting the account option. See CLI options User Group Key \u00b6 To create a new user group key using hub key create and selecting the user group option. If you are building an app in an organization, use HUB_ORG=<org name> hub key create to link a new key to the organization not your personal account. There are currently no migration tools, so we recommend creating a new organization or using an existing organization when starting a new app (see Organizations ). \u279c hub key create # select the 'user' option \u2714 user KEY SECRET TYPE bqab5csdh...no6jjezox4 bm2tk476yivwlw...3a4cayll7ztha user > Success! Created new API key and secret Non-signing User Group keys \u00b6 You can use insecure keys with the API by creating non-signing keys. These keys are meant to use during development only. Read the tutorial on development mode to use these keys. Updating User Group keys \u00b6 You can replace your keys in your app at any time and the user will still have access to their Threads and Buckets as long as the key is connected to the same developer or organization. See CLI commands API Libraries \u00b6 You can find all remote Thread and Bucket APIs in the textile libraries below. These libraries are meant to work in combination with the threads libraries when you want to create and manage Threads database in your app. JS Hub Start threads, buckets, and user creation in any JavaScript app. JS Hub Use the Buckets client from Go Hub CLI Use scripting and command-line tooling with the Hub CLI.","title":"APIs & API Keys"},{"location":"hub/apis/#apis-and-api-keys","text":"In this section, we'll walk through the basic concepts useful when building your app to use the Hub. We'll break the discussion into a few key parts, shown in the table of contents to the right.","title":"APIs and API Keys"},{"location":"hub/apis/#a-tour-of-available-apis","text":"","title":"A Tour of Available APIs"},{"location":"hub/apis/#buckets","text":"Buckets provide S3-like data storage on IPFS. Just as you can create Buckets with the Hub CLI , you can create Buckets using JavaScript with js-hub . The js-hub library allows you to create and edit Buckets owned by you or your organization using an account key . Alternatively, you can use Buckets to store your user's data using a user group key .","title":"Buckets"},{"location":"hub/apis/#threaddb","text":"ThreadDB is a mongo-like database that runs on IPFS. You can use js-hub connect to the Hub's hosted thread server ( Client ) to push and persist encrypted data on an IPFS-backed database. Alternatively, you can embed local, p2p databases in your app that use remote IPFS peers for pinning and remote ThreadDB peers to relay updates ( Database ).","title":"ThreadDB"},{"location":"hub/apis/#user-inboxes","text":"The Users API provides mechanisms for sending and receiving messages between Hub users. Mailboxes are built on ThreadDB. Hub mailboxes are a unique inboxing and messaging system designed for modern apps where users hold private keys linked to their identity. With just their private and public key, a user can send and receive encrypted messages to other users in your app.","title":"User Inboxes"},{"location":"hub/apis/#api-access","text":"When building apps or services, you can access the Hub APIs to push new buckets, relay or persist threads, ensure data from your app is available on the IPFS network, and more. You can access those APIs through the use of API keys.","title":"API Access"},{"location":"hub/apis/#api-keys","text":"The Hub has two forms of API key, an Account Key and a User Group Key . Account Keys can grant access to the developers own resources (e.g. Buckets you create using the command-line interface). If Account Keys are generated with the -o (organization) flag, they will grant access to that organization's resources. Example uses include, integrating your Buckets into CI, dashboards, team messaging integration, etc. User Group Keys only grant access to new resources for new identities, not those of the developer. User group keys can be used in an application to allow app users to leverage Hub APIs (e.g. create and push new buckets). User group keys do not have permission to access the developer or organization resources, but threads and buckets created using these keys are counted against API limits .","title":"API Keys"},{"location":"hub/apis/#key-use-and-security","text":"API keys are project-centric credentials that you can use to provision your Hub resources to end users (either within your organization or in a public app). We recommend reading this thorough overview of API key design and best practices .","title":"Key Use and Security"},{"location":"hub/apis/#access-summary","text":"Below is a brief summary of the Hub resources you may create and access with each key type. Resource example Owner CLI Required Key Developer Threads Hub Developer create, access Account Key Developer Buckets Hub Developer create, access Account Key Organization Threads Hub Developer(s) create, access Account Key Organization Buckets Hub Developer(s) create, access Account Key User Threads App User User Group Key User Buckets App User User Group Key","title":"Access Summary"},{"location":"hub/apis/#creating-keys","text":"","title":"Creating Keys"},{"location":"hub/apis/#account-key","text":"To create a new Account Key using hub key create and selecting the account option. See CLI options","title":"Account Key"},{"location":"hub/apis/#user-group-key","text":"To create a new user group key using hub key create and selecting the user group option. If you are building an app in an organization, use HUB_ORG=<org name> hub key create to link a new key to the organization not your personal account. There are currently no migration tools, so we recommend creating a new organization or using an existing organization when starting a new app (see Organizations ). \u279c hub key create # select the 'user' option \u2714 user KEY SECRET TYPE bqab5csdh...no6jjezox4 bm2tk476yivwlw...3a4cayll7ztha user > Success! Created new API key and secret","title":"User Group Key"},{"location":"hub/apis/#non-signing-user-group-keys","text":"You can use insecure keys with the API by creating non-signing keys. These keys are meant to use during development only. Read the tutorial on development mode to use these keys.","title":"Non-signing User Group keys"},{"location":"hub/apis/#updating-user-group-keys","text":"You can replace your keys in your app at any time and the user will still have access to their Threads and Buckets as long as the key is connected to the same developer or organization. See CLI commands","title":"Updating User Group keys"},{"location":"hub/apis/#api-libraries","text":"You can find all remote Thread and Bucket APIs in the textile libraries below. These libraries are meant to work in combination with the threads libraries when you want to create and manage Threads database in your app.","title":"API Libraries"},{"location":"hub/development/","text":"Getting Started \u00b6 In this section, we'll walk through the basic concepts useful when building your app to use the Hub. We'll break the discussion into a few key parts, shown in the table of contents to the right. Available APIs \u00b6 Buckets \u00b6 Buckets provide S3-like data storage on IPFS. Just as you can create Buckets with the Hub CLI , you can create Buckets using JavaScript with js-hub . The js-hub library allows you to create and edit Buckets owned by you or your organization using an account key . Alternatively, you can use Buckets to store your user's data using a user group key . ThreadDB \u00b6 ThreadDB is a mongo-like database that runs on IPFS. You can use it in combination with js-hub to add replication and relay to your user's databases. When combined, js-threads and js-hub allow you to embed private, p2p databases in your app that use remote IPFS peers for pinning and remote ThreadDB peers to relay updates to all parties. This configuration will help you scale your app and offer the highest quality experience to your users. API Access \u00b6 When building apps or services, you can access the Hub APIs to push new buckets, relay or persist threads, ensure data from your app is available on the IPFS network, and more. You can access those APIs through the use of API keys. Roles \u00b6 There are only three roles on the Hub, the developer, a developer's orgs, and the user. Developers : You. You are a primary account owner. You can create new API keys, create and join new Organizations, and access admin APIs. You can create your own Buckets and Threads. You can use the CLI with your account do all the mentioned. Organizations : You and your collaborators. Members can share admin control of API keys. Members can share access to and synchronize Bucket state across all members. Referenced through docs as simply, Org . Users : Accounts generated by your apps using a User Group API key. Your app can create Threads and Buckets owned by these users. These users can then add or remove content from those assets based on their identity. They cannot use the CLI and cannot create new API keys. API Keys \u00b6 The Hub has two forms of API key, an Account Key and a User Group Key . Account Keys can grant access to the developers own resources (e.g. Buckets you create using the command-line interface). If Account Keys are generated with the -o (organization) flag, they will grant access to that organization's resources. Example uses include, integrating your Buckets into CI, dashboards, team messaging integration, etc. User Group Keys only grant access to new resources for new identities, not those of the developer. User group keys can be used in an application to allow app users to leverage Hub APIs (e.g. create and push new buckets). User group keys do not have permission to access the developer or organization resources, but threads and buckets created using these keys are counted against API limits . Access Summary \u00b6 Below is a brief summary of the Hub resources you may create and access with each key type. Resource example Owner CLI Required Key Developer Threads Hub Developer create, access Account Key Developer Buckets Hub Developer create, access Account Key Organization Threads Hub Developer(s) create, access Account Key Organization Buckets Hub Developer(s) create, access Account Key User Threads App User User Group Key User Buckets App User User Group Key Creating Keys \u00b6 Account Key \u00b6 To create a new Account Key using hub key create and selecting the account option. See CLI options User Group Key \u00b6 To create a new user group key using hub key create and selecting the user group option. If you are building an app in an organization, use HUB_ORG=<org name> hub key create to link a new key to the organization not your personal account. There is currently no migration tools, so we recommend creating a new organization or using an existing organization when starting a new app (see Organizations ). \u279c hub key create # select the 'user' option \u2714 user KEY SECRET TYPE bqab5csdh...no6jjezox4 bm2tk476yivwlw...3a4cayll7ztha user > Success! Created new API key and secret Non-signing User Group keys \u00b6 You can use insecure keys with the API by creating non-signing keys. These keys are meant to use during development only. Read the tutorial on development mode to use these keys. Updating User Group keys \u00b6 You can replace your keys in your app at any time and the user will still have access to their Threads and Buckets as long as the key is connected to the same developer or organization. See CLI commands Identity and API access \u00b6 Generic identity model \u00b6 Identities also provide a way for developers to allocate resources (i.e., storage) for a particular user, and in fact, is a key component in ensuring that a user controls their own data . Hub, Buckets, and ThreadDB APIs are flexible when it comes to user identity, allowing you to handle user identities (for access control and security/encryption) in the best way for your app and your users. In order to handle multiple peers collaborating on a single database, as well as the ability to handle storage on behalf of a user, Hub APIs expect a simple Identity interface for singing and validating updates. You can create a basic identity for our user in a JavaScript application using the PrivateKey object available in the Hub library. In practice, you might have your own identity provider, or you might want to use a hierarchical key/wallet or mnemonic phrase to help store a users keys for them. Whatever you decide, Textile's generic identity interface should be able to support it. import { PrivateKey } from '@textile/hub' async function example () { const identity = await PrivateKey . fromRandom () // Random identity return identity } Read more about Identity in the identity tutorial . Data Ownership \u00b6 The databases and buckets you create over the APIs are owned in one of three ways. Developer owned. If you use an account key with the Buckets or ThreadDB APIs, the data will be linked directly to your account. Org owned. If you create an account key using the HUB_ORG environmental variable, the Buckets and Threads will be linked to the organization. User owned. If you create a user group key, Textile allows your app to provision new Buckets and Threads on behalf of your users. This data will be signed and owned by your end-users and only accessible to them. API keys add a lot of flexibility in how you use resources on the Hub. A developer is able to access Hub resources as themselves (i.e., the developer), with all the administrative capabilities that entails, or as users of their app, which are sandboxed but can create Threads (and Buckets) of their own within that user-scoped sandbox. This is a very powerful framework for accessing and allocating developer resources on behalf of users, while still providing the control and quality user-experience that apps built on Threads should provide. User authorization \u00b6 This step is only necessary if you are using production (signing required) API keys. If you are in development mode , you don't need to do this step. Authorizing the user with your user group key and Secret will allow the user to store threads and buckets using your developer resources on the Hub. If you are running in development mode and created a key that doesn't require signing. Read more about setting up authentication and authorization in production mode . Libraries \u00b6 You can find all remote Thread and Bucket APIs in the textile libraries below. These libraries are meant to work in combination with the threads libraries when you want to create and manage Threads database in your app. Here are the libraries you will find useful to start building today. Library Browser, React Native, & NodeJS js-hub Golang Libraries go-threads , buckets Command-line Hub CLI , thread-shell (coming)","title":"Getting Started"},{"location":"hub/development/#getting-started","text":"In this section, we'll walk through the basic concepts useful when building your app to use the Hub. We'll break the discussion into a few key parts, shown in the table of contents to the right.","title":"Getting Started"},{"location":"hub/development/#available-apis","text":"","title":"Available APIs"},{"location":"hub/development/#buckets","text":"Buckets provide S3-like data storage on IPFS. Just as you can create Buckets with the Hub CLI , you can create Buckets using JavaScript with js-hub . The js-hub library allows you to create and edit Buckets owned by you or your organization using an account key . Alternatively, you can use Buckets to store your user's data using a user group key .","title":"Buckets"},{"location":"hub/development/#threaddb","text":"ThreadDB is a mongo-like database that runs on IPFS. You can use it in combination with js-hub to add replication and relay to your user's databases. When combined, js-threads and js-hub allow you to embed private, p2p databases in your app that use remote IPFS peers for pinning and remote ThreadDB peers to relay updates to all parties. This configuration will help you scale your app and offer the highest quality experience to your users.","title":"ThreadDB"},{"location":"hub/development/#api-access","text":"When building apps or services, you can access the Hub APIs to push new buckets, relay or persist threads, ensure data from your app is available on the IPFS network, and more. You can access those APIs through the use of API keys.","title":"API Access"},{"location":"hub/development/#roles","text":"There are only three roles on the Hub, the developer, a developer's orgs, and the user. Developers : You. You are a primary account owner. You can create new API keys, create and join new Organizations, and access admin APIs. You can create your own Buckets and Threads. You can use the CLI with your account do all the mentioned. Organizations : You and your collaborators. Members can share admin control of API keys. Members can share access to and synchronize Bucket state across all members. Referenced through docs as simply, Org . Users : Accounts generated by your apps using a User Group API key. Your app can create Threads and Buckets owned by these users. These users can then add or remove content from those assets based on their identity. They cannot use the CLI and cannot create new API keys.","title":"Roles"},{"location":"hub/development/#api-keys","text":"The Hub has two forms of API key, an Account Key and a User Group Key . Account Keys can grant access to the developers own resources (e.g. Buckets you create using the command-line interface). If Account Keys are generated with the -o (organization) flag, they will grant access to that organization's resources. Example uses include, integrating your Buckets into CI, dashboards, team messaging integration, etc. User Group Keys only grant access to new resources for new identities, not those of the developer. User group keys can be used in an application to allow app users to leverage Hub APIs (e.g. create and push new buckets). User group keys do not have permission to access the developer or organization resources, but threads and buckets created using these keys are counted against API limits .","title":"API Keys"},{"location":"hub/development/#access-summary","text":"Below is a brief summary of the Hub resources you may create and access with each key type. Resource example Owner CLI Required Key Developer Threads Hub Developer create, access Account Key Developer Buckets Hub Developer create, access Account Key Organization Threads Hub Developer(s) create, access Account Key Organization Buckets Hub Developer(s) create, access Account Key User Threads App User User Group Key User Buckets App User User Group Key","title":"Access Summary"},{"location":"hub/development/#creating-keys","text":"","title":"Creating Keys"},{"location":"hub/development/#account-key","text":"To create a new Account Key using hub key create and selecting the account option. See CLI options","title":"Account Key"},{"location":"hub/development/#user-group-key","text":"To create a new user group key using hub key create and selecting the user group option. If you are building an app in an organization, use HUB_ORG=<org name> hub key create to link a new key to the organization not your personal account. There is currently no migration tools, so we recommend creating a new organization or using an existing organization when starting a new app (see Organizations ). \u279c hub key create # select the 'user' option \u2714 user KEY SECRET TYPE bqab5csdh...no6jjezox4 bm2tk476yivwlw...3a4cayll7ztha user > Success! Created new API key and secret","title":"User Group Key"},{"location":"hub/development/#non-signing-user-group-keys","text":"You can use insecure keys with the API by creating non-signing keys. These keys are meant to use during development only. Read the tutorial on development mode to use these keys.","title":"Non-signing User Group keys"},{"location":"hub/development/#updating-user-group-keys","text":"You can replace your keys in your app at any time and the user will still have access to their Threads and Buckets as long as the key is connected to the same developer or organization. See CLI commands","title":"Updating User Group keys"},{"location":"hub/development/#identity-and-api-access","text":"","title":"Identity and API access"},{"location":"hub/development/#generic-identity-model","text":"Identities also provide a way for developers to allocate resources (i.e., storage) for a particular user, and in fact, is a key component in ensuring that a user controls their own data . Hub, Buckets, and ThreadDB APIs are flexible when it comes to user identity, allowing you to handle user identities (for access control and security/encryption) in the best way for your app and your users. In order to handle multiple peers collaborating on a single database, as well as the ability to handle storage on behalf of a user, Hub APIs expect a simple Identity interface for singing and validating updates. You can create a basic identity for our user in a JavaScript application using the PrivateKey object available in the Hub library. In practice, you might have your own identity provider, or you might want to use a hierarchical key/wallet or mnemonic phrase to help store a users keys for them. Whatever you decide, Textile's generic identity interface should be able to support it. import { PrivateKey } from '@textile/hub' async function example () { const identity = await PrivateKey . fromRandom () // Random identity return identity } Read more about Identity in the identity tutorial .","title":"Generic identity model"},{"location":"hub/development/#data-ownership","text":"The databases and buckets you create over the APIs are owned in one of three ways. Developer owned. If you use an account key with the Buckets or ThreadDB APIs, the data will be linked directly to your account. Org owned. If you create an account key using the HUB_ORG environmental variable, the Buckets and Threads will be linked to the organization. User owned. If you create a user group key, Textile allows your app to provision new Buckets and Threads on behalf of your users. This data will be signed and owned by your end-users and only accessible to them. API keys add a lot of flexibility in how you use resources on the Hub. A developer is able to access Hub resources as themselves (i.e., the developer), with all the administrative capabilities that entails, or as users of their app, which are sandboxed but can create Threads (and Buckets) of their own within that user-scoped sandbox. This is a very powerful framework for accessing and allocating developer resources on behalf of users, while still providing the control and quality user-experience that apps built on Threads should provide.","title":"Data Ownership"},{"location":"hub/development/#user-authorization","text":"This step is only necessary if you are using production (signing required) API keys. If you are in development mode , you don't need to do this step. Authorizing the user with your user group key and Secret will allow the user to store threads and buckets using your developer resources on the Hub. If you are running in development mode and created a key that doesn't require signing. Read more about setting up authentication and authorization in production mode .","title":"User authorization"},{"location":"hub/development/#libraries","text":"You can find all remote Thread and Bucket APIs in the textile libraries below. These libraries are meant to work in combination with the threads libraries when you want to create and manage Threads database in your app. Here are the libraries you will find useful to start building today. Library Browser, React Native, & NodeJS js-hub Golang Libraries go-threads , buckets Command-line Hub CLI , thread-shell (coming)","title":"Libraries"},{"location":"hub/cli/hub/","text":"hub \u00b6 The Hub Client. Options \u00b6 --api string API target (default \"api.textile.io:443\") -h, --help help for hub -o, --org string Org username -s, --session string User session token Alternatively, you can use an environmental variable, HUB_ORG , in place of the --org flag. SEE ALSO \u00b6 hub buck - Manage an object storage bucket hub destroy - Destroy your account hub init - Initialize account hub keys - API key management hub login - Login hub logout - Logout hub orgs - Org management hub threads - Thread management hub whoami - Show current user","title":"Overview"},{"location":"hub/cli/hub/#hub","text":"The Hub Client.","title":"hub"},{"location":"hub/cli/hub/#options","text":"--api string API target (default \"api.textile.io:443\") -h, --help help for hub -o, --org string Org username -s, --session string User session token Alternatively, you can use an environmental variable, HUB_ORG , in place of the --org flag.","title":"Options"},{"location":"hub/cli/hub/#see-also","text":"hub buck - Manage an object storage bucket hub destroy - Destroy your account hub init - Initialize account hub keys - API key management hub login - Login hub logout - Logout hub orgs - Org management hub threads - Thread management hub whoami - Show current user","title":"SEE ALSO"},{"location":"hub/cli/hub_buck/","text":"hub buck \u00b6 Manages files and folders in an object storage bucket. Options \u00b6 -h, --help help for buck SEE ALSO \u00b6 hub - Hub Client hub buck add - Add adds a UnixFs DAG locally at path hub buck archive - Create a Filecoin archive hub buck cat - Cat bucket objects at path hub buck decrypt - Decrypt bucket objects at path with password hub buck destroy - Destroy bucket and all objects hub buck encrypt - Encrypt file with a password hub buck init - Initialize a new or existing bucket hub buck links - Show links to where this bucket can be accessed hub buck ls - List top-level or nested bucket objects hub buck pull - Pull bucket object changes hub buck push - Push bucket object changes hub buck root - Show bucket root CIDs hub buck status - Show bucket object changes hub buck watch - Watch auto-pushes local changes to the remote","title":"Overview"},{"location":"hub/cli/hub_buck/#hub-buck","text":"Manages files and folders in an object storage bucket.","title":"hub buck"},{"location":"hub/cli/hub_buck/#options","text":"-h, --help help for buck","title":"Options"},{"location":"hub/cli/hub_buck/#see-also","text":"hub - Hub Client hub buck add - Add adds a UnixFs DAG locally at path hub buck archive - Create a Filecoin archive hub buck cat - Cat bucket objects at path hub buck decrypt - Decrypt bucket objects at path with password hub buck destroy - Destroy bucket and all objects hub buck encrypt - Encrypt file with a password hub buck init - Initialize a new or existing bucket hub buck links - Show links to where this bucket can be accessed hub buck ls - List top-level or nested bucket objects hub buck pull - Pull bucket object changes hub buck push - Push bucket object changes hub buck root - Show bucket root CIDs hub buck status - Show bucket object changes hub buck watch - Watch auto-pushes local changes to the remote","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_add/","text":"hub buck add \u00b6 Add adds a UnixFs DAG locally at path, merging with existing content. hub buck add [cid] [path] [flags] Options \u00b6 -h, --help help for add -y, --yes Skips confirmations prompts to always overwrite files and merge folders SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Add"},{"location":"hub/cli/hub_buck_add/#hub-buck-add","text":"Add adds a UnixFs DAG locally at path, merging with existing content. hub buck add [cid] [path] [flags]","title":"hub buck add"},{"location":"hub/cli/hub_buck_add/#options","text":"-h, --help help for add -y, --yes Skips confirmations prompts to always overwrite files and merge folders","title":"Options"},{"location":"hub/cli/hub_buck_add/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_archive/","text":"hub buck archive \u00b6 Creates a Filecoin archive from the remote bucket root. hub buck archive [flags] Options \u00b6 -h, --help help for archive SEE ALSO \u00b6 hub buck - Manage an object storage bucket hub buck archive info - Show info about the current archive hub buck archive status - Show status of the latest archive","title":"Archive"},{"location":"hub/cli/hub_buck_archive/#hub-buck-archive","text":"Creates a Filecoin archive from the remote bucket root. hub buck archive [flags]","title":"hub buck archive"},{"location":"hub/cli/hub_buck_archive/#options","text":"-h, --help help for archive","title":"Options"},{"location":"hub/cli/hub_buck_archive/#see-also","text":"hub buck - Manage an object storage bucket hub buck archive info - Show info about the current archive hub buck archive status - Show status of the latest archive","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_archive_info/","text":"hub buck archive info \u00b6 Shows information about the current archive. hub buck archive info [flags] Options \u00b6 -h, --help help for info SEE ALSO \u00b6 hub buck archive - Create a Filecoin archive","title":"hub buck archive info"},{"location":"hub/cli/hub_buck_archive_info/#hub-buck-archive-info","text":"Shows information about the current archive. hub buck archive info [flags]","title":"hub buck archive info"},{"location":"hub/cli/hub_buck_archive_info/#options","text":"-h, --help help for info","title":"Options"},{"location":"hub/cli/hub_buck_archive_info/#see-also","text":"hub buck archive - Create a Filecoin archive","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_archive_status/","text":"hub buck archive status \u00b6 Shows the status of the most recent bucket archive. hub buck archive status [flags] Options \u00b6 -h, --help help for status -w, --watch Watch execution log SEE ALSO \u00b6 hub buck archive - Create a Filecoin archive","title":"hub buck archive status"},{"location":"hub/cli/hub_buck_archive_status/#hub-buck-archive-status","text":"Shows the status of the most recent bucket archive. hub buck archive status [flags]","title":"hub buck archive status"},{"location":"hub/cli/hub_buck_archive_status/#options","text":"-h, --help help for status -w, --watch Watch execution log","title":"Options"},{"location":"hub/cli/hub_buck_archive_status/#see-also","text":"hub buck archive - Create a Filecoin archive","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_cat/","text":"hub buck cat \u00b6 Cats bucket objects at path. hub buck cat [path] [flags] Options \u00b6 -h, --help help for cat SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Cat"},{"location":"hub/cli/hub_buck_cat/#hub-buck-cat","text":"Cats bucket objects at path. hub buck cat [path] [flags]","title":"hub buck cat"},{"location":"hub/cli/hub_buck_cat/#options","text":"-h, --help help for cat","title":"Options"},{"location":"hub/cli/hub_buck_cat/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_decrypt/","text":"hub buck decrypt \u00b6 Decrypts bucket objects at path with the given password and writes to stdout. hub buck decrypt [path] [password] [flags] Options \u00b6 -h, --help help for decrypt -p, --password string Decryption password SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Decrypt"},{"location":"hub/cli/hub_buck_decrypt/#hub-buck-decrypt","text":"Decrypts bucket objects at path with the given password and writes to stdout. hub buck decrypt [path] [password] [flags]","title":"hub buck decrypt"},{"location":"hub/cli/hub_buck_decrypt/#options","text":"-h, --help help for decrypt -p, --password string Decryption password","title":"Options"},{"location":"hub/cli/hub_buck_decrypt/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_destroy/","text":"hub buck destroy \u00b6 Destroys the bucket and all objects. hub buck destroy [flags] Options \u00b6 -h, --help help for destroy SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Destroy"},{"location":"hub/cli/hub_buck_destroy/#hub-buck-destroy","text":"Destroys the bucket and all objects. hub buck destroy [flags]","title":"hub buck destroy"},{"location":"hub/cli/hub_buck_destroy/#options","text":"-h, --help help for destroy","title":"Options"},{"location":"hub/cli/hub_buck_destroy/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_encrypt/","text":"hub buck encrypt \u00b6 Encrypts file with a password (WARNING: Password is not recoverable). hub buck encrypt [file] [password] [flags] Options \u00b6 -h, --help help for encrypt -p, --password string Encryption password SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Encrypt"},{"location":"hub/cli/hub_buck_encrypt/#hub-buck-encrypt","text":"Encrypts file with a password (WARNING: Password is not recoverable). hub buck encrypt [file] [password] [flags]","title":"hub buck encrypt"},{"location":"hub/cli/hub_buck_encrypt/#options","text":"-h, --help help for encrypt -p, --password string Encryption password","title":"Options"},{"location":"hub/cli/hub_buck_encrypt/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_init/","text":"hub buck init \u00b6 Initializes a new or existing bucket. A .textile config directory and a seed file will be created in the current working directory. Existing configs will not be overwritten. Use the '--existing' flag to initialize from an existing remote bucket. Use the '--cid' flag to initialize from an existing UnixFS DAG. hub buck init [flags] Options \u00b6 --cid string Bootstrap the bucket with a UnixFS Cid from the IPFS network -e, --existing Initializes from an existing remote bucket if true -h, --help help for init --key string Bucket key -n, --name string Bucket name -p, --private Obfuscates files and folders with encryption --thread string Thread ID SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Init"},{"location":"hub/cli/hub_buck_init/#hub-buck-init","text":"Initializes a new or existing bucket. A .textile config directory and a seed file will be created in the current working directory. Existing configs will not be overwritten. Use the '--existing' flag to initialize from an existing remote bucket. Use the '--cid' flag to initialize from an existing UnixFS DAG. hub buck init [flags]","title":"hub buck init"},{"location":"hub/cli/hub_buck_init/#options","text":"--cid string Bootstrap the bucket with a UnixFS Cid from the IPFS network -e, --existing Initializes from an existing remote bucket if true -h, --help help for init --key string Bucket key -n, --name string Bucket name -p, --private Obfuscates files and folders with encryption --thread string Thread ID","title":"Options"},{"location":"hub/cli/hub_buck_init/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_links/","text":"hub buck links \u00b6 Displays a thread, IPNS, and website link to this bucket. hub buck links [flags] Options \u00b6 -h, --help help for links SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Links"},{"location":"hub/cli/hub_buck_links/#hub-buck-links","text":"Displays a thread, IPNS, and website link to this bucket. hub buck links [flags]","title":"hub buck links"},{"location":"hub/cli/hub_buck_links/#options","text":"-h, --help help for links","title":"Options"},{"location":"hub/cli/hub_buck_links/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_ls/","text":"hub buck ls \u00b6 Lists top-level or nested bucket objects. hub buck ls [path] [flags] Options \u00b6 -h, --help help for ls SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Ls"},{"location":"hub/cli/hub_buck_ls/#hub-buck-ls","text":"Lists top-level or nested bucket objects. hub buck ls [path] [flags]","title":"hub buck ls"},{"location":"hub/cli/hub_buck_ls/#options","text":"-h, --help help for ls","title":"Options"},{"location":"hub/cli/hub_buck_ls/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_pull/","text":"hub buck pull \u00b6 Pulls paths that have been added to and paths that have been removed or differ from the remote bucket root. hub buck pull [flags] Options \u00b6 -f, --force Force pull all remote files if true --hard Pulls and prunes local changes if true -h, --help help for pull -y, --yes Skips the confirmation prompt if true SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Pull"},{"location":"hub/cli/hub_buck_pull/#hub-buck-pull","text":"Pulls paths that have been added to and paths that have been removed or differ from the remote bucket root. hub buck pull [flags]","title":"hub buck pull"},{"location":"hub/cli/hub_buck_pull/#options","text":"-f, --force Force pull all remote files if true --hard Pulls and prunes local changes if true -h, --help help for pull -y, --yes Skips the confirmation prompt if true","title":"Options"},{"location":"hub/cli/hub_buck_pull/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_push/","text":"hub buck push \u00b6 Pushes paths that have been added to and paths that have been removed or differ from the local bucket root. hub buck push [flags] Options \u00b6 -f, --force Allows non-fast-forward updates if true -h, --help help for push --maxsize int Max bucket size in MiB (default 1024) -y, --yes Skips the confirmation prompt if true SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Push"},{"location":"hub/cli/hub_buck_push/#hub-buck-push","text":"Pushes paths that have been added to and paths that have been removed or differ from the local bucket root. hub buck push [flags]","title":"hub buck push"},{"location":"hub/cli/hub_buck_push/#options","text":"-f, --force Allows non-fast-forward updates if true -h, --help help for push --maxsize int Max bucket size in MiB (default 1024) -y, --yes Skips the confirmation prompt if true","title":"Options"},{"location":"hub/cli/hub_buck_push/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_root/","text":"hub buck root \u00b6 Shows the local and remote bucket root CIDs (these will differ if the bucket is encrypted). hub buck root [flags] Options \u00b6 -h, --help help for root SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Root"},{"location":"hub/cli/hub_buck_root/#hub-buck-root","text":"Shows the local and remote bucket root CIDs (these will differ if the bucket is encrypted). hub buck root [flags]","title":"hub buck root"},{"location":"hub/cli/hub_buck_root/#options","text":"-h, --help help for root","title":"Options"},{"location":"hub/cli/hub_buck_root/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_status/","text":"hub buck status \u00b6 Displays paths that have been added to and paths that have been removed or differ from the local bucket root. hub buck status [flags] Options \u00b6 -h, --help help for status SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Status"},{"location":"hub/cli/hub_buck_status/#hub-buck-status","text":"Displays paths that have been added to and paths that have been removed or differ from the local bucket root. hub buck status [flags]","title":"hub buck status"},{"location":"hub/cli/hub_buck_status/#options","text":"-h, --help help for status","title":"Options"},{"location":"hub/cli/hub_buck_status/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_watch/","text":"hub buck watch \u00b6 Watch auto-pushes local changes to the remote. hub buck watch [flags] Options \u00b6 -h, --help help for watch SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Watch"},{"location":"hub/cli/hub_buck_watch/#hub-buck-watch","text":"Watch auto-pushes local changes to the remote. hub buck watch [flags]","title":"hub buck watch"},{"location":"hub/cli/hub_buck_watch/#options","text":"-h, --help help for watch","title":"Options"},{"location":"hub/cli/hub_buck_watch/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_destroy/","text":"hub destroy \u00b6 Destroys your Hub account and all associated data. hub destroy [flags] Options \u00b6 -h, --help help for destroy SEE ALSO \u00b6 hub - Hub Client","title":"hub destroy"},{"location":"hub/cli/hub_destroy/#hub-destroy","text":"Destroys your Hub account and all associated data. hub destroy [flags]","title":"hub destroy"},{"location":"hub/cli/hub_destroy/#options","text":"-h, --help help for destroy","title":"Options"},{"location":"hub/cli/hub_destroy/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"hub/cli/hub_init/","text":"hub init \u00b6 Initializes a new Hub account. hub init [flags] Options \u00b6 -h, --help help for init SEE ALSO \u00b6 hub - Hub Client","title":"hub init"},{"location":"hub/cli/hub_init/#hub-init","text":"Initializes a new Hub account. hub init [flags]","title":"hub init"},{"location":"hub/cli/hub_init/#options","text":"-h, --help help for init","title":"Options"},{"location":"hub/cli/hub_init/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"hub/cli/hub_keys/","text":"hub keys \u00b6 Manages your API keys. Options \u00b6 -h, --help help for keys SEE ALSO \u00b6 hub - Hub Client hub keys create - Create an API key and secret hub keys invalidate - Invalidate an API key hub keys ls - List your API keys","title":"API Keys"},{"location":"hub/cli/hub_keys/#hub-keys","text":"Manages your API keys.","title":"hub keys"},{"location":"hub/cli/hub_keys/#options","text":"-h, --help help for keys","title":"Options"},{"location":"hub/cli/hub_keys/#see-also","text":"hub - Hub Client hub keys create - Create an API key and secret hub keys invalidate - Invalidate an API key hub keys ls - List your API keys","title":"SEE ALSO"},{"location":"hub/cli/hub_keys_create/","text":"hub keys create \u00b6 Creates a new API key and secret. Keys are used by apps and services that leverage buckets or threads. Using the 'HUB_ORG' environmental variable will create a new key under the Organization's account. There are two types of API keys: 1. 'Account' keys provide direct access to developer/org account buckets and threads. 2. 'User Group' keys provide existing non-admin identities (e.g. app users) access to their own buckets and threads, using the resources of the parent account (i.e. the developer or organization). API secrets are used for Signature Authentication, which is a security measure that can prevent outsiders from using your API key. API secrets should be kept safely on a backend server, not in publicly readable client code. However, for development purposes, you may opt-out of Signature Authentication during key creation. hub keys create [flags] Options \u00b6 -h, --help help for create SEE ALSO \u00b6 hub keys - API key management","title":"hub keys create"},{"location":"hub/cli/hub_keys_create/#hub-keys-create","text":"Creates a new API key and secret. Keys are used by apps and services that leverage buckets or threads. Using the 'HUB_ORG' environmental variable will create a new key under the Organization's account. There are two types of API keys: 1. 'Account' keys provide direct access to developer/org account buckets and threads. 2. 'User Group' keys provide existing non-admin identities (e.g. app users) access to their own buckets and threads, using the resources of the parent account (i.e. the developer or organization). API secrets are used for Signature Authentication, which is a security measure that can prevent outsiders from using your API key. API secrets should be kept safely on a backend server, not in publicly readable client code. However, for development purposes, you may opt-out of Signature Authentication during key creation. hub keys create [flags]","title":"hub keys create"},{"location":"hub/cli/hub_keys_create/#options","text":"-h, --help help for create","title":"Options"},{"location":"hub/cli/hub_keys_create/#see-also","text":"hub keys - API key management","title":"SEE ALSO"},{"location":"hub/cli/hub_keys_invalidate/","text":"hub keys invalidate \u00b6 Invalidates an API key. Invalidated keys cannot be used to create new threads. hub keys invalidate [flags] Options \u00b6 -h, --help help for invalidate SEE ALSO \u00b6 hub keys - API key management","title":"hub keys invalidate"},{"location":"hub/cli/hub_keys_invalidate/#hub-keys-invalidate","text":"Invalidates an API key. Invalidated keys cannot be used to create new threads. hub keys invalidate [flags]","title":"hub keys invalidate"},{"location":"hub/cli/hub_keys_invalidate/#options","text":"-h, --help help for invalidate","title":"Options"},{"location":"hub/cli/hub_keys_invalidate/#see-also","text":"hub keys - API key management","title":"SEE ALSO"},{"location":"hub/cli/hub_keys_ls/","text":"hub keys ls \u00b6 Lists all of your API keys. hub keys ls [flags] Options \u00b6 -h, --help help for ls SEE ALSO \u00b6 hub keys - API key management","title":"hub keys ls"},{"location":"hub/cli/hub_keys_ls/#hub-keys-ls","text":"Lists all of your API keys. hub keys ls [flags]","title":"hub keys ls"},{"location":"hub/cli/hub_keys_ls/#options","text":"-h, --help help for ls","title":"Options"},{"location":"hub/cli/hub_keys_ls/#see-also","text":"hub keys - API key management","title":"SEE ALSO"},{"location":"hub/cli/hub_login/","text":"hub login \u00b6 Handles login to a Hub account. hub login [flags] Options \u00b6 -h, --help help for login SEE ALSO \u00b6 hub - Hub Client","title":"Login"},{"location":"hub/cli/hub_login/#hub-login","text":"Handles login to a Hub account. hub login [flags]","title":"hub login"},{"location":"hub/cli/hub_login/#options","text":"-h, --help help for login","title":"Options"},{"location":"hub/cli/hub_login/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"hub/cli/hub_logout/","text":"hub logout \u00b6 Handles logout of a Hub account. hub logout [flags] Options \u00b6 -h, --help help for logout SEE ALSO \u00b6 hub - Hub Client","title":"Logout"},{"location":"hub/cli/hub_logout/#hub-logout","text":"Handles logout of a Hub account. hub logout [flags]","title":"hub logout"},{"location":"hub/cli/hub_logout/#options","text":"-h, --help help for logout","title":"Options"},{"location":"hub/cli/hub_logout/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs/","text":"hub orgs \u00b6 Manages your organizations. Options \u00b6 -h, --help help for orgs SEE ALSO \u00b6 hub - Hub Client hub orgs create - Create an org hub orgs destroy - Destroy an org hub orgs invite - Invite members to an org hub orgs leave - Leave an org hub orgs ls - List orgs you're a member of hub orgs members - List org members","title":"Orgs"},{"location":"hub/cli/hub_orgs/#hub-orgs","text":"Manages your organizations.","title":"hub orgs"},{"location":"hub/cli/hub_orgs/#options","text":"-h, --help help for orgs","title":"Options"},{"location":"hub/cli/hub_orgs/#see-also","text":"hub - Hub Client hub orgs create - Create an org hub orgs destroy - Destroy an org hub orgs invite - Invite members to an org hub orgs leave - Leave an org hub orgs ls - List orgs you're a member of hub orgs members - List org members","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_create/","text":"hub orgs create \u00b6 Creates a new organization. hub orgs create [flags] Options \u00b6 -h, --help help for create SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs create"},{"location":"hub/cli/hub_orgs_create/#hub-orgs-create","text":"Creates a new organization. hub orgs create [flags]","title":"hub orgs create"},{"location":"hub/cli/hub_orgs_create/#options","text":"-h, --help help for create","title":"Options"},{"location":"hub/cli/hub_orgs_create/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_destroy/","text":"hub orgs destroy \u00b6 Destroys an organization and all associated data. You must be the org owner. hub orgs destroy [flags] Options \u00b6 -h, --help help for destroy SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs destroy"},{"location":"hub/cli/hub_orgs_destroy/#hub-orgs-destroy","text":"Destroys an organization and all associated data. You must be the org owner. hub orgs destroy [flags]","title":"hub orgs destroy"},{"location":"hub/cli/hub_orgs_destroy/#options","text":"-h, --help help for destroy","title":"Options"},{"location":"hub/cli/hub_orgs_destroy/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_invite/","text":"hub orgs invite \u00b6 Invites a new member to an organization. hub orgs invite [flags] Options \u00b6 -h, --help help for invite SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs invite"},{"location":"hub/cli/hub_orgs_invite/#hub-orgs-invite","text":"Invites a new member to an organization. hub orgs invite [flags]","title":"hub orgs invite"},{"location":"hub/cli/hub_orgs_invite/#options","text":"-h, --help help for invite","title":"Options"},{"location":"hub/cli/hub_orgs_invite/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_leave/","text":"hub orgs leave \u00b6 Leaves an organization. hub orgs leave [flags] Options \u00b6 -h, --help help for leave SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs leave"},{"location":"hub/cli/hub_orgs_leave/#hub-orgs-leave","text":"Leaves an organization. hub orgs leave [flags]","title":"hub orgs leave"},{"location":"hub/cli/hub_orgs_leave/#options","text":"-h, --help help for leave","title":"Options"},{"location":"hub/cli/hub_orgs_leave/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_ls/","text":"hub orgs ls \u00b6 Lists all the organizations that you're a member of. hub orgs ls [flags] Options \u00b6 -h, --help help for ls SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs ls"},{"location":"hub/cli/hub_orgs_ls/#hub-orgs-ls","text":"Lists all the organizations that you're a member of. hub orgs ls [flags]","title":"hub orgs ls"},{"location":"hub/cli/hub_orgs_ls/#options","text":"-h, --help help for ls","title":"Options"},{"location":"hub/cli/hub_orgs_ls/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_members/","text":"hub orgs members \u00b6 Lists current organization members. hub orgs members [flags] Options \u00b6 -h, --help help for members SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs members"},{"location":"hub/cli/hub_orgs_members/#hub-orgs-members","text":"Lists current organization members. hub orgs members [flags]","title":"hub orgs members"},{"location":"hub/cli/hub_orgs_members/#options","text":"-h, --help help for members","title":"Options"},{"location":"hub/cli/hub_orgs_members/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_threads/","text":"hub threads \u00b6 Manages your threads. Options \u00b6 -h, --help help for threads SEE ALSO \u00b6 hub - Hub Client hub threads ls - List your threads","title":"Threads"},{"location":"hub/cli/hub_threads/#hub-threads","text":"Manages your threads.","title":"hub threads"},{"location":"hub/cli/hub_threads/#options","text":"-h, --help help for threads","title":"Options"},{"location":"hub/cli/hub_threads/#see-also","text":"hub - Hub Client hub threads ls - List your threads","title":"SEE ALSO"},{"location":"hub/cli/hub_threads_ls/","text":"hub threads ls \u00b6 Lists all of your threads. hub threads ls [flags] Options \u00b6 -h, --help help for ls SEE ALSO \u00b6 hub threads - Thread management","title":"hub threads ls"},{"location":"hub/cli/hub_threads_ls/#hub-threads-ls","text":"Lists all of your threads. hub threads ls [flags]","title":"hub threads ls"},{"location":"hub/cli/hub_threads_ls/#options","text":"-h, --help help for ls","title":"Options"},{"location":"hub/cli/hub_threads_ls/#see-also","text":"hub threads - Thread management","title":"SEE ALSO"},{"location":"hub/cli/hub_whoami/","text":"hub whoami \u00b6 Shows the user for the current session. hub whoami [flags] Options \u00b6 -h, --help help for whoami SEE ALSO \u00b6 hub - Hub Client","title":"Whoami"},{"location":"hub/cli/hub_whoami/#hub-whoami","text":"Shows the user for the current session. hub whoami [flags]","title":"hub whoami"},{"location":"hub/cli/hub_whoami/#options","text":"-h, --help help for whoami","title":"Options"},{"location":"hub/cli/hub_whoami/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"policies/code-of-conduct/","text":"Our Pledge \u00b6 In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards \u00b6 Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities \u00b6 Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope \u00b6 This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement \u00b6 Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at contact@textile.io . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution \u00b6 This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/\u00bc","title":"Code of conduct"},{"location":"policies/code-of-conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"policies/code-of-conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"policies/code-of-conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"policies/code-of-conduct/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"policies/code-of-conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at contact@textile.io . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"policies/code-of-conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/\u00bc","title":"Attribution"},{"location":"policies/license/","text":"Unless otherwise explicitly stated, all Textile code and software products are licensed under the following license: MIT License \u00b6 Copyright \u00a9 2018, 2019 Textile Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"policies/license/#mit-license","text":"Copyright \u00a9 2018, 2019 Textile Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"},{"location":"policies/privacy/","text":"Textile provides exchange and storage of data. Textile provides remote data storage for users on the IPFS network (see https://ipfs.io/ ). The IPFS protocol has no mechanisms for deletion of data hosted on multiple providers on the network. When a Textile user 'deletes' data, we will remove that data from all servers in the IPFS network run by Textile. Information We Have \u00b6 Certain information (e.g. a user email, public keys, encrypted data content address, decrypted data, etc.) are transmitted to us solely for the purpose of transmitting and storing data. Unless otherwise stated below, this information is only kept as long as necessary to place each call or transmit each message, and is not used for any other purpose. Information we store The identifier you register with. The email contact address of any developer you invite to an organization. Encrypted or decrypted contents of ThreadDB. Encrypted or decrypted contents of Buckets. Transient information IP addresses may be kept for up to 90 days for rate limiting and to prevent abuse. Textile is currently collecting performance metrics and critical issues detected in our software. This data may be kept for up to a year. Information We May Share \u00b6 We do not share your information with companies, organizations, and individuals outside of Textile unless one of the following circumstances applies: With your consent. The data is encrypted and stored on IPFS hosts. When legally required. We will share the information we have with entities outside of Textile if we have a good faith belief that access, use, preservation, or disclosure of the information is necessary to: meet any applicable law, regulation, legal process or enforceable governmental request. enforce applicable Terms of Service, including investigation of potential violations. detect, prevent, or otherwise address fraud, security, or technical issues. protect against harm to the rights, property, or safety of Textile, our users, or the public as required or permitted by law. We will update this privacy policy as needed so that it is current, accurate, and as clear as possible. Please contact us with any questions at contact@textile.io Changelog \u00b6 05.04.20: Finalize TOS for new Textile Hub, Buckets, and ThreadDB services. 05.15.20: Corrected ThreadsDB => ThreadDB","title":"Privacy"},{"location":"policies/privacy/#information-we-have","text":"Certain information (e.g. a user email, public keys, encrypted data content address, decrypted data, etc.) are transmitted to us solely for the purpose of transmitting and storing data. Unless otherwise stated below, this information is only kept as long as necessary to place each call or transmit each message, and is not used for any other purpose. Information we store The identifier you register with. The email contact address of any developer you invite to an organization. Encrypted or decrypted contents of ThreadDB. Encrypted or decrypted contents of Buckets. Transient information IP addresses may be kept for up to 90 days for rate limiting and to prevent abuse. Textile is currently collecting performance metrics and critical issues detected in our software. This data may be kept for up to a year.","title":"Information We Have"},{"location":"policies/privacy/#information-we-may-share","text":"We do not share your information with companies, organizations, and individuals outside of Textile unless one of the following circumstances applies: With your consent. The data is encrypted and stored on IPFS hosts. When legally required. We will share the information we have with entities outside of Textile if we have a good faith belief that access, use, preservation, or disclosure of the information is necessary to: meet any applicable law, regulation, legal process or enforceable governmental request. enforce applicable Terms of Service, including investigation of potential violations. detect, prevent, or otherwise address fraud, security, or technical issues. protect against harm to the rights, property, or safety of Textile, our users, or the public as required or permitted by law. We will update this privacy policy as needed so that it is current, accurate, and as clear as possible. Please contact us with any questions at contact@textile.io","title":"Information We May Share"},{"location":"policies/privacy/#changelog","text":"05.04.20: Finalize TOS for new Textile Hub, Buckets, and ThreadDB services. 05.15.20: Corrected ThreadsDB => ThreadDB","title":"Changelog"},{"location":"policies/terms/","text":"Last updated: 05/04/20 Welcome to Textile. Please read these terms of service (these \u201c Terms \u201d) carefully as they form a contract between you and We Are Set, Inc, a Delaware corporation ( Textile , \u201c we \u201d, \u201c us \u201d, or \u201c our \u201d), that governs your access and use of (i) the web verification and encryption solution software provided by Textile (the \u201c Software \u201d); (ii) the Textile websites at textile.io (the \u201c Site \u201d); and (iii) any written or electronic use or features guides or other documentation provided or made available by Textile (the \u201c User Guides \u201d) (collectively the \u201c Service(s) \u201d). By registering or using any of the Services you agree to be bound by these Terms. If you are using the Services on behalf of an organization, you are agreeing to these Terms for that organization and promising to Textile that you have the authority to bind that organization to these Terms (in which event, \u201cyou\u201d and \u201cyour\u201d will refer to that organization). You may use the Services only in compliance with these Terms and only if you have the power to form a contract with Textile and are not barred under any applicable laws from doing so. IF YOU DO NOT AGREE TO BE BOUND BY THESE TERMS, YOU MUST NOT USE THE SERVICES . BY CLICKING THE CONFIRMATION LINK WHEN YOU OPEN AN ACCOUNT WITH US, YOU ACKNOWLEDGE AND AGREE TO BE BOUND TO THE TERMS. Should you have any questions concerning this Agreement, please contact privacy@textile.io . Please note that Textile does not provide warranties for the Services. This contract also limits our liability to you and contains an arbitration provision and a class action waiver. See Sections 14 (NO WARRANTY), 16 (LIMITATION OF LIABILITY) and 19 (ARBITRATION) of these Terms for details. 1. About this Service \u00b6 The Service offers verification and authentication services and encryption services for users. The Service provides a data storage system (\" Storage \") for developers to maintain remote copies of User Content. Storage is managed on IPFS ( https://www.ipfs.io/ ) nodes running on a user's personal device and replicated on remote IPFS nodes maintained by the Company. If you shared User Content which you no longer want to share publicly or privately using our Services, you must either delete that User Content or your Account. By making such deletion, the relevant User Content will become unlinked from the IPFS network and will be deleted from our IPFS node. You agree to immediately notify Company of any unauthorized use, or suspected unauthorized use of your Account or any other breach of security. Company cannot and will not be liable for any loss or damage arising from your failure to comply with the above requirements. 2. Changes to these Terms \u00b6 We reserve the right to revise these Terms from time to time. We will date and post the most current version of these Terms on the Site. Any changes will be effective upon posting the revised version of these Terms (or such later effective date as may be indicated at the top of the revised Terms). If, in our sole discretion, we deem a revision to these Terms to be material, we will notify you via the Service and/or by email to the email address associated with your account. Notice of other changes may be provided via the Site. Therefore, we encourage you to check the date of these Terms whenever you visit the Site to see if these Terms have been updated. Your continued access or use of any portion of the Service constitutes your acceptance of such changes. If you don\u2019t agree to any of the changes, we\u2019re not obligated to keep providing the Service to you, and you must cancel and stop using the Service. 3. Access to the Service \u00b6 You may use the Service, on a non-exclusive basis, solely in strict compliance with these Terms and all applicable laws. 4. Your Account \u00b6 To obtain access to certain Services, you may be required to obtain an account with Textile (become a \u201c Registered User \u201d). Until you apply for and are approved for an account your access to the Service will be limited to the areas of the Service, if any, that Textile makes available to the general public. When registering with Textile you must: (a) provide true, accurate, current and complete information about yourself as requested by the Service\u2019s registration form (such information being the \u201c Registration Data \u201d); and (b) maintain and promptly update the Registration Data to keep it true, accurate, current and complete. Textile may deny approval or withdraw such approval at any time in its sole discretion, with or without cause. Only you may use your Textile account. You must keep your account and passwords confidential and not authorize any third party to access or use the Service on your behalf, unless we provide an approved mechanism for such use. Textile will not be liable for any loss or damage arising from any unauthorized use of your accounts. CONTENT You represent and warrant that none of the following infringe any intellectual property, publicity or other proprietary rights: your provision of Your Content to us, your causing Your Content to be posted using the Service, and use of any such content (including of works derived from it) by us, other users of the Service, or others in contract with us that is done in connection with the Service and in compliance with these Terms. You acknowledge and agree that we may access or disclose information about you or any other information or data collected, stored or processed on our servers, including Your Content, if required to do so by law or in the good-faith belief that such action is necessary to: (a) comply with any law, regulation, legal process or lawful governmental requests; (b) protect the rights or property of Textile or our customers, including the enforcement of our agreements or policies governing your use of the Service; or \u00a9 act on a good faith belief that such access or disclosure is necessary to protect the personal safety of Textile employees, customers, or the public. We retain the right to block or otherwise prevent delivery of any type of file, email or other communication to or from the Service as part of our efforts to protect the Service, protect our customers, or stop you from breaching these Terms. 6. Consent to Electronic Communications and Solicitation \u00b6 By registering for the Service, you understand that we may send you communications or data regarding the Services, including but not limited to: (a) notices about your use of the Services, including any notices concerning violations of use; (b) updates; and \u00a9 promotional information and materials regarding Textile\u2019s products and services, via electronic mail. We give you the opportunity to opt-out of receiving promotional electronic mail from us by following the opt-out instructions provided in the message. 7. Suspension and Termination of Use of the Service \u00b6 We reserve the right, to temporarily suspend or terminate your access to the Service at any time in our sole discretion, with or without cause, with or without notice, and without incurring liability of any kind. For example, we may suspend or terminate your access to or use of the Service for: (a) the actual or suspected violation of these Terms; (b) the use of the Services in a manner that may cause Textile to have legal liability or disrupt others\u2019 use of the Services; \u00a9 the suspicion or detection of any malicious code, virus or other harmful code by you or in your account; (d) scheduled downtime and recurring downtime; (e) any actual or suspected effort by you to circumvent Textile\u2019s security or encryption; or (f) unplanned technical problems and outages. If, in Textile\u2019s determination, the suspension might be indefinite and/or Textile has elected to terminate your access to the Service, Textile will use commercially reasonable efforts to notify you through the Service and/or by email to the email address associated with your account. You acknowledge that if your access to the Service is suspended or terminated, you may no longer have access to Your Content that is stored with the Service. 8. Acceptable Use \u00b6 You must not use the Service to harm others or the Service. For example, you must not use the Service to harm, threaten, or harass another person, organization, or Textile. You must not: damage, disable, overburden, or impair the Service (or any network connected to the Service); resell or redistribute the Service or any part of it; use any unauthorized means to modify, reroute, or gain access to the Service or attempt to carry out these activities; or use any data mining, robots, or similar data gathering and extraction tools; or use any automated process or Service (such as a bot, a spider, or periodic caching of information stored by Textile) to access or use the Service;. In addition, you promise that you will not and will not encourage or assist any third party to: I. reproduce, modify, alter, tamper with, repair or create derivative works of any Software, unless that permission is granted in a license. Further, unless expressly prohibited under applicable law, you may not use the Service to develop, test, validate and/or improve any service that is a substitute for, or substantially similar to, the Service (including any portion thereof); II. reverse engineer, disassemble or decompile the Software used to provide or access the Service, including the Software, or attempt to discover or recreate the source code used to provide or access the Service, except and only to the extent that that permission is granted in a license or applicable law expressly permits doing so; III. use the Service in any manner or for any purpose other than as expressly permitted by these Terms, the Privacy Policy, any User Guides or any other policy, instruction or terms applicable to the Service that are available on the Service (\u201cPolicies\u201d); IV. sell, lend, rent, resell, lease, sublicense or otherwise transfer any of the rights granted to you with respect to the Services to any third party; V. remove, obscure or alter any proprietary rights notice pertaining to the Service; VI. use the Service in connection with the operation of nuclear facilities, aircraft navigation, communication systems, medical devices, air traffic control devices, real time control systems or other situations in which the failure of the Service could lead to death, personal injury, or physical property or environmental damage; VII. use the Service to: (i) engage in any unlawful or fraudulent activity or perpetrate a hoax or engage in phishing schemes or forgery or other similar falsification or manipulation of data; (ii) send unsolicited or unauthorized junk mail, spam, chain letters, pyramid schemes or any other form of duplicative or unsolicited messages, whether commercial or otherwise; (iii) store or transmit any inappropriate content, such as content: (1) containing unlawful, defamatory, threatening, abusive, libelous or otherwise objectionable material of any kind or nature, (2) containing any material that encourages conduct that could constitute a criminal offense, or (3) in a way that violates or infringes upon the intellectual property rights or the privacy or publicity rights of any person or entity or that may otherwise be unlawful or give rise to civil or criminal liability; (iv) store or transmit any content that contains or is used to initiate a denial of service attack, software viruses or other harmful or deleterious computer code, files or programs such as Trojan horses, worms, time bombs, cancelbots, or spyware; or (v) abuse, harass, stalk or otherwise violate the legal rights of a third party; VIII. interfere with or disrupt servers or networks used by Textile to provide the Service or used by other users\u2019 to access the Service, or violate any third party regulations, policies or procedures of such servers or networks or harass or interfere with another user\u2019s full use and enjoyment of any Software or the Service; IX. access or attempt to access Textile\u2019s other accounts, computer systems or networks not covered by these Terms, through password mining or any other means; X. cause, in Textile\u2019s sole discretion, inordinate burden on the Service or Textile\u2019s system resources or capacity; or XI. share passwords or other access information or devices or otherwise authorize any third party to access or use the Software or the Service. Textile reserves the right, in its sole discretion, to deactivate, change and/or require you to change your Textile user ID and any custom or vanity URLs, custom links, or vanity domains you may obtain through the Services for any reason or for no reason. Textile may exercise such right at any time, with or without prior notice. We will make all judgments concerning the applicability of these guidelines in our sole and exclusive discretion. We reserve the right, in our sole discretion, to determine whether and what action to take in response to each such notification, and any action or inaction in a particular instance will not dictate or limit our response to a future complaint. We will not assume or have any liability for any action or inaction with respect to any Your Content. 9. Updates to the Service \u00b6 Textile reserves the right, in its sole discretion, to make necessary unscheduled deployments of changes, updates or enhancements to the Service at any time. We may add or remove functionalities or features, and we may suspend or stop the Service altogether. 10. Software \u00b6 If you receive Software from us, its use is governed in one of two ways: If you\u2019re presented with license terms that you must accept in order to use the Software, those terms apply; if no license is presented to you, these Terms apply. We reserve all other rights to the Software. We may automatically check your version of the Software. We may also automatically download to your computer or device new versions of the Software. Any Software is licensed, not sold. Unless we notify you otherwise, the Software license ends when your Service ends. You must then promptly uninstall the Software, or we may disable it. You must not work around any technical limitations in the Software. The Software is subject to applicable U.S. export laws and regulations. You must comply with all domestic and international export laws and regulations that apply to the Software. These laws include restrictions on destinations, end users, and end use. Without limitation, you may not transfer the Software or Service without U.S. government permission to anyone on U.S. government exclusion lists (see the Commerce Department\u2019s compliance list at http://www.bis.doc.gov/index.php/policy-guidance/lists-of-parties-of-concern . You represent and warrant that you\u2019re not on any of those lists or under the control of or an agent for anyone on those lists or the entities listed above. 11. Third Party Services and Content \u00b6 All transactions using the Services are between the transacting parties only. The Services may contain features and functionalities linking you or providing you with certain functionality and access to third party content, including Web sites, directories, servers, networks, systems, information and databases, applications, software, programs, products or services, and the Internet as a whole; you acknowledge that we are not responsible for such content or services. We may also provide some content to you as part of the Services. However, Textile is not an agent of any transacting party, nor or we a direct party in any such transaction. Any such activities, and any terms associated with such activities, are solely between you and the applicable third-party. Similarly, we are not responsible for any third party content you access with the Services, and you irrevocably waive any claim against us with respect to such sites and third-party content. Textile shall have no liability, obligation or responsibility for any such correspondence, purchase or promotion between you and any such third-party. You should make whatever investigation you feel necessary or appropriate before proceeding with any online or offline transaction with any of these third parties. You are solely responsible for your dealings with any third party related to the Services, including the delivery of and payment for goods and services. 12. Textile Proprietary Rights \u00b6 As between Textile and you, Textile or its licensors own and reserve all right, title and interest in and to the Service and all hardware, software and other items used to provide the Service, other than the rights explicitly granted to you to use the Service in accordance with this Terms. No title to or ownership of any proprietary rights related to the Service is transferred to you pursuant to these Terms. All rights not explicitly granted to you are reserved by Textile. In the event that you provide comments, suggestions and recommendations to Textile with respect to the Service (including, without limitation, with respect to modifications, enhancements, improvements and other changes to the Service) (collectively, \u201cFeedback\u201d), you hereby grant to Textile a world-wide, royalty free, irrevocable, perpetual license to use and otherwise incorporate any Feedback in connection with the Service. 13. Privacy \u00b6 In order to operate and provide the Service, we collect certain information about you. We use that information as described in the privacy policy located at https://docs.textile.io/policies/privacy (\u201c Privacy Policy \u201d). 14. No Warranty \u00b6 TEXTILE PROVIDES THE SERVICE \u201cAS IS\u201d, \u201cWITH ALL FAULTS\u201d AND \u201cAS AVAILABLE\u201d. TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, TEXTILE MAKES NO (AND SPECIFICALLY DISCLAIMS ALL) REPRESENTATIONS OR WARRANTIES OF ANY KIND, WHETHER EXPRESS, IMPLIED, STATUTORY OR OTHERWISE, INCLUDING, WITHOUT LIMITATION, ANY WARRANTY THAT THE SERVICE WILL BE UNINTERRUPTED, ERROR-FREE OR FREE OF HARMFUL COMPONENTS, THAT YOUR CONTENT WILL BE SECURE OR NOT OTHERWISE LOST OR DAMAGED, OR ANY IMPLIED WARRANTY OF MERCHANTABILITY, SATISFACTORY QUALITY, FITNESS FOR A PARTICULAR PURPOSE, OR NON-INFRINGEMENT, AND ANY WARRANTY ARISING OUT OF ANY COURSE OF PERFORMANCE, COURSE OF DEALING OR USAGE OF TRADE. SOME JURISDICTIONS DO NOT ALLOW THE FOREGOING EXCLUSIONS. IN SUCH AN EVENT SUCH EXCLUSION WILL NOT APPLY SOLELY TO THE EXTENT PROHIBITED BY APPLICABLE LAW. You hereby acknowledge and agree that this disclaimer of warranties is a fundamental part of the agreement between you and Textile contained in these Terms and that Textile would not agree to enter these Terms or allow you access or use the Service without such disclaimers. 15. Indemnification \u00b6 You will defend Textile against any cost, loss, damage, or other liability arising from any third party demand or claim that any Your Content, or your use of the Service, in breach of these Terms: (a) infringes a registered patent, registered trademark, or copyright of a third party, or misappropriates a trade secret (to the extent that such misappropriation is not the result of Textile\u2019s actions); or (b) violates applicable law or these Terms. Textile will reasonably notify you of any such claim or demand that is subject to your indemnification obligation. 16. Limitation of Liability \u00b6 TO THE FULLEST EXTENT PERMITTED BY LAW, IN NO EVENT WILL TEXTILE, ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE FOR: ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, PUNITIVE, COVER OR CONSEQUENTIAL DAMAGES, OR DAMAGES FOR LOST PROFITS, REVENUE, GOODWILL, USE OR CONTENT, HOWEVER CAUSED, UNDER ANY THEORY OF LIABILITY, INCLUDING, WITHOUT LIMITATION, CONTRACT, TORT, WARRANTY, NEGLIGENCE OR OTHERWISE, EVEN IF TEXTILE HAS BEEN ADVISED AS TO THE POSSIBILITY OF SUCH DAMAGES. TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, THE AGGREGATE LIABILITY OF TEXTILE AND ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS, RELATING TO THE SERVICES WILL BE LIMITED TO FIFTY DOLLARS ($50.00). THE LIMITATIONS AND EXCLUSIONS ALSO APPLY IF THIS REMEDY DOES NOT FULLY COMPENSATE YOU FOR ANY LOSSES OR FAILS OF ITS ESSENTIAL PURPOSE. SOME JURISDICTIONS DO NOT ALLOW THE LIMITATION OF INCIDENTAL, CONSEQUENTIAL OR OTHER DAMAGES. IN SUCH AN EVENT THIS LIMITATION WILL NOT APPLY TO YOU TO THE EXTENT PROHIBITED BY LAW. You acknowledge that the foregoing limitations are an essential element of the agreement between you and Textile and that in the absence of such limitations the terms and conditions set forth in these Terms would be substantially different. 17. Arbitration; Class Action Waiver \u00b6 17.1 Introduction Introduction. This Section 17 includes an arbitration agreement and an agreement that all claims will be brought only in an individual capacity (and not as a class action or other representative proceeding). Please read it carefully. You may opt out of the arbitration agreement by following the opt out procedure described below. 17.2 Process Informal Process First You agree that in the event of any dispute between you and Textile, you will first contact Textile and make a good faith sustained effort to resolve the dispute before resorting to more formal means of resolution, including without limitation any court action. 17.3 Arbitration Agreement After the informal dispute resolution process any remaining dispute, controversy, or claim (collectively, \u201cClaim\u201d) relating in any way to your use of Textile\u2019s services and/or products, including the Service, or relating in any way to the communications between you and Textile or any other user of the Service, will be finally resolved by binding arbitration. This mandatory arbitration agreement applies equally to you and Textile. However, this arbitration agreement does not (a) govern any Claim by Textile for infringement of its intellectual property or access to the Service that is unauthorized or exceeds authorization granted in these Terms or (b) bar you from making use of applicable small claims court procedures in appropriate cases. If you are an individual you may opt out of this arbitration agreement within thirty (30) days of the first date you access or use this Service by following the procedure described below. Arbitration is more informal than a lawsuit in court. There is no judge or jury in arbitration. Instead, the dispute is resolve by a neutral arbitrator. Court review of an arbitration award is limited. Except to the extent the parties agree otherwise, arbitrators can award the same damages and relief that a court can award. You agree that the U.S. Federal Arbitration Act governs the interpretation and enforcement of this provision, and that you and Textile are each waiving the right to a trial by jury or to participate in a class action. This arbitration provision will survive any termination of these Terms. If you wish to begin an arbitration proceeding, after following the informal dispute resolution procedure, you must send a letter requesting arbitration and describing your claim to Textile, Inc., Attn: President, 85 Broad St., 18 th Floor - NY, NY 10004. The arbitration will be administered by the American Arbitration Association (AAA) under its rules including, if you are an individual, the AAA's Supplementary Procedures for Consumer-Related Disputes. If you are not an individual or have used the Services on behalf of an entity, the AAA's Supplementary Procedures for Consumer-Related Disputes will not be used. The AAA's rules are available at www.adr.org or by calling 1-800-778-7879. The number of arbitrators will be one. You may choose to have the arbitration conducted by telephone, based on written submissions, or in person in the county where you live or at another mutually agreed location. The arbitration will be conducted in the English language and California law will apply. Judgment on the award rendered by the arbitrator may be entered in any court having jurisdiction thereof. Payment of all filing, administration and arbitrator fees will be governed by the AAA's rules. If you are an individual and have not accessed or used the Service on behalf of an entity, we will reimburse those fees for claims totaling less than $10,000, unless the arbitrator determines the claims are frivolous, and we will not seek attorneys\u2019 fees and costs in arbitration unless the arbitrator determines the claims are frivolous. The arbitrator, and not any federal, state, or local court, will have exclusive authority to resolve any dispute relating to the interpretation, applicability, unconscionability, arbitrability, enforceability, or formation of this arbitration agreement, including any claim that all or any part of this arbitration agreement is void or voidable. However, the preceding sentence will not apply to the \u201cClass Action Waiver\u201d section below. If you do not want to arbitrate disputes with Textile and you are an individual, you may opt out of this arbitration agreement by sending an email to [ legal@textile.io ] within thirty (30) days of the first date you access or use the Service. CLASS ACTION WAIVER Any Claim must be brought in the respective party\u2019s individual capacity, and not as a plaintiff or class member in any purported class, collective, representative, multiple plaintiff, or similar proceeding (\u201cClass Action\u201d). The parties expressly waive any ability to maintain any Class Action in any forum. If the Claim is subject to arbitration, the arbitrator will not have authority to combine or aggregate similar claims or conduct any Class Action nor make an award to any person or entity not a party to the arbitration. Any claim that all or part of this Class Action Waiver is unenforceable, unconscionable, void, or voidable may be determined only by a court of competent jurisdiction and not by an arbitrator. The parties understand that any right to litigate in court, to have a judge or jury decide their case, or to be a party to a class or representative action, is waived, and that any claims must be decided individually, through arbitration. If this class action waiver is found to be unenforceable, then the entirety of the Arbitration Agreement, if otherwise effective, will be null and void. The arbitrator may award declaratory or injunctive relief only in favor of the individual party seeking relief and only to the extent necessary to provide relief warranted by that party's individual claim. If for any reason a claim proceeds in court rather than in arbitration, you and Textile each waive any right to a jury trial and each submit to the exclusive jurisdiction of the federal courts located in San Francisco, California. 18. Notices \u00b6 We may send you, in electronic form, information about the Service, additional information, and information the law requires us to provide. We may provide required information to you by email at the address you specified when you signed up for the Service or by access to a website that we identify. Notices emailed to you will be deemed given and received when the email is sent. If you don\u2019t consent to receive notices electronically, you must stop using the Service. You may provide legal noticed to us via email to legal@textile.io , with a duplicate copy sent via registered mail, return receipt requested, to the following address: Textile, Attn: President, 206 Jackson Street. Sunnyvale, CA 94086, USA. Any such notice, in either case, must specifically reference that it is a notice given under these Terms. 19. Miscellaneous \u00b6 19.1. Severability; Entire Agreement These Terms apply to the maximum extent permitted by relevant law. If a court holds that we cannot enforce a part of these Terms as written, you and we will replace those terms with similar terms to the extent enforceable under the relevant law, but the rest of these Terms will remain in effect. This is the entire contract between you and us regarding the Service. It supersedes any prior contract or oral or written statements regarding your use of the Service. 19.2. Assignment and transfer We may assign, transfer, or otherwise dispose our rights and obligations under these Terms, in whole or in part, at any time without notice. You may not assign these Terms or transfer any rights to use the Service. 19.3. Independent Contractors; No third-party beneficiaries Textile and you are not legal partners or agents; instead, our relationship is that of independent contractors. These Terms are solely for your and our benefit. It is not for the benefit of any other person, except for permitted successors. 19.4. Claims You must bring any claim related to these Terms or the Service within one year of the date you could first bring the claim, unless your local law requires a longer time to file claims. If it isn\u2019t filed in time, the claim is permanently barred. 19.5. Waiver The failure of you or Textile to insist upon or enforce strict performance of any of the provisions of these Terms or to exercise any rights or remedies under these Terms will not be construed as a waiver or relinquishment to any extent of your right or Textile\u2019s right to assert or rely upon any such provision, right or remedy in that or any other instance; rather, the same will remain in full force and effect. 19.6. Government Use If you are a U.S. government entity, you acknowledge that any Software and User Guides that are provided are \u201cCommercial Items\u201d as defined at 48 C.F.R. 2.101, and are being provided as commercial computer software subject to the restricted rights described in 48 C.F.R. 2.101 and 12.212. 20. Copyright Complaints and Removal Policy \u00b6 We reserve the right to delete or disable Content alleged to violate these Terms and to terminate repeat offenders. 20.1 DMCA Take-down Notices If you are a copyright owner or an agent thereof and believe, in good faith, that any materials on the Service infringe upon your copyrights, you may submit a notification pursuant to the Digital Millennium Copyright Act (see 17 U.S.C. 512) (the \u201cDMCA\u201d) by sending the following information in writing to Textile\u2019s designated copyright agent at [ legal@textile.io ]: (a) The date of your notification; (b) A physical or electronic signature of a person authorized to act on behalf of the owner of an exclusive right that is allegedly infringed; \u00a9 A description of the copyrighted work claimed to have been infringed, or, if multiple copyrighted works at a single online site are covered by a single notification, a representative list of such works at that site; (d) A description of the material that is claimed to be infringing or to be the subject of infringing activity and that is to be removed or access to which is to be disabled, and information reasonably sufficient to enable Textile to locate the material; (e) Information reasonably sufficient to permit Textile to contact you, such as an address, telephone number and/or email address; (f) A statement that you have a good faith belief that use of the material in the manner complained of is not authorized by the copyright owner, its agent or the law; and (g) A statement that the information in the notification is accurate, and under penalty of perjury, that you are authorized to act on behalf of the owner of an exclusive right that is allegedly infringed. The failure to send proper notification pursuant to the DMCA may result in our taking incomplete or no action with respect to the allegedly infringing material described in such improper notification, and under some circumstances may even result in liability to the person(s) submitting such improper notifications. 20.2 Counter-Notices If you believe that your content that has been removed from the Service is not infringing, or that you have authorization from the copyright owner, the copyright owner\u2019s agent or pursuant to the law, to post and use the content, you may send a counter-notice containing the following information to our copyright agent using the contact information set forth above: (i) Your physical or electronic signature; (ii) A description of the content that has been removed and the location at which the content appeared before it was removed; (iii) A statement that you have a good faith belief that the content was removed as a result of mistake or a misidentification of the content; and (iv) Your name, address, telephone number and email address, a statement that you consent to the jurisdiction of the federal court in the Northern District Court of California and a statement that you will accept service of process from the person who provided notification of the alleged infringement. If a counter-notice is received by the Textile copyright agent, Textile may send a copy of the counter-notice to the original complaining party informing such person that it may reinstate the removed content in 10 business days. Unless the copyright owner files an action seeking a court order against the content provider or user, the removed content may (in Textile\u2019s discretion) be reinstated on the Service within 10 to 14 business days after receipt of the counter-notice. 21. Intellectual Property Notices \u00b6 All contents of the Site and Services including but not limited to design, text, software, technical drawings, configurations, graphics, other files, and their selection and arrangement are: Copyright \u00a9 Textile, and/or the proprietary property of its suppliers, affiliates, or licensors. All Rights Reserved. Textile and the Textile logo are including without limitation, either trademarks, service marks or registered trademarks of Textile, Inc., and may not be copied, imitated, or used, in whole or in part, without Textile\u2019s prior written permission or that of our suppliers or licensors. Other product and company names may be trade or service marks of their respective owners. Textile may have patents, patent applications, trademarks, copyrights, or other intellectual property rights covering subject matter that is part of the Service. Unless we have granted you licenses to our intellectual property in these Terms, our providing you with the Service does not give you any license to our intellectual property. Any rights not expressly granted herein are reserved.","title":"Terms"},{"location":"policies/terms/#1-about-this-service","text":"The Service offers verification and authentication services and encryption services for users. The Service provides a data storage system (\" Storage \") for developers to maintain remote copies of User Content. Storage is managed on IPFS ( https://www.ipfs.io/ ) nodes running on a user's personal device and replicated on remote IPFS nodes maintained by the Company. If you shared User Content which you no longer want to share publicly or privately using our Services, you must either delete that User Content or your Account. By making such deletion, the relevant User Content will become unlinked from the IPFS network and will be deleted from our IPFS node. You agree to immediately notify Company of any unauthorized use, or suspected unauthorized use of your Account or any other breach of security. Company cannot and will not be liable for any loss or damage arising from your failure to comply with the above requirements.","title":"1. About this Service"},{"location":"policies/terms/#2-changes-to-these-terms","text":"We reserve the right to revise these Terms from time to time. We will date and post the most current version of these Terms on the Site. Any changes will be effective upon posting the revised version of these Terms (or such later effective date as may be indicated at the top of the revised Terms). If, in our sole discretion, we deem a revision to these Terms to be material, we will notify you via the Service and/or by email to the email address associated with your account. Notice of other changes may be provided via the Site. Therefore, we encourage you to check the date of these Terms whenever you visit the Site to see if these Terms have been updated. Your continued access or use of any portion of the Service constitutes your acceptance of such changes. If you don\u2019t agree to any of the changes, we\u2019re not obligated to keep providing the Service to you, and you must cancel and stop using the Service.","title":"2. Changes to these Terms"},{"location":"policies/terms/#3-access-to-the-service","text":"You may use the Service, on a non-exclusive basis, solely in strict compliance with these Terms and all applicable laws.","title":"3. Access to the Service"},{"location":"policies/terms/#4-your-account","text":"To obtain access to certain Services, you may be required to obtain an account with Textile (become a \u201c Registered User \u201d). Until you apply for and are approved for an account your access to the Service will be limited to the areas of the Service, if any, that Textile makes available to the general public. When registering with Textile you must: (a) provide true, accurate, current and complete information about yourself as requested by the Service\u2019s registration form (such information being the \u201c Registration Data \u201d); and (b) maintain and promptly update the Registration Data to keep it true, accurate, current and complete. Textile may deny approval or withdraw such approval at any time in its sole discretion, with or without cause. Only you may use your Textile account. You must keep your account and passwords confidential and not authorize any third party to access or use the Service on your behalf, unless we provide an approved mechanism for such use. Textile will not be liable for any loss or damage arising from any unauthorized use of your accounts. CONTENT You represent and warrant that none of the following infringe any intellectual property, publicity or other proprietary rights: your provision of Your Content to us, your causing Your Content to be posted using the Service, and use of any such content (including of works derived from it) by us, other users of the Service, or others in contract with us that is done in connection with the Service and in compliance with these Terms. You acknowledge and agree that we may access or disclose information about you or any other information or data collected, stored or processed on our servers, including Your Content, if required to do so by law or in the good-faith belief that such action is necessary to: (a) comply with any law, regulation, legal process or lawful governmental requests; (b) protect the rights or property of Textile or our customers, including the enforcement of our agreements or policies governing your use of the Service; or \u00a9 act on a good faith belief that such access or disclosure is necessary to protect the personal safety of Textile employees, customers, or the public. We retain the right to block or otherwise prevent delivery of any type of file, email or other communication to or from the Service as part of our efforts to protect the Service, protect our customers, or stop you from breaching these Terms.","title":"4. Your Account"},{"location":"policies/terms/#6-consent-to-electronic-communications-and-solicitation","text":"By registering for the Service, you understand that we may send you communications or data regarding the Services, including but not limited to: (a) notices about your use of the Services, including any notices concerning violations of use; (b) updates; and \u00a9 promotional information and materials regarding Textile\u2019s products and services, via electronic mail. We give you the opportunity to opt-out of receiving promotional electronic mail from us by following the opt-out instructions provided in the message.","title":"6. Consent to Electronic Communications and Solicitation"},{"location":"policies/terms/#7-suspension-and-termination-of-use-of-the-service","text":"We reserve the right, to temporarily suspend or terminate your access to the Service at any time in our sole discretion, with or without cause, with or without notice, and without incurring liability of any kind. For example, we may suspend or terminate your access to or use of the Service for: (a) the actual or suspected violation of these Terms; (b) the use of the Services in a manner that may cause Textile to have legal liability or disrupt others\u2019 use of the Services; \u00a9 the suspicion or detection of any malicious code, virus or other harmful code by you or in your account; (d) scheduled downtime and recurring downtime; (e) any actual or suspected effort by you to circumvent Textile\u2019s security or encryption; or (f) unplanned technical problems and outages. If, in Textile\u2019s determination, the suspension might be indefinite and/or Textile has elected to terminate your access to the Service, Textile will use commercially reasonable efforts to notify you through the Service and/or by email to the email address associated with your account. You acknowledge that if your access to the Service is suspended or terminated, you may no longer have access to Your Content that is stored with the Service.","title":"7. Suspension and Termination of Use of the Service"},{"location":"policies/terms/#8-acceptable-use","text":"You must not use the Service to harm others or the Service. For example, you must not use the Service to harm, threaten, or harass another person, organization, or Textile. You must not: damage, disable, overburden, or impair the Service (or any network connected to the Service); resell or redistribute the Service or any part of it; use any unauthorized means to modify, reroute, or gain access to the Service or attempt to carry out these activities; or use any data mining, robots, or similar data gathering and extraction tools; or use any automated process or Service (such as a bot, a spider, or periodic caching of information stored by Textile) to access or use the Service;. In addition, you promise that you will not and will not encourage or assist any third party to: I. reproduce, modify, alter, tamper with, repair or create derivative works of any Software, unless that permission is granted in a license. Further, unless expressly prohibited under applicable law, you may not use the Service to develop, test, validate and/or improve any service that is a substitute for, or substantially similar to, the Service (including any portion thereof); II. reverse engineer, disassemble or decompile the Software used to provide or access the Service, including the Software, or attempt to discover or recreate the source code used to provide or access the Service, except and only to the extent that that permission is granted in a license or applicable law expressly permits doing so; III. use the Service in any manner or for any purpose other than as expressly permitted by these Terms, the Privacy Policy, any User Guides or any other policy, instruction or terms applicable to the Service that are available on the Service (\u201cPolicies\u201d); IV. sell, lend, rent, resell, lease, sublicense or otherwise transfer any of the rights granted to you with respect to the Services to any third party; V. remove, obscure or alter any proprietary rights notice pertaining to the Service; VI. use the Service in connection with the operation of nuclear facilities, aircraft navigation, communication systems, medical devices, air traffic control devices, real time control systems or other situations in which the failure of the Service could lead to death, personal injury, or physical property or environmental damage; VII. use the Service to: (i) engage in any unlawful or fraudulent activity or perpetrate a hoax or engage in phishing schemes or forgery or other similar falsification or manipulation of data; (ii) send unsolicited or unauthorized junk mail, spam, chain letters, pyramid schemes or any other form of duplicative or unsolicited messages, whether commercial or otherwise; (iii) store or transmit any inappropriate content, such as content: (1) containing unlawful, defamatory, threatening, abusive, libelous or otherwise objectionable material of any kind or nature, (2) containing any material that encourages conduct that could constitute a criminal offense, or (3) in a way that violates or infringes upon the intellectual property rights or the privacy or publicity rights of any person or entity or that may otherwise be unlawful or give rise to civil or criminal liability; (iv) store or transmit any content that contains or is used to initiate a denial of service attack, software viruses or other harmful or deleterious computer code, files or programs such as Trojan horses, worms, time bombs, cancelbots, or spyware; or (v) abuse, harass, stalk or otherwise violate the legal rights of a third party; VIII. interfere with or disrupt servers or networks used by Textile to provide the Service or used by other users\u2019 to access the Service, or violate any third party regulations, policies or procedures of such servers or networks or harass or interfere with another user\u2019s full use and enjoyment of any Software or the Service; IX. access or attempt to access Textile\u2019s other accounts, computer systems or networks not covered by these Terms, through password mining or any other means; X. cause, in Textile\u2019s sole discretion, inordinate burden on the Service or Textile\u2019s system resources or capacity; or XI. share passwords or other access information or devices or otherwise authorize any third party to access or use the Software or the Service. Textile reserves the right, in its sole discretion, to deactivate, change and/or require you to change your Textile user ID and any custom or vanity URLs, custom links, or vanity domains you may obtain through the Services for any reason or for no reason. Textile may exercise such right at any time, with or without prior notice. We will make all judgments concerning the applicability of these guidelines in our sole and exclusive discretion. We reserve the right, in our sole discretion, to determine whether and what action to take in response to each such notification, and any action or inaction in a particular instance will not dictate or limit our response to a future complaint. We will not assume or have any liability for any action or inaction with respect to any Your Content.","title":"8. Acceptable Use"},{"location":"policies/terms/#9-updates-to-the-service","text":"Textile reserves the right, in its sole discretion, to make necessary unscheduled deployments of changes, updates or enhancements to the Service at any time. We may add or remove functionalities or features, and we may suspend or stop the Service altogether.","title":"9. Updates to the Service"},{"location":"policies/terms/#10-software","text":"If you receive Software from us, its use is governed in one of two ways: If you\u2019re presented with license terms that you must accept in order to use the Software, those terms apply; if no license is presented to you, these Terms apply. We reserve all other rights to the Software. We may automatically check your version of the Software. We may also automatically download to your computer or device new versions of the Software. Any Software is licensed, not sold. Unless we notify you otherwise, the Software license ends when your Service ends. You must then promptly uninstall the Software, or we may disable it. You must not work around any technical limitations in the Software. The Software is subject to applicable U.S. export laws and regulations. You must comply with all domestic and international export laws and regulations that apply to the Software. These laws include restrictions on destinations, end users, and end use. Without limitation, you may not transfer the Software or Service without U.S. government permission to anyone on U.S. government exclusion lists (see the Commerce Department\u2019s compliance list at http://www.bis.doc.gov/index.php/policy-guidance/lists-of-parties-of-concern . You represent and warrant that you\u2019re not on any of those lists or under the control of or an agent for anyone on those lists or the entities listed above.","title":"10. Software"},{"location":"policies/terms/#11-third-party-services-and-content","text":"All transactions using the Services are between the transacting parties only. The Services may contain features and functionalities linking you or providing you with certain functionality and access to third party content, including Web sites, directories, servers, networks, systems, information and databases, applications, software, programs, products or services, and the Internet as a whole; you acknowledge that we are not responsible for such content or services. We may also provide some content to you as part of the Services. However, Textile is not an agent of any transacting party, nor or we a direct party in any such transaction. Any such activities, and any terms associated with such activities, are solely between you and the applicable third-party. Similarly, we are not responsible for any third party content you access with the Services, and you irrevocably waive any claim against us with respect to such sites and third-party content. Textile shall have no liability, obligation or responsibility for any such correspondence, purchase or promotion between you and any such third-party. You should make whatever investigation you feel necessary or appropriate before proceeding with any online or offline transaction with any of these third parties. You are solely responsible for your dealings with any third party related to the Services, including the delivery of and payment for goods and services.","title":"11. Third Party Services and Content"},{"location":"policies/terms/#12-textile-proprietary-rights","text":"As between Textile and you, Textile or its licensors own and reserve all right, title and interest in and to the Service and all hardware, software and other items used to provide the Service, other than the rights explicitly granted to you to use the Service in accordance with this Terms. No title to or ownership of any proprietary rights related to the Service is transferred to you pursuant to these Terms. All rights not explicitly granted to you are reserved by Textile. In the event that you provide comments, suggestions and recommendations to Textile with respect to the Service (including, without limitation, with respect to modifications, enhancements, improvements and other changes to the Service) (collectively, \u201cFeedback\u201d), you hereby grant to Textile a world-wide, royalty free, irrevocable, perpetual license to use and otherwise incorporate any Feedback in connection with the Service.","title":"12. Textile Proprietary Rights"},{"location":"policies/terms/#13-privacy","text":"In order to operate and provide the Service, we collect certain information about you. We use that information as described in the privacy policy located at https://docs.textile.io/policies/privacy (\u201c Privacy Policy \u201d).","title":"13. Privacy"},{"location":"policies/terms/#14-no-warranty","text":"TEXTILE PROVIDES THE SERVICE \u201cAS IS\u201d, \u201cWITH ALL FAULTS\u201d AND \u201cAS AVAILABLE\u201d. TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, TEXTILE MAKES NO (AND SPECIFICALLY DISCLAIMS ALL) REPRESENTATIONS OR WARRANTIES OF ANY KIND, WHETHER EXPRESS, IMPLIED, STATUTORY OR OTHERWISE, INCLUDING, WITHOUT LIMITATION, ANY WARRANTY THAT THE SERVICE WILL BE UNINTERRUPTED, ERROR-FREE OR FREE OF HARMFUL COMPONENTS, THAT YOUR CONTENT WILL BE SECURE OR NOT OTHERWISE LOST OR DAMAGED, OR ANY IMPLIED WARRANTY OF MERCHANTABILITY, SATISFACTORY QUALITY, FITNESS FOR A PARTICULAR PURPOSE, OR NON-INFRINGEMENT, AND ANY WARRANTY ARISING OUT OF ANY COURSE OF PERFORMANCE, COURSE OF DEALING OR USAGE OF TRADE. SOME JURISDICTIONS DO NOT ALLOW THE FOREGOING EXCLUSIONS. IN SUCH AN EVENT SUCH EXCLUSION WILL NOT APPLY SOLELY TO THE EXTENT PROHIBITED BY APPLICABLE LAW. You hereby acknowledge and agree that this disclaimer of warranties is a fundamental part of the agreement between you and Textile contained in these Terms and that Textile would not agree to enter these Terms or allow you access or use the Service without such disclaimers.","title":"14. No Warranty"},{"location":"policies/terms/#15-indemnification","text":"You will defend Textile against any cost, loss, damage, or other liability arising from any third party demand or claim that any Your Content, or your use of the Service, in breach of these Terms: (a) infringes a registered patent, registered trademark, or copyright of a third party, or misappropriates a trade secret (to the extent that such misappropriation is not the result of Textile\u2019s actions); or (b) violates applicable law or these Terms. Textile will reasonably notify you of any such claim or demand that is subject to your indemnification obligation.","title":"15. Indemnification"},{"location":"policies/terms/#16-limitation-of-liability","text":"TO THE FULLEST EXTENT PERMITTED BY LAW, IN NO EVENT WILL TEXTILE, ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE FOR: ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, PUNITIVE, COVER OR CONSEQUENTIAL DAMAGES, OR DAMAGES FOR LOST PROFITS, REVENUE, GOODWILL, USE OR CONTENT, HOWEVER CAUSED, UNDER ANY THEORY OF LIABILITY, INCLUDING, WITHOUT LIMITATION, CONTRACT, TORT, WARRANTY, NEGLIGENCE OR OTHERWISE, EVEN IF TEXTILE HAS BEEN ADVISED AS TO THE POSSIBILITY OF SUCH DAMAGES. TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, THE AGGREGATE LIABILITY OF TEXTILE AND ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS, RELATING TO THE SERVICES WILL BE LIMITED TO FIFTY DOLLARS ($50.00). THE LIMITATIONS AND EXCLUSIONS ALSO APPLY IF THIS REMEDY DOES NOT FULLY COMPENSATE YOU FOR ANY LOSSES OR FAILS OF ITS ESSENTIAL PURPOSE. SOME JURISDICTIONS DO NOT ALLOW THE LIMITATION OF INCIDENTAL, CONSEQUENTIAL OR OTHER DAMAGES. IN SUCH AN EVENT THIS LIMITATION WILL NOT APPLY TO YOU TO THE EXTENT PROHIBITED BY LAW. You acknowledge that the foregoing limitations are an essential element of the agreement between you and Textile and that in the absence of such limitations the terms and conditions set forth in these Terms would be substantially different.","title":"16. Limitation of Liability"},{"location":"policies/terms/#17-arbitration-class-action-waiver","text":"17.1 Introduction Introduction. This Section 17 includes an arbitration agreement and an agreement that all claims will be brought only in an individual capacity (and not as a class action or other representative proceeding). Please read it carefully. You may opt out of the arbitration agreement by following the opt out procedure described below. 17.2 Process Informal Process First You agree that in the event of any dispute between you and Textile, you will first contact Textile and make a good faith sustained effort to resolve the dispute before resorting to more formal means of resolution, including without limitation any court action. 17.3 Arbitration Agreement After the informal dispute resolution process any remaining dispute, controversy, or claim (collectively, \u201cClaim\u201d) relating in any way to your use of Textile\u2019s services and/or products, including the Service, or relating in any way to the communications between you and Textile or any other user of the Service, will be finally resolved by binding arbitration. This mandatory arbitration agreement applies equally to you and Textile. However, this arbitration agreement does not (a) govern any Claim by Textile for infringement of its intellectual property or access to the Service that is unauthorized or exceeds authorization granted in these Terms or (b) bar you from making use of applicable small claims court procedures in appropriate cases. If you are an individual you may opt out of this arbitration agreement within thirty (30) days of the first date you access or use this Service by following the procedure described below. Arbitration is more informal than a lawsuit in court. There is no judge or jury in arbitration. Instead, the dispute is resolve by a neutral arbitrator. Court review of an arbitration award is limited. Except to the extent the parties agree otherwise, arbitrators can award the same damages and relief that a court can award. You agree that the U.S. Federal Arbitration Act governs the interpretation and enforcement of this provision, and that you and Textile are each waiving the right to a trial by jury or to participate in a class action. This arbitration provision will survive any termination of these Terms. If you wish to begin an arbitration proceeding, after following the informal dispute resolution procedure, you must send a letter requesting arbitration and describing your claim to Textile, Inc., Attn: President, 85 Broad St., 18 th Floor - NY, NY 10004. The arbitration will be administered by the American Arbitration Association (AAA) under its rules including, if you are an individual, the AAA's Supplementary Procedures for Consumer-Related Disputes. If you are not an individual or have used the Services on behalf of an entity, the AAA's Supplementary Procedures for Consumer-Related Disputes will not be used. The AAA's rules are available at www.adr.org or by calling 1-800-778-7879. The number of arbitrators will be one. You may choose to have the arbitration conducted by telephone, based on written submissions, or in person in the county where you live or at another mutually agreed location. The arbitration will be conducted in the English language and California law will apply. Judgment on the award rendered by the arbitrator may be entered in any court having jurisdiction thereof. Payment of all filing, administration and arbitrator fees will be governed by the AAA's rules. If you are an individual and have not accessed or used the Service on behalf of an entity, we will reimburse those fees for claims totaling less than $10,000, unless the arbitrator determines the claims are frivolous, and we will not seek attorneys\u2019 fees and costs in arbitration unless the arbitrator determines the claims are frivolous. The arbitrator, and not any federal, state, or local court, will have exclusive authority to resolve any dispute relating to the interpretation, applicability, unconscionability, arbitrability, enforceability, or formation of this arbitration agreement, including any claim that all or any part of this arbitration agreement is void or voidable. However, the preceding sentence will not apply to the \u201cClass Action Waiver\u201d section below. If you do not want to arbitrate disputes with Textile and you are an individual, you may opt out of this arbitration agreement by sending an email to [ legal@textile.io ] within thirty (30) days of the first date you access or use the Service. CLASS ACTION WAIVER Any Claim must be brought in the respective party\u2019s individual capacity, and not as a plaintiff or class member in any purported class, collective, representative, multiple plaintiff, or similar proceeding (\u201cClass Action\u201d). The parties expressly waive any ability to maintain any Class Action in any forum. If the Claim is subject to arbitration, the arbitrator will not have authority to combine or aggregate similar claims or conduct any Class Action nor make an award to any person or entity not a party to the arbitration. Any claim that all or part of this Class Action Waiver is unenforceable, unconscionable, void, or voidable may be determined only by a court of competent jurisdiction and not by an arbitrator. The parties understand that any right to litigate in court, to have a judge or jury decide their case, or to be a party to a class or representative action, is waived, and that any claims must be decided individually, through arbitration. If this class action waiver is found to be unenforceable, then the entirety of the Arbitration Agreement, if otherwise effective, will be null and void. The arbitrator may award declaratory or injunctive relief only in favor of the individual party seeking relief and only to the extent necessary to provide relief warranted by that party's individual claim. If for any reason a claim proceeds in court rather than in arbitration, you and Textile each waive any right to a jury trial and each submit to the exclusive jurisdiction of the federal courts located in San Francisco, California.","title":"17. Arbitration; Class Action Waiver"},{"location":"policies/terms/#18-notices","text":"We may send you, in electronic form, information about the Service, additional information, and information the law requires us to provide. We may provide required information to you by email at the address you specified when you signed up for the Service or by access to a website that we identify. Notices emailed to you will be deemed given and received when the email is sent. If you don\u2019t consent to receive notices electronically, you must stop using the Service. You may provide legal noticed to us via email to legal@textile.io , with a duplicate copy sent via registered mail, return receipt requested, to the following address: Textile, Attn: President, 206 Jackson Street. Sunnyvale, CA 94086, USA. Any such notice, in either case, must specifically reference that it is a notice given under these Terms.","title":"18. Notices"},{"location":"policies/terms/#19-miscellaneous","text":"19.1. Severability; Entire Agreement These Terms apply to the maximum extent permitted by relevant law. If a court holds that we cannot enforce a part of these Terms as written, you and we will replace those terms with similar terms to the extent enforceable under the relevant law, but the rest of these Terms will remain in effect. This is the entire contract between you and us regarding the Service. It supersedes any prior contract or oral or written statements regarding your use of the Service. 19.2. Assignment and transfer We may assign, transfer, or otherwise dispose our rights and obligations under these Terms, in whole or in part, at any time without notice. You may not assign these Terms or transfer any rights to use the Service. 19.3. Independent Contractors; No third-party beneficiaries Textile and you are not legal partners or agents; instead, our relationship is that of independent contractors. These Terms are solely for your and our benefit. It is not for the benefit of any other person, except for permitted successors. 19.4. Claims You must bring any claim related to these Terms or the Service within one year of the date you could first bring the claim, unless your local law requires a longer time to file claims. If it isn\u2019t filed in time, the claim is permanently barred. 19.5. Waiver The failure of you or Textile to insist upon or enforce strict performance of any of the provisions of these Terms or to exercise any rights or remedies under these Terms will not be construed as a waiver or relinquishment to any extent of your right or Textile\u2019s right to assert or rely upon any such provision, right or remedy in that or any other instance; rather, the same will remain in full force and effect. 19.6. Government Use If you are a U.S. government entity, you acknowledge that any Software and User Guides that are provided are \u201cCommercial Items\u201d as defined at 48 C.F.R. 2.101, and are being provided as commercial computer software subject to the restricted rights described in 48 C.F.R. 2.101 and 12.212.","title":"19. Miscellaneous"},{"location":"policies/terms/#20-copyright-complaints-and-removal-policy","text":"We reserve the right to delete or disable Content alleged to violate these Terms and to terminate repeat offenders. 20.1 DMCA Take-down Notices If you are a copyright owner or an agent thereof and believe, in good faith, that any materials on the Service infringe upon your copyrights, you may submit a notification pursuant to the Digital Millennium Copyright Act (see 17 U.S.C. 512) (the \u201cDMCA\u201d) by sending the following information in writing to Textile\u2019s designated copyright agent at [ legal@textile.io ]: (a) The date of your notification; (b) A physical or electronic signature of a person authorized to act on behalf of the owner of an exclusive right that is allegedly infringed; \u00a9 A description of the copyrighted work claimed to have been infringed, or, if multiple copyrighted works at a single online site are covered by a single notification, a representative list of such works at that site; (d) A description of the material that is claimed to be infringing or to be the subject of infringing activity and that is to be removed or access to which is to be disabled, and information reasonably sufficient to enable Textile to locate the material; (e) Information reasonably sufficient to permit Textile to contact you, such as an address, telephone number and/or email address; (f) A statement that you have a good faith belief that use of the material in the manner complained of is not authorized by the copyright owner, its agent or the law; and (g) A statement that the information in the notification is accurate, and under penalty of perjury, that you are authorized to act on behalf of the owner of an exclusive right that is allegedly infringed. The failure to send proper notification pursuant to the DMCA may result in our taking incomplete or no action with respect to the allegedly infringing material described in such improper notification, and under some circumstances may even result in liability to the person(s) submitting such improper notifications. 20.2 Counter-Notices If you believe that your content that has been removed from the Service is not infringing, or that you have authorization from the copyright owner, the copyright owner\u2019s agent or pursuant to the law, to post and use the content, you may send a counter-notice containing the following information to our copyright agent using the contact information set forth above: (i) Your physical or electronic signature; (ii) A description of the content that has been removed and the location at which the content appeared before it was removed; (iii) A statement that you have a good faith belief that the content was removed as a result of mistake or a misidentification of the content; and (iv) Your name, address, telephone number and email address, a statement that you consent to the jurisdiction of the federal court in the Northern District Court of California and a statement that you will accept service of process from the person who provided notification of the alleged infringement. If a counter-notice is received by the Textile copyright agent, Textile may send a copy of the counter-notice to the original complaining party informing such person that it may reinstate the removed content in 10 business days. Unless the copyright owner files an action seeking a court order against the content provider or user, the removed content may (in Textile\u2019s discretion) be reinstated on the Service within 10 to 14 business days after receipt of the counter-notice.","title":"20. Copyright Complaints and Removal Policy"},{"location":"policies/terms/#21-intellectual-property-notices","text":"All contents of the Site and Services including but not limited to design, text, software, technical drawings, configurations, graphics, other files, and their selection and arrangement are: Copyright \u00a9 Textile, and/or the proprietary property of its suppliers, affiliates, or licensors. All Rights Reserved. Textile and the Textile logo are including without limitation, either trademarks, service marks or registered trademarks of Textile, Inc., and may not be copied, imitated, or used, in whole or in part, without Textile\u2019s prior written permission or that of our suppliers or licensors. Other product and company names may be trade or service marks of their respective owners. Textile may have patents, patent applications, trademarks, copyrights, or other intellectual property rights covering subject matter that is part of the Service. Unless we have granted you licenses to our intellectual property in these Terms, our providing you with the Service does not give you any license to our intellectual property. Any rights not expressly granted herein are reserved.","title":"21. Intellectual Property Notices"},{"location":"powergate/","text":"Introduction to the Powergate \u00b6 The Powergate is an API driven solution for deploying multitiered storage across Filecoin and IPFS . Persistent storage on Filecoin allows rich storage configuration for data such as replication factor, miner selection, deal renewal, and repair. Network available storage is configurable and provided through a connected IPFS peer or pinning network. Warning The Powergate will remain in rapid development until close to the Filecoin Mainnet launch. During this time, will likely encounter bugs and unannounced API changes. Do not run the Powergate in production systems. Overview \u00b6 Powergate is a collection of libraries, modules, and configurations that can used independently, and composed together to integrate Filecoin into your application or storage system. The Powergate is designed to manage one or many Filecoin wallet addresses. Each address in Powergate can be independently managed through the FFS API (or grouped together into a single FFS instance ). Some benefits of using the Powergate include: Ensure data stored on Filecoin is available on the IPFS network easily. Handle long-term storage deal management, including automated renew and repair. Make use of network indices to improve miner selection and deal creation. Manage Filecoin wallet addresses for one or many users. Easily configure, connect, and deploy Powergate, Lotus , and IPFS together. Much more! Libraries \u00b6 Powergate Repo Open source multi-tiered file storage API built on Filecoin and IPFS. POW JS Client Typescript/Javascript client for Textile's Powergate . POW Golang Client Golang client for the Powergate. POW CLI A command-line interface to work directly with a running Powergate. Filecoin Local Localnet A fast development node for working with Filecoin APIs. Getting started \u00b6 Command-line Interface \u00b6 The Powergate includes the full set of features through the binary command-line interface. Install the CLI You can build and install the Powergate CLI from the Powergate Repo . git clone git@github.com:textileio/powergate.git cd powergate make build Info To compile from source, verify you have Go 1.14 or newer installed. All make commands install binaries in $GOPATH/bin , which usually is in $PATH , so you can run them right away from any folder in your terminal. Using the CLI Powergate CLI commands are just pow . Multi-tiered storage \u00b6 The workhorse of APIs in the Powergate is called, the FFS (Filecoin File System). This module provides a multi-tiered file storage API built on Filecoin and IPFS. Storing data on IPFS and Filecoin is as easy as expressing your desired configuration for storing a Cid. The FFS is where the Powergate handles Filecoin wallet addresses, long-term deal management, and connecting Filecoin to IPFS. Access to the FFS is enabled through a basic token, allowing you to create many FFS Instances, and map Powergate API access to user(s) in your system. Read about the FFS here . Network Indices \u00b6 Indices A running Powergate deployment will collect a number of useful indices about the network. Some of the data collected in these indices are used by the FFS to streamline miner selection when creating new deals. You can use the indices directly to build other features into your own system. Miners index . Provides processed data regarding registered miners (on-chain and off-chain), such as: total miner power, relative power, online status, geolocation, and more! Ask index . Provides a fast-retrieval up to date snapshot of miner's asking prices for data storage. Slashing index . Provides history data about miners faults while proving their storage on-chain. Reputation Module Built on top of the previous indexes, a Reputation module constructs a weighted-scoring system that allows to sort miners considering multiple on-chain and off-chain data, such as: compared price to the median of the market, low storage-fault history, power on network, and external sources (soon!). Powergate APIs \u00b6 The Powergate APIs are available as gRPC endpoints. There are three ways to get familiar with the broad set of APIs available to start using on the Powergate. Explore the CLI . The CLI runs on the Powergate API, so in general, anything you can do in the CLI you can also do over the API. Use the JS Client . We have provided an easy to use JavaScript client for the Powergate APIs . User the Go Client . You can use the Powergate APIs from your go app by building directly on the Powergate Go Client . Browse the Protocols . The API is typed with Protocol Buffers and you can quickly view all capabilities by looking at the .proto files in the Powergate repo . The best place to start is the FFS API . Additional Tools \u00b6 The Powergate comes packed with a number of additional tools that will be useful to you as you integrate it into your system. Lotus . A Lotus node running on the current Testnet. IPFS . A full IPFS node running to back Powergate FFS. Prometheus . The backend for metrics processing. Grafana . Providing metrics dashboard. cAdvisor . Providing container metrics. Running the Powergate \u00b6 You can run the Powergate on the Filecoin testnet or using an embedded localnet we make available as part of the Powergate stack. We recommend starting out with the localnet as you'll get access to the full set of APIs and capabilities without having to start syncing the network right away. When ready, you can update your Powergate to connect to the live testnet and in the future mainnet . Localnet \u00b6 The localnet provides a fast, fully functional, embedded Filecoin network that can be used for testing, building, or running continuous integratin. Read more about running the Powergate on localnet or running the localnet to use the Lotus client directly . Testnet \u00b6 Once you are ready to start using the Powergate with the Filecoin Testnet, it's just a single line. git clone git@github.com:textileio/powergate.git cd powergate/docker make up Read the latest setup instructions . Mainnet \u00b6 When Filecoin Mainnet launches, we'll provide setup steps like the Testnet steps above. Learn more \u00b6 Walk-through Video \u00b6 In the above presentation, we'll give a high-level overview of how the Powergate fits into the Filecoin and IPFS networks and a detailed walk-through of system components. Running System Video \u00b6 The above video shows the Powergate startup including IPFS and Lotus nodes. Next, the admin uses the Powergate CLI to create a deal on the Filecoin network. Keep up-to-date \u00b6 Follow the project on our blog and on our GitHub repo and give us your feedback.","title":"Introduction"},{"location":"powergate/#introduction-to-the-powergate","text":"The Powergate is an API driven solution for deploying multitiered storage across Filecoin and IPFS . Persistent storage on Filecoin allows rich storage configuration for data such as replication factor, miner selection, deal renewal, and repair. Network available storage is configurable and provided through a connected IPFS peer or pinning network. Warning The Powergate will remain in rapid development until close to the Filecoin Mainnet launch. During this time, will likely encounter bugs and unannounced API changes. Do not run the Powergate in production systems.","title":"Introduction to the Powergate"},{"location":"powergate/#overview","text":"Powergate is a collection of libraries, modules, and configurations that can used independently, and composed together to integrate Filecoin into your application or storage system. The Powergate is designed to manage one or many Filecoin wallet addresses. Each address in Powergate can be independently managed through the FFS API (or grouped together into a single FFS instance ). Some benefits of using the Powergate include: Ensure data stored on Filecoin is available on the IPFS network easily. Handle long-term storage deal management, including automated renew and repair. Make use of network indices to improve miner selection and deal creation. Manage Filecoin wallet addresses for one or many users. Easily configure, connect, and deploy Powergate, Lotus , and IPFS together. Much more!","title":"Overview"},{"location":"powergate/#libraries","text":"","title":"Libraries"},{"location":"powergate/#getting-started","text":"","title":"Getting started"},{"location":"powergate/#command-line-interface","text":"The Powergate includes the full set of features through the binary command-line interface. Install the CLI You can build and install the Powergate CLI from the Powergate Repo . git clone git@github.com:textileio/powergate.git cd powergate make build Info To compile from source, verify you have Go 1.14 or newer installed. All make commands install binaries in $GOPATH/bin , which usually is in $PATH , so you can run them right away from any folder in your terminal. Using the CLI Powergate CLI commands are just pow .","title":"Command-line Interface"},{"location":"powergate/#multi-tiered-storage","text":"The workhorse of APIs in the Powergate is called, the FFS (Filecoin File System). This module provides a multi-tiered file storage API built on Filecoin and IPFS. Storing data on IPFS and Filecoin is as easy as expressing your desired configuration for storing a Cid. The FFS is where the Powergate handles Filecoin wallet addresses, long-term deal management, and connecting Filecoin to IPFS. Access to the FFS is enabled through a basic token, allowing you to create many FFS Instances, and map Powergate API access to user(s) in your system. Read about the FFS here .","title":"Multi-tiered storage"},{"location":"powergate/#network-indices","text":"Indices A running Powergate deployment will collect a number of useful indices about the network. Some of the data collected in these indices are used by the FFS to streamline miner selection when creating new deals. You can use the indices directly to build other features into your own system. Miners index . Provides processed data regarding registered miners (on-chain and off-chain), such as: total miner power, relative power, online status, geolocation, and more! Ask index . Provides a fast-retrieval up to date snapshot of miner's asking prices for data storage. Slashing index . Provides history data about miners faults while proving their storage on-chain. Reputation Module Built on top of the previous indexes, a Reputation module constructs a weighted-scoring system that allows to sort miners considering multiple on-chain and off-chain data, such as: compared price to the median of the market, low storage-fault history, power on network, and external sources (soon!).","title":"Network Indices"},{"location":"powergate/#powergate-apis","text":"The Powergate APIs are available as gRPC endpoints. There are three ways to get familiar with the broad set of APIs available to start using on the Powergate. Explore the CLI . The CLI runs on the Powergate API, so in general, anything you can do in the CLI you can also do over the API. Use the JS Client . We have provided an easy to use JavaScript client for the Powergate APIs . User the Go Client . You can use the Powergate APIs from your go app by building directly on the Powergate Go Client . Browse the Protocols . The API is typed with Protocol Buffers and you can quickly view all capabilities by looking at the .proto files in the Powergate repo . The best place to start is the FFS API .","title":"Powergate APIs"},{"location":"powergate/#additional-tools","text":"The Powergate comes packed with a number of additional tools that will be useful to you as you integrate it into your system. Lotus . A Lotus node running on the current Testnet. IPFS . A full IPFS node running to back Powergate FFS. Prometheus . The backend for metrics processing. Grafana . Providing metrics dashboard. cAdvisor . Providing container metrics.","title":"Additional Tools"},{"location":"powergate/#running-the-powergate","text":"You can run the Powergate on the Filecoin testnet or using an embedded localnet we make available as part of the Powergate stack. We recommend starting out with the localnet as you'll get access to the full set of APIs and capabilities without having to start syncing the network right away. When ready, you can update your Powergate to connect to the live testnet and in the future mainnet .","title":"Running the Powergate"},{"location":"powergate/#localnet","text":"The localnet provides a fast, fully functional, embedded Filecoin network that can be used for testing, building, or running continuous integratin. Read more about running the Powergate on localnet or running the localnet to use the Lotus client directly .","title":"Localnet"},{"location":"powergate/#testnet","text":"Once you are ready to start using the Powergate with the Filecoin Testnet, it's just a single line. git clone git@github.com:textileio/powergate.git cd powergate/docker make up Read the latest setup instructions .","title":"Testnet"},{"location":"powergate/#mainnet","text":"When Filecoin Mainnet launches, we'll provide setup steps like the Testnet steps above.","title":"Mainnet"},{"location":"powergate/#learn-more","text":"","title":"Learn more"},{"location":"powergate/#walk-through-video","text":"In the above presentation, we'll give a high-level overview of how the Powergate fits into the Filecoin and IPFS networks and a detailed walk-through of system components.","title":"Walk-through Video"},{"location":"powergate/#running-system-video","text":"The above video shows the Powergate startup including IPFS and Lotus nodes. Next, the admin uses the Powergate CLI to create a deal on the Filecoin network.","title":"Running System Video"},{"location":"powergate/#keep-up-to-date","text":"Follow the project on our blog and on our GitHub repo and give us your feedback.","title":"Keep up-to-date"},{"location":"powergate/ffs/","text":"Storing Data \u00b6 The Filecoin File System API (FFS) manages all the necessary state and capabilities to provide multi-tiered file storage through the Powergate. The FFS is the primary API for storing and retrieving data, tracking long-term deals on Filecoin, and allowing data persisted on Filecoin to be available on IPFS. Intro to the FFS \u00b6 The FFS API is scoped to one or more Filecoin wallet addresses. So to start accessing the FFS API, you must init a new instance at which time the Powergate will: Create a new default wallet address for the FFS Instance. You can configure the Powergate to automatically fund new wallets from a master address. Create a new API token linked to the FFS Instance. Enable access to the FFS API through the use of the supplied token. Anytime you use the FFS API (including use through the CLI), you will supply the token to indicate which FFS Instance your requests are targeting. Since each FFS Instance has its own address, it has its own balance and therefor limits on the Filecoin network. Warning If you're providing a --lotusmasteraddr and --walletinitialfund , be sure that address exists in the Lotus node and it has enough funds, since walletinitialfund attoFILs will be sent from there to fund from newly created FFS instances. Recall that both flags are optional, and if not present there won't be any auto-funding transaction, so you're responsible to fund wallet addresses of new FFS instances. You can fund any testnet wallet address using the official Lotus Faucet. Multi-tiered design \u00b6 The FFS provides you API access to multi-tiered storage system built on IPFS and Filecoin. In many places, we refer to these two tiers of storage as Hot (IFPS) and Cold (Filecoin). This mirrors multi-tiered storage often deployed with a hot storage layer in memory and a cold storage layer on disk . Hot storage layer \u00b6 Data stored in the Powergate hot layer is available to the IPFS network (or private network). Hot storage is designed to be fast and available on the IPFS network (private or public DHT). The default StorageConfig enables both hot for all new data stored. Data stored with hot enabled is pinned to the Powergate's IPFS node. Cold storage layer \u00b6 Data stored in the Powergate Cold layer is stored by miners on the Filecoin network (localnet or testnet). You can use the StorageConfig to configure many properties of the Cold storage layer per file you store, such as where, how many copies, and how long to store the file. The default StorageConfig enables both hot and cold storage layers, meaning your data will be simultaneously available on IPFS and persisted on Filecoin. Moving between tiers \u00b6 Hot to Cold \u00b6 Data that is stored in the hot layer can be moved to cold storage in a couple different ways. The most common scenario is where data is stored initially with cold disabled and later a new StorageConfig is pushed that enables cold storage. In this scenario, Powergate will resolve the file from the hot layer, create any newly required Filecoin deals to fulfill. the cold storage settings. Cold to Hot \u00b6 Data stored only in the cold layer isn't guaranteed to be available on the IPFS network. In order for it to be, you need to push a new storage config that enables hot storage. You can automate this movement using the AllowUnfreeze flag of the StorageConfig . Either way, Powergate will always attempt resolve the data, first by trying to fetch it from the IPFS network, and if unable to do that, will execute a retrieval deal to pull the data from Finally. Finally, the data will be pinned in hot layer IPFS storage and available on the IPFS network. Read more about updating the StorageConfig here . Using the FFS \u00b6 To start using the FFS APIs you must first create an FFS Instance . Create an FFS Instance \u00b6 Using the Powergate CLI, you can create new FFS instances easily. pow ffs create Success Instance created with id 0ac0fb4d-581c-4276-bd90-a9aa30dd4cb4 and token 883f57b1-4e66-47f8-b291-7cf8b10f6370 Add environmental variable (optional) The --token is used to scope the requests to the FFS instance we created. You can skip setting the --token flag on every command by adding your new token as an environmental variable. For the rest of the examples, we'll assume you've set this environmental variable. export POW_TOKEN = 883f57b1-4e66-47f8-b291-7cf8b10f6370 Make data available \u00b6 The FFS requires data you aim to store to be available over IPFS. If you are using the CLI, you can ensure that it is available by staging it on IPFS using stage . Note that stage does not store your data in the Powergate FFS. It is an optional step that caches your data to ensure it is available on IPFS before being stored in the Powergate FFS. This is technically equivalent to ipfs add --pin=false , which is adding data without pinning it. pow ffs stage <path/filename> Success Success! Cached file in FFS hot storage with cid: <cid> Info If data exists on the IPFS network, you don't need to run stage as the Powergate will automatically fetch that data from remote peers. Initiate storage \u00b6 The Powergate manages each file stored in the FFS based on the setup defined in a StorageConfig . To tell the Powergate to start managing a new file by moving it from the cached state we created above to the Hot and/or Cold layers, we must push a new StorageConfig for the CID we generated above. Learn more about the StorageConfig here . Every FFS instance has a default StorageConfig that will be used for every new deal unless overridden. pow ffs config push --watch <cid> Success > Success! Pushed cid config for <cid> to FFS with job id: 70368cda-d65a-4e11-8a9f-fbf36135f563 JOB ID STATUS 70368cda-d65a-4e11-8a9f-fbf36135f563 Executing When complete, you should see, Success > Success! Pushed cid config for <cid> to FFS with job id: 70368cda-d65a-4e11-8a9f-fbf36135f563 JOB ID STATUS 70368cda-d65a-4e11-8a9f-fbf36135f563 Success Info The FFS is configured by default to run up to 50 pushes in parallel, though you can update this setting as needed. Read more about the FFS design here . FFS Watch The status will update as the deal progresses. If you push a file without the --watch flag, you can check the progress later using, watch . pow ffs watch <cid> Retrieve files \u00b6 Finally, you can verify that the file was stored on the network by making a request to get it back out. \u276f pow ffs get <cid> myfile2 Success Success! Data written to myfile2 Warning If you ever interact directly with the IPFS node, do not ever manually modify the pinset. The Powergate requires full control over the pinset, since it is required when users specify HotStorage.Enabled=true . Manually interacting with the IPFS node's pinset could lead to unexpected behavior in the Powergate. Miner selection \u00b6 Powergate has many internal components that are used to simplify the process of using Filecoin. One set of components are the Powergate's indexes, where it collects information about miners including, power, sector size, storage ask price, etc. With that information, the Powergate can create a reasonable ranking of miners. Miners that are most promising for making deals will show up at the top. When pushing data to cold storage, the FFS will use this information to automate finding miners and initiating deals. You can use the StorageConfig to help direct the Powergate to miners that match your particular requirements. Learn more \u00b6 The FFS does a lot of work out of the box. If you'd like to learn more about the components, design, and capabilities of the FFS, we encourage you to read the FFS Design document .","title":"Intro to FFS"},{"location":"powergate/ffs/#storing-data","text":"The Filecoin File System API (FFS) manages all the necessary state and capabilities to provide multi-tiered file storage through the Powergate. The FFS is the primary API for storing and retrieving data, tracking long-term deals on Filecoin, and allowing data persisted on Filecoin to be available on IPFS.","title":"Storing Data"},{"location":"powergate/ffs/#intro-to-the-ffs","text":"The FFS API is scoped to one or more Filecoin wallet addresses. So to start accessing the FFS API, you must init a new instance at which time the Powergate will: Create a new default wallet address for the FFS Instance. You can configure the Powergate to automatically fund new wallets from a master address. Create a new API token linked to the FFS Instance. Enable access to the FFS API through the use of the supplied token. Anytime you use the FFS API (including use through the CLI), you will supply the token to indicate which FFS Instance your requests are targeting. Since each FFS Instance has its own address, it has its own balance and therefor limits on the Filecoin network. Warning If you're providing a --lotusmasteraddr and --walletinitialfund , be sure that address exists in the Lotus node and it has enough funds, since walletinitialfund attoFILs will be sent from there to fund from newly created FFS instances. Recall that both flags are optional, and if not present there won't be any auto-funding transaction, so you're responsible to fund wallet addresses of new FFS instances. You can fund any testnet wallet address using the official Lotus Faucet.","title":"Intro to the FFS"},{"location":"powergate/ffs/#multi-tiered-design","text":"The FFS provides you API access to multi-tiered storage system built on IPFS and Filecoin. In many places, we refer to these two tiers of storage as Hot (IFPS) and Cold (Filecoin). This mirrors multi-tiered storage often deployed with a hot storage layer in memory and a cold storage layer on disk .","title":"Multi-tiered design"},{"location":"powergate/ffs/#hot-storage-layer","text":"Data stored in the Powergate hot layer is available to the IPFS network (or private network). Hot storage is designed to be fast and available on the IPFS network (private or public DHT). The default StorageConfig enables both hot for all new data stored. Data stored with hot enabled is pinned to the Powergate's IPFS node.","title":"Hot storage layer"},{"location":"powergate/ffs/#cold-storage-layer","text":"Data stored in the Powergate Cold layer is stored by miners on the Filecoin network (localnet or testnet). You can use the StorageConfig to configure many properties of the Cold storage layer per file you store, such as where, how many copies, and how long to store the file. The default StorageConfig enables both hot and cold storage layers, meaning your data will be simultaneously available on IPFS and persisted on Filecoin.","title":"Cold storage layer"},{"location":"powergate/ffs/#moving-between-tiers","text":"","title":"Moving between tiers"},{"location":"powergate/ffs/#hot-to-cold","text":"Data that is stored in the hot layer can be moved to cold storage in a couple different ways. The most common scenario is where data is stored initially with cold disabled and later a new StorageConfig is pushed that enables cold storage. In this scenario, Powergate will resolve the file from the hot layer, create any newly required Filecoin deals to fulfill. the cold storage settings.","title":"Hot to Cold"},{"location":"powergate/ffs/#cold-to-hot","text":"Data stored only in the cold layer isn't guaranteed to be available on the IPFS network. In order for it to be, you need to push a new storage config that enables hot storage. You can automate this movement using the AllowUnfreeze flag of the StorageConfig . Either way, Powergate will always attempt resolve the data, first by trying to fetch it from the IPFS network, and if unable to do that, will execute a retrieval deal to pull the data from Finally. Finally, the data will be pinned in hot layer IPFS storage and available on the IPFS network. Read more about updating the StorageConfig here .","title":"Cold to Hot"},{"location":"powergate/ffs/#using-the-ffs","text":"To start using the FFS APIs you must first create an FFS Instance .","title":"Using the FFS"},{"location":"powergate/ffs/#create-an-ffs-instance","text":"Using the Powergate CLI, you can create new FFS instances easily. pow ffs create Success Instance created with id 0ac0fb4d-581c-4276-bd90-a9aa30dd4cb4 and token 883f57b1-4e66-47f8-b291-7cf8b10f6370 Add environmental variable (optional) The --token is used to scope the requests to the FFS instance we created. You can skip setting the --token flag on every command by adding your new token as an environmental variable. For the rest of the examples, we'll assume you've set this environmental variable. export POW_TOKEN = 883f57b1-4e66-47f8-b291-7cf8b10f6370","title":"Create an FFS Instance"},{"location":"powergate/ffs/#make-data-available","text":"The FFS requires data you aim to store to be available over IPFS. If you are using the CLI, you can ensure that it is available by staging it on IPFS using stage . Note that stage does not store your data in the Powergate FFS. It is an optional step that caches your data to ensure it is available on IPFS before being stored in the Powergate FFS. This is technically equivalent to ipfs add --pin=false , which is adding data without pinning it. pow ffs stage <path/filename> Success Success! Cached file in FFS hot storage with cid: <cid> Info If data exists on the IPFS network, you don't need to run stage as the Powergate will automatically fetch that data from remote peers.","title":"Make data available"},{"location":"powergate/ffs/#initiate-storage","text":"The Powergate manages each file stored in the FFS based on the setup defined in a StorageConfig . To tell the Powergate to start managing a new file by moving it from the cached state we created above to the Hot and/or Cold layers, we must push a new StorageConfig for the CID we generated above. Learn more about the StorageConfig here . Every FFS instance has a default StorageConfig that will be used for every new deal unless overridden. pow ffs config push --watch <cid> Success > Success! Pushed cid config for <cid> to FFS with job id: 70368cda-d65a-4e11-8a9f-fbf36135f563 JOB ID STATUS 70368cda-d65a-4e11-8a9f-fbf36135f563 Executing When complete, you should see, Success > Success! Pushed cid config for <cid> to FFS with job id: 70368cda-d65a-4e11-8a9f-fbf36135f563 JOB ID STATUS 70368cda-d65a-4e11-8a9f-fbf36135f563 Success Info The FFS is configured by default to run up to 50 pushes in parallel, though you can update this setting as needed. Read more about the FFS design here . FFS Watch The status will update as the deal progresses. If you push a file without the --watch flag, you can check the progress later using, watch . pow ffs watch <cid>","title":"Initiate storage"},{"location":"powergate/ffs/#retrieve-files","text":"Finally, you can verify that the file was stored on the network by making a request to get it back out. \u276f pow ffs get <cid> myfile2 Success Success! Data written to myfile2 Warning If you ever interact directly with the IPFS node, do not ever manually modify the pinset. The Powergate requires full control over the pinset, since it is required when users specify HotStorage.Enabled=true . Manually interacting with the IPFS node's pinset could lead to unexpected behavior in the Powergate.","title":"Retrieve files"},{"location":"powergate/ffs/#miner-selection","text":"Powergate has many internal components that are used to simplify the process of using Filecoin. One set of components are the Powergate's indexes, where it collects information about miners including, power, sector size, storage ask price, etc. With that information, the Powergate can create a reasonable ranking of miners. Miners that are most promising for making deals will show up at the top. When pushing data to cold storage, the FFS will use this information to automate finding miners and initiating deals. You can use the StorageConfig to help direct the Powergate to miners that match your particular requirements.","title":"Miner selection"},{"location":"powergate/ffs/#learn-more","text":"The FFS does a lot of work out of the box. If you'd like to learn more about the components, design, and capabilities of the FFS, we encourage you to read the FFS Design document .","title":"Learn more"},{"location":"powergate/localnet/","text":"Filecoin Localnet \u00b6 Having a fully synced Lotus node can take a considerable amount of time and effort to maintain. The required effort is normal on live blockchain networks, but isn't ideal in some scenarios. Scenarios such as application development, testing, and continuous integration can be enhanced by having access to Lotus nodes and APIs that don't require connection to the live network. For those cases, we have built the localnet . Speed The localnet is tuned for speed. After you have the docker instances installed, starting the localnet should take under a minute and storing a file in a new deal should take about a minute with the default settings and faster with custom settings. The localnet runs a local localnet with a mock sector-builder. This enables fast deployment of a development Filecoin network containing miners with mocked sealing but the rest of the network logic remaining the same as that of the production Filecoin network. The miners are configured to accept and store all incoming deals. Configurable Depending on your use case you can change settings such as block generation speed and sector sizes. For CI environments you may set block production speeds to the order of ~100ms and disable --bigsectors . This localnet setup would be optimized for minimum CPU usage and very fast chain progress, which can confirm deals in seconds. If you require more realistic scenarios (e.g. during product demos), you can change to block production speed to ~1s and enable --bigsectors . This would progress deal slow enough that you can observe updates in the status of confirmed deals at the rate of ~1 minute and also store larger files if required. Warning Not using --bigsectors will limit you to storing files of around 700 bytes and deals will complete in 30-60 seconds. Using --bigsectors will allow you to store files anywhere from 1Mb to 400Mb, but deals will complete in 3-4 minutes. Be sure to choose the value that makes sense for your development scenario. Production compatible storage The localnet is designed so that you can build and test your system quickly but function the exact same way as the production Filecoin network, except faster and entirely local. The localnet supports both 2KiB and 512MiB sectors, and the speed of block production is configurable. For advanced features, refer to the localnet Readme . Localnet Miners \u00b6 Miners are generated deterministically when you start the localnet. If you run the localnet with a single miner, the miner's address will be t01000 . If you start the localnet with two miners, the addresses will be t01000 and t01001 . And so on. When running the localnet within the Powergate, you can also fetch miner details from the miner API endpoints and CLI. Getting Started \u00b6 There are a few resources you'll need before you start running any nodes. Docker Desktop . In the examples below, you'll run node instances using local Docker containers. You can do the same with any Docker enabled system, but to get started we recommend Docker Desktop and the default configurations we provide. Powergate . If you run the localnet as part of the Powergate, you should get the latest version of the Powergate source code. Golang . Building the Powergate CLI from code requires that you can run commands with Go. Other sections of the tutorials below don't have any Go requirement. Localnet with Powergate \u00b6 If you're interested in running Powergate to experiment with the CLI or APIs, the fastest way is to replace the Lotus client dependency with a running localnet. This will run the Powergate on a Lotus client connected to an embedded network of miners. Installation \u00b6 You can run a localnet setup by using a Powergate release or by using Powergate source code. Download a release \u00b6 Visit the latest Powergate release page and download the powergate-docker-<version>.zip release artifact. Unzip it and cd into the resulting directory: unzip powergate-docker-<version>.zip cd powergate-docker-<version> Use Powergate source code \u00b6 Clone the Powergate and cd into the project's docker directory: git clone git@github.com:textileio/powergate.git cd powergate/docker Setup \u00b6 With whichever method you chose in the Installation section above, you can now use the provided docker-compose configuration. With the default setup, you will run Powergate connected to a local localnet with 512Mib sectors and instantly available gRPC API or CLI that don't require any extra config flags \ud83c\udf8a Run the docker-compose Docker files for the Powergate are all contained in the folder, /docker . BIGSECTORS = true make localnet Info You can set BIGSECTORS according to your needs. See the description above for more information. If you don't specify a BIGSECTORS environment variable, the default is true . If this is your first time running the Powergate, Docker will download the required instances before any Powergate setup begins. Downloads are dependent on your bandwidth and may take a few minutes , but wont be required for subsequent runs of the Powergate. Once running, you will begin to see log outputs, including those of the embedded miner. lotus_1 | 2020 -05-29T20:35:08.644Z WARN miner miner/miner.go:177 \\ mined block in the past { \"block-time\" : \"2009-01-01T04:44:30.000Z\" , \\ \"time\" : \"2020-05-29T20:35:08.644Z\" , \"duration\" : 359999438 .64444387 } When complete, you will have a fully functional Powergate ( powd ), a Lotus localnet, and an IPFS node wired correctly together to start using. Create a deal and store a file \u00b6 Now that your Powergate is running on localnet, all the CLI and API commands are the same as using it in production mode, just your deals will store faster (and disappear when you delete the localnet). Install the CLI \u00b6 You can install the CLI from a Powergate release or from source. Download a release \u00b6 Visit the latest Powergate release page and download the pow_<version>_<platform>.tar.gz file appropriate for your system. Unzip and install pow (following example is for unix-like systems): tar -xzvf pow_v0.1.0_darwin-amd64.tar.gz ./install Moved ./pow to /usr/local/bin Info If you're installing on macOS, there are some system permissions issues you'll have to deal with. Please follow the hub installation instructions to work around the issue. Build from source \u00b6 From the root of the powergate repo, you can build the CLI from the latest code. This will install the Powergate CLI, pow , on your machine. make build-pow Test your installation. pow --help Start storing data \u00b6 You are now ready to start storing and retrieving data using the Powergate. Read more on Storing Data with the FFS . Localnet with Lotus Client \u00b6 You can run the localnet to make use of the Lotus Client with all the benefits described in the introduction but no Powergate or IPFS components. Run from Docker image \u00b6 You can run localnet with the Docker image we maintain. Running the image is just a single line. docker run --name texlocalnet -e TEXLOTUSDEVNET_SPEED = 1500 \\ -e TEXLOTUSDEVNET_BIGSECTORS = true -p 1234 :7777 \\ -v /tmp/import:/tmp/import textile/lotus-devnet After running the container, the Lotus API endpoint is available at the default port which lets you use the Lotus CLI without any extra configuration. Recall that localnets should be used as ephemeral networks, so be sure to stop and remove the texlocalnet container if you re-rerun the above command again. If you plan to use the ClientImport API or lotus client import command, your target file to import should be in the /tmp/import path on your host machine. This folder is bound to the docker image and the localnet, so the Lotus node can find it under the same path. Finally, notice that the above command doesn't specify the textile/lotus-devnet tag, so it's recommended that you consider updating your cached latest tag. Configuration parameters In the above we use the environmental variables to set the speed and bigsectors flags. The complete mapping of options is, TEXLOTUSDEVNET_SPEED: time in milliseconds of blocks/tipset generation. TEXLOTUSDEVNET_BIGSECTORS: If true, the localnet will run on 512Mib sectors, but 2Kib otherwise. TEXLOTUSDEVNET_NUMMINERS: The number of miners in the localnet. This is an experimental feature, which seems stable for <=3. TEXLOTUSDEVNET_IPFSADDR: Optional multiaddr of an IPFS node to enable the Lotus node be connected to an IPFS node to avoid importing deals data, and storing retrievals. Run from source code \u00b6 Requirements Devnet . If you run the localnet with a stand-alone Lotus node, you should get the latest version of the localnet source code. Installation \u00b6 Clone the lotus-devnet repo and cd into the project git clone git@github.com:textileio/lotus-devnet.git cd lotus-devnet Setup \u00b6 Install the dependencies: make build Run the devnet with: go run main.go If you've previously compiled a prior version of lotus-devnet , running make clean is recommended before building again. For full configuration options, see the project Readme","title":"Localnet"},{"location":"powergate/localnet/#filecoin-localnet","text":"Having a fully synced Lotus node can take a considerable amount of time and effort to maintain. The required effort is normal on live blockchain networks, but isn't ideal in some scenarios. Scenarios such as application development, testing, and continuous integration can be enhanced by having access to Lotus nodes and APIs that don't require connection to the live network. For those cases, we have built the localnet . Speed The localnet is tuned for speed. After you have the docker instances installed, starting the localnet should take under a minute and storing a file in a new deal should take about a minute with the default settings and faster with custom settings. The localnet runs a local localnet with a mock sector-builder. This enables fast deployment of a development Filecoin network containing miners with mocked sealing but the rest of the network logic remaining the same as that of the production Filecoin network. The miners are configured to accept and store all incoming deals. Configurable Depending on your use case you can change settings such as block generation speed and sector sizes. For CI environments you may set block production speeds to the order of ~100ms and disable --bigsectors . This localnet setup would be optimized for minimum CPU usage and very fast chain progress, which can confirm deals in seconds. If you require more realistic scenarios (e.g. during product demos), you can change to block production speed to ~1s and enable --bigsectors . This would progress deal slow enough that you can observe updates in the status of confirmed deals at the rate of ~1 minute and also store larger files if required. Warning Not using --bigsectors will limit you to storing files of around 700 bytes and deals will complete in 30-60 seconds. Using --bigsectors will allow you to store files anywhere from 1Mb to 400Mb, but deals will complete in 3-4 minutes. Be sure to choose the value that makes sense for your development scenario. Production compatible storage The localnet is designed so that you can build and test your system quickly but function the exact same way as the production Filecoin network, except faster and entirely local. The localnet supports both 2KiB and 512MiB sectors, and the speed of block production is configurable. For advanced features, refer to the localnet Readme .","title":"Filecoin Localnet"},{"location":"powergate/localnet/#localnet-miners","text":"Miners are generated deterministically when you start the localnet. If you run the localnet with a single miner, the miner's address will be t01000 . If you start the localnet with two miners, the addresses will be t01000 and t01001 . And so on. When running the localnet within the Powergate, you can also fetch miner details from the miner API endpoints and CLI.","title":"Localnet Miners"},{"location":"powergate/localnet/#getting-started","text":"There are a few resources you'll need before you start running any nodes. Docker Desktop . In the examples below, you'll run node instances using local Docker containers. You can do the same with any Docker enabled system, but to get started we recommend Docker Desktop and the default configurations we provide. Powergate . If you run the localnet as part of the Powergate, you should get the latest version of the Powergate source code. Golang . Building the Powergate CLI from code requires that you can run commands with Go. Other sections of the tutorials below don't have any Go requirement.","title":"Getting Started"},{"location":"powergate/localnet/#localnet-with-powergate","text":"If you're interested in running Powergate to experiment with the CLI or APIs, the fastest way is to replace the Lotus client dependency with a running localnet. This will run the Powergate on a Lotus client connected to an embedded network of miners.","title":"Localnet with Powergate"},{"location":"powergate/localnet/#installation","text":"You can run a localnet setup by using a Powergate release or by using Powergate source code.","title":"Installation"},{"location":"powergate/localnet/#download-a-release","text":"Visit the latest Powergate release page and download the powergate-docker-<version>.zip release artifact. Unzip it and cd into the resulting directory: unzip powergate-docker-<version>.zip cd powergate-docker-<version>","title":"Download a release"},{"location":"powergate/localnet/#use-powergate-source-code","text":"Clone the Powergate and cd into the project's docker directory: git clone git@github.com:textileio/powergate.git cd powergate/docker","title":"Use Powergate source code"},{"location":"powergate/localnet/#setup","text":"With whichever method you chose in the Installation section above, you can now use the provided docker-compose configuration. With the default setup, you will run Powergate connected to a local localnet with 512Mib sectors and instantly available gRPC API or CLI that don't require any extra config flags \ud83c\udf8a Run the docker-compose Docker files for the Powergate are all contained in the folder, /docker . BIGSECTORS = true make localnet Info You can set BIGSECTORS according to your needs. See the description above for more information. If you don't specify a BIGSECTORS environment variable, the default is true . If this is your first time running the Powergate, Docker will download the required instances before any Powergate setup begins. Downloads are dependent on your bandwidth and may take a few minutes , but wont be required for subsequent runs of the Powergate. Once running, you will begin to see log outputs, including those of the embedded miner. lotus_1 | 2020 -05-29T20:35:08.644Z WARN miner miner/miner.go:177 \\ mined block in the past { \"block-time\" : \"2009-01-01T04:44:30.000Z\" , \\ \"time\" : \"2020-05-29T20:35:08.644Z\" , \"duration\" : 359999438 .64444387 } When complete, you will have a fully functional Powergate ( powd ), a Lotus localnet, and an IPFS node wired correctly together to start using.","title":"Setup"},{"location":"powergate/localnet/#create-a-deal-and-store-a-file","text":"Now that your Powergate is running on localnet, all the CLI and API commands are the same as using it in production mode, just your deals will store faster (and disappear when you delete the localnet).","title":"Create a deal and store a file"},{"location":"powergate/localnet/#install-the-cli","text":"You can install the CLI from a Powergate release or from source.","title":"Install the CLI"},{"location":"powergate/localnet/#download-a-release_1","text":"Visit the latest Powergate release page and download the pow_<version>_<platform>.tar.gz file appropriate for your system. Unzip and install pow (following example is for unix-like systems): tar -xzvf pow_v0.1.0_darwin-amd64.tar.gz ./install Moved ./pow to /usr/local/bin Info If you're installing on macOS, there are some system permissions issues you'll have to deal with. Please follow the hub installation instructions to work around the issue.","title":"Download a release"},{"location":"powergate/localnet/#build-from-source","text":"From the root of the powergate repo, you can build the CLI from the latest code. This will install the Powergate CLI, pow , on your machine. make build-pow Test your installation. pow --help","title":"Build from source"},{"location":"powergate/localnet/#start-storing-data","text":"You are now ready to start storing and retrieving data using the Powergate. Read more on Storing Data with the FFS .","title":"Start storing data"},{"location":"powergate/localnet/#localnet-with-lotus-client","text":"You can run the localnet to make use of the Lotus Client with all the benefits described in the introduction but no Powergate or IPFS components.","title":"Localnet with Lotus Client"},{"location":"powergate/localnet/#run-from-docker-image","text":"You can run localnet with the Docker image we maintain. Running the image is just a single line. docker run --name texlocalnet -e TEXLOTUSDEVNET_SPEED = 1500 \\ -e TEXLOTUSDEVNET_BIGSECTORS = true -p 1234 :7777 \\ -v /tmp/import:/tmp/import textile/lotus-devnet After running the container, the Lotus API endpoint is available at the default port which lets you use the Lotus CLI without any extra configuration. Recall that localnets should be used as ephemeral networks, so be sure to stop and remove the texlocalnet container if you re-rerun the above command again. If you plan to use the ClientImport API or lotus client import command, your target file to import should be in the /tmp/import path on your host machine. This folder is bound to the docker image and the localnet, so the Lotus node can find it under the same path. Finally, notice that the above command doesn't specify the textile/lotus-devnet tag, so it's recommended that you consider updating your cached latest tag. Configuration parameters In the above we use the environmental variables to set the speed and bigsectors flags. The complete mapping of options is, TEXLOTUSDEVNET_SPEED: time in milliseconds of blocks/tipset generation. TEXLOTUSDEVNET_BIGSECTORS: If true, the localnet will run on 512Mib sectors, but 2Kib otherwise. TEXLOTUSDEVNET_NUMMINERS: The number of miners in the localnet. This is an experimental feature, which seems stable for <=3. TEXLOTUSDEVNET_IPFSADDR: Optional multiaddr of an IPFS node to enable the Lotus node be connected to an IPFS node to avoid importing deals data, and storing retrievals.","title":"Run from Docker image"},{"location":"powergate/localnet/#run-from-source-code","text":"Requirements Devnet . If you run the localnet with a stand-alone Lotus node, you should get the latest version of the localnet source code.","title":"Run from source code"},{"location":"powergate/localnet/#installation_1","text":"Clone the lotus-devnet repo and cd into the project git clone git@github.com:textileio/lotus-devnet.git cd lotus-devnet","title":"Installation"},{"location":"powergate/localnet/#setup_1","text":"Install the dependencies: make build Run the devnet with: go run main.go If you've previously compiled a prior version of lotus-devnet , running make clean is recommended before building again. For full configuration options, see the project Readme","title":"Setup"},{"location":"powergate/storageconfig/","text":"Managing Storage with the StorageConfig \u00b6 Every FFS instance can manage how data is stored on IPFS and Filecoin using the StorageConfig ( details below ). The StorageConfig is a powerful tool to customize all the details of how you store data on Filecoin, make it available over IPFS, enforce replication, manage expiring deals, and more. Setting the StorageConfig \u00b6 In every Powergate deployment there are three ways to manage StorageConfigs throughout the system. The FFS instance default StorageConfig. This is initially set by the system default StorageConfig. It can be modified by the FFS instance owner after creation. The storage request StorageConfig. This will use the FFS instance default, but a custom StorageConfig can also be supplied at request time. A storage update StorageConfig. Any StorageConfigs attached to existing stored data can be updated with a new StorageConfig. The FFS instance will then work to modify the way data is stored to match the new configuration Get the default StorageConfig of an FFS instance \u00b6 View the current default StorageConfig of an FFS instance. pow ffs config default -t <token> Set the default StorageConfig of an FFS instance \u00b6 To set the default StorageConfig to one stored in new-config.json . pow ffs config set-default new-config.json -t <token> Set a custom StorageConfig at storage time \u00b6 You can provide a flag ( -c ) to include a custom StorageConfig for a new storage request. Storage requests without a custom StorageConfig will use the instance default storage config. pow ffs config push <cid> -t <token> -c custom-config.json Get the StorageConfig of previously stored data \u00b6 To pull the StorageConfig associated with data already managed by the FFS instance, use the of the stored data. pow ffs config get <cid> -t <token> Update the StorageConfig of existing data \u00b6 To update the StorageConfig of data already stored and managed by the Powergate with a new config stored in updated-config.json . This command requires the override flag ( -o ) to confirm that you understand that the command will replace an existing config. pow ffs config push <cid> -t <token> -o -c updated-config.json StorageConfig Details \u00b6 Here is an example of the default StorageConfig . { // Hot has this desired storing configuration in Hot Storage. \"Hot\" : { // Enable indicates if Cid data is stored. If true, it will // consider further configurations to execute actions. \"Enabled\" : true , // AllowUnfreeze indicates that if data isn't available in the // Hot Storage, it's allowed to be feeded by Cold Storage if // available. \"AllowUnfreeze\" : false , \"Ipfs\" : { // AddTimeout is an upper bound on adding data to IPFS node from // the network before failing. \"AddTimeout\" : 30 } }, // Cold has desired storing configuration in the Cold Storage. \"Cold\" : { // Enabled indicates that data will be saved in Cold storage. // If is switched from false->true, it will consider the other // attributes as the desired state of the data in this Storage. \"Enabled\" : true , // Filecoin describes the desired Filecoin configuration for a // Cid in the Filecoin network. \"Filecoin\" : { // RepFactor indicates the desired amount of active deals // with different miners to store the data. While making deals // the other attributes of FilConfig are considered for miner // selection. \"RepFactor\" : 1 , // DealDuration indicates the duration to be used when making // new deals. \"DealDuration\" : 1000 , // ExcludedMiners is a set of miner addresses won't be ever be // selected when making new deals, even if they comply to other // filters. \"ExcludedMiners\" : null , // TrustedMiners is a set of miner addresses which will be // forcibly used when making new deals. An empty/nil list // disables this feature. \"TrustedMiners\" : null , // CountryCodes indicates that new deals should select miners // on specific countries. \"CountryCodes\" : null , // Renew indicates deal-renewal configuration. \"Renew\" : { // Enabled indicates that deal-renewal is enabled for this // Cid. \"Enabled\" : false , // Threshold indicates how many epochs before expiring should // trigger deal renewal. e.g: 100 epoch before expiring. \"Threshold\" : 0 }, // Addr is the wallet address used to store the data in filecoin \"Addr\" : \"<unique>\" , \"MaxPrice\" : 0 } }, // If true, Powergate will detect if the data is no longer // stored according to the StorageConfig requirements and // make new storage arrangements that match the StorageConfig \"Repairable\" : false }","title":"Storage Configs"},{"location":"powergate/storageconfig/#managing-storage-with-the-storageconfig","text":"Every FFS instance can manage how data is stored on IPFS and Filecoin using the StorageConfig ( details below ). The StorageConfig is a powerful tool to customize all the details of how you store data on Filecoin, make it available over IPFS, enforce replication, manage expiring deals, and more.","title":"Managing Storage with the StorageConfig"},{"location":"powergate/storageconfig/#setting-the-storageconfig","text":"In every Powergate deployment there are three ways to manage StorageConfigs throughout the system. The FFS instance default StorageConfig. This is initially set by the system default StorageConfig. It can be modified by the FFS instance owner after creation. The storage request StorageConfig. This will use the FFS instance default, but a custom StorageConfig can also be supplied at request time. A storage update StorageConfig. Any StorageConfigs attached to existing stored data can be updated with a new StorageConfig. The FFS instance will then work to modify the way data is stored to match the new configuration","title":"Setting the StorageConfig"},{"location":"powergate/storageconfig/#get-the-default-storageconfig-of-an-ffs-instance","text":"View the current default StorageConfig of an FFS instance. pow ffs config default -t <token>","title":"Get the default StorageConfig of an FFS instance"},{"location":"powergate/storageconfig/#set-the-default-storageconfig-of-an-ffs-instance","text":"To set the default StorageConfig to one stored in new-config.json . pow ffs config set-default new-config.json -t <token>","title":"Set the default StorageConfig of an FFS instance"},{"location":"powergate/storageconfig/#set-a-custom-storageconfig-at-storage-time","text":"You can provide a flag ( -c ) to include a custom StorageConfig for a new storage request. Storage requests without a custom StorageConfig will use the instance default storage config. pow ffs config push <cid> -t <token> -c custom-config.json","title":"Set a custom StorageConfig at storage time"},{"location":"powergate/storageconfig/#get-the-storageconfig-of-previously-stored-data","text":"To pull the StorageConfig associated with data already managed by the FFS instance, use the of the stored data. pow ffs config get <cid> -t <token>","title":"Get the StorageConfig of previously stored data"},{"location":"powergate/storageconfig/#update-the-storageconfig-of-existing-data","text":"To update the StorageConfig of data already stored and managed by the Powergate with a new config stored in updated-config.json . This command requires the override flag ( -o ) to confirm that you understand that the command will replace an existing config. pow ffs config push <cid> -t <token> -o -c updated-config.json","title":"Update the StorageConfig of existing data"},{"location":"powergate/storageconfig/#storageconfig-details","text":"Here is an example of the default StorageConfig . { // Hot has this desired storing configuration in Hot Storage. \"Hot\" : { // Enable indicates if Cid data is stored. If true, it will // consider further configurations to execute actions. \"Enabled\" : true , // AllowUnfreeze indicates that if data isn't available in the // Hot Storage, it's allowed to be feeded by Cold Storage if // available. \"AllowUnfreeze\" : false , \"Ipfs\" : { // AddTimeout is an upper bound on adding data to IPFS node from // the network before failing. \"AddTimeout\" : 30 } }, // Cold has desired storing configuration in the Cold Storage. \"Cold\" : { // Enabled indicates that data will be saved in Cold storage. // If is switched from false->true, it will consider the other // attributes as the desired state of the data in this Storage. \"Enabled\" : true , // Filecoin describes the desired Filecoin configuration for a // Cid in the Filecoin network. \"Filecoin\" : { // RepFactor indicates the desired amount of active deals // with different miners to store the data. While making deals // the other attributes of FilConfig are considered for miner // selection. \"RepFactor\" : 1 , // DealDuration indicates the duration to be used when making // new deals. \"DealDuration\" : 1000 , // ExcludedMiners is a set of miner addresses won't be ever be // selected when making new deals, even if they comply to other // filters. \"ExcludedMiners\" : null , // TrustedMiners is a set of miner addresses which will be // forcibly used when making new deals. An empty/nil list // disables this feature. \"TrustedMiners\" : null , // CountryCodes indicates that new deals should select miners // on specific countries. \"CountryCodes\" : null , // Renew indicates deal-renewal configuration. \"Renew\" : { // Enabled indicates that deal-renewal is enabled for this // Cid. \"Enabled\" : false , // Threshold indicates how many epochs before expiring should // trigger deal renewal. e.g: 100 epoch before expiring. \"Threshold\" : 0 }, // Addr is the wallet address used to store the data in filecoin \"Addr\" : \"<unique>\" , \"MaxPrice\" : 0 } }, // If true, Powergate will detect if the data is no longer // stored according to the StorageConfig requirements and // make new storage arrangements that match the StorageConfig \"Repairable\" : false }","title":"StorageConfig Details"},{"location":"powergate/testnet/","text":"Filecoin Testnet \u00b6 If you are ready to run on Testnet, the Powergate should make it as easy as possible. Note that running a fully synced Lotus node can take a considerable amount of time and resources. The required effort is normal on live blockchain networks. It may take more than a day to properly sync the current chain the first time your run the Powergate. Getting Started \u00b6 There are a few resources you'll need before you start running any nodes. Docker Desktop . In the examples below, you'll run node instances using local Docker containers. You can do the same with any Docker enabled system, but to get started we recommend Docker Desktop and the default configurations we provide. Powergate . Golang . Building the Powergate CLI from code requires that you can run commands with Go. Other sections of the tutorials below don't have any Go requirement. Testnet with Powergate \u00b6 Installation \u00b6 Clone the Powergate and cd into the project git clone git@github.com:textileio/powergate.git cd powergate Setup \u00b6 A default setup is available in a docker-compose configuration shipped with the Powergate. With the default setup, you will run Powergate connected to live Filecoin testnet. Run the docker-compose Docker files for the Powergate are all contained in the folder, /docker . cd docker make up If this is your first time running the Powergate, Docker will download the required instances before any Powergate setup begins. Downloads are dependent on your bandwidth and may take a few minutes , but wont be required for subsequent runs of the Powergate. If this is the first time you are running the Powergate on the testnet, or if you have been offline for any amount of time, you will need to wait for the chain to properly sync. This will likely take more than a day. Once running, you will begin to see log outputs. lotus_1 | 2020 -05-29T20:35:08.644Z WARN miner miner/miner.go:177 \\ mined block in the past { \"block-time\" : \"2009-01-01T04:44:30.000Z\" , \\ \"time\" : \"2020-05-29T20:35:08.644Z\" , \"duration\" : 359999438 .64444387 } When complete, you will have a fully functional Powergate ( powd ), a Lotus node, and an IPFS node wired correctly together to start using the Testnet! Create a deal and store a file \u00b6 Now that your Powergate is running on testnet, all the CLI and API commands are the same as if you had run it on localnet before. Install the CLI \u00b6 From the root of the powergate repo, you can build the CLI from the latest code. This will install the Powergate CLI, pow , on your machine. make build Test your installation. pow --help Start storing data \u00b6 You are now ready to start storing and retrieving data using the Powergate. Read more on Storing Data with the FFS .","title":"Testnet"},{"location":"powergate/testnet/#filecoin-testnet","text":"If you are ready to run on Testnet, the Powergate should make it as easy as possible. Note that running a fully synced Lotus node can take a considerable amount of time and resources. The required effort is normal on live blockchain networks. It may take more than a day to properly sync the current chain the first time your run the Powergate.","title":"Filecoin Testnet"},{"location":"powergate/testnet/#getting-started","text":"There are a few resources you'll need before you start running any nodes. Docker Desktop . In the examples below, you'll run node instances using local Docker containers. You can do the same with any Docker enabled system, but to get started we recommend Docker Desktop and the default configurations we provide. Powergate . Golang . Building the Powergate CLI from code requires that you can run commands with Go. Other sections of the tutorials below don't have any Go requirement.","title":"Getting Started"},{"location":"powergate/testnet/#testnet-with-powergate","text":"","title":"Testnet with Powergate"},{"location":"powergate/testnet/#installation","text":"Clone the Powergate and cd into the project git clone git@github.com:textileio/powergate.git cd powergate","title":"Installation"},{"location":"powergate/testnet/#setup","text":"A default setup is available in a docker-compose configuration shipped with the Powergate. With the default setup, you will run Powergate connected to live Filecoin testnet. Run the docker-compose Docker files for the Powergate are all contained in the folder, /docker . cd docker make up If this is your first time running the Powergate, Docker will download the required instances before any Powergate setup begins. Downloads are dependent on your bandwidth and may take a few minutes , but wont be required for subsequent runs of the Powergate. If this is the first time you are running the Powergate on the testnet, or if you have been offline for any amount of time, you will need to wait for the chain to properly sync. This will likely take more than a day. Once running, you will begin to see log outputs. lotus_1 | 2020 -05-29T20:35:08.644Z WARN miner miner/miner.go:177 \\ mined block in the past { \"block-time\" : \"2009-01-01T04:44:30.000Z\" , \\ \"time\" : \"2020-05-29T20:35:08.644Z\" , \"duration\" : 359999438 .64444387 } When complete, you will have a fully functional Powergate ( powd ), a Lotus node, and an IPFS node wired correctly together to start using the Testnet!","title":"Setup"},{"location":"powergate/testnet/#create-a-deal-and-store-a-file","text":"Now that your Powergate is running on testnet, all the CLI and API commands are the same as if you had run it on localnet before.","title":"Create a deal and store a file"},{"location":"powergate/testnet/#install-the-cli","text":"From the root of the powergate repo, you can build the CLI from the latest code. This will install the Powergate CLI, pow , on your machine. make build Test your installation. pow --help","title":"Install the CLI"},{"location":"powergate/testnet/#start-storing-data","text":"You are now ready to start storing and retrieving data using the Powergate. Read more on Storing Data with the FFS .","title":"Start storing data"},{"location":"powergate/cli/pow/","text":"pow \u00b6 A client for storage and retreival of powergate data Synopsis \u00b6 A client for storage and retreival of powergate data Options \u00b6 -h, --help help for pow --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow asks - Provides commands to view asks data pow faults - Provides commands to view faults data pow ffs - Provides commands to manage ffs pow health - Display the node health status pow miners - Provides commands to view miners data pow net - Provides commands related to peers and network pow reputation - Provides commands to view miner reputation data pow server-info - Display information about the connected server pow wallet - Provides commands about filecoin wallets","title":"Overview"},{"location":"powergate/cli/pow/#pow","text":"A client for storage and retreival of powergate data","title":"pow"},{"location":"powergate/cli/pow/#synopsis","text":"A client for storage and retreival of powergate data","title":"Synopsis"},{"location":"powergate/cli/pow/#options","text":"-h, --help help for pow --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options"},{"location":"powergate/cli/pow/#see-also","text":"pow asks - Provides commands to view asks data pow faults - Provides commands to view faults data pow ffs - Provides commands to manage ffs pow health - Display the node health status pow miners - Provides commands to view miners data pow net - Provides commands related to peers and network pow reputation - Provides commands to view miner reputation data pow server-info - Display information about the connected server pow wallet - Provides commands about filecoin wallets","title":"SEE ALSO"},{"location":"powergate/cli/pow_asks/","text":"pow asks \u00b6 Provides commands to view asks data Synopsis \u00b6 Provides commands to view asks data Options \u00b6 -h, --help help for asks Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data pow asks get - Get the asks index pow asks query - Query the available asks","title":"Asks"},{"location":"powergate/cli/pow_asks/#pow-asks","text":"Provides commands to view asks data","title":"pow asks"},{"location":"powergate/cli/pow_asks/#synopsis","text":"Provides commands to view asks data","title":"Synopsis"},{"location":"powergate/cli/pow_asks/#options","text":"-h, --help help for asks","title":"Options"},{"location":"powergate/cli/pow_asks/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_asks/#see-also","text":"pow - A client for storage and retreival of powergate data pow asks get - Get the asks index pow asks query - Query the available asks","title":"SEE ALSO"},{"location":"powergate/cli/pow_asks_get/","text":"pow asks get \u00b6 Get the asks index Synopsis \u00b6 Get the asks index pow asks get [flags] Options \u00b6 -h, --help help for get Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow asks - Provides commands to view asks data","title":"Pow asks get"},{"location":"powergate/cli/pow_asks_get/#pow-asks-get","text":"Get the asks index","title":"pow asks get"},{"location":"powergate/cli/pow_asks_get/#synopsis","text":"Get the asks index pow asks get [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_asks_get/#options","text":"-h, --help help for get","title":"Options"},{"location":"powergate/cli/pow_asks_get/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_asks_get/#see-also","text":"pow asks - Provides commands to view asks data","title":"SEE ALSO"},{"location":"powergate/cli/pow_asks_query/","text":"pow asks query \u00b6 Query the available asks Synopsis \u00b6 Query the available asks pow asks query [flags] Options \u00b6 -h, --help help for query -l, --limit int limit the number of results (default -1) -m, --maxPrice uint max price of the asks to query -o, --offset int offset of results (default -1) -p, --pieceSize int piece size of the asks to query Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow asks - Provides commands to view asks data","title":"Pow asks query"},{"location":"powergate/cli/pow_asks_query/#pow-asks-query","text":"Query the available asks","title":"pow asks query"},{"location":"powergate/cli/pow_asks_query/#synopsis","text":"Query the available asks pow asks query [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_asks_query/#options","text":"-h, --help help for query -l, --limit int limit the number of results (default -1) -m, --maxPrice uint max price of the asks to query -o, --offset int offset of results (default -1) -p, --pieceSize int piece size of the asks to query","title":"Options"},{"location":"powergate/cli/pow_asks_query/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_asks_query/#see-also","text":"pow asks - Provides commands to view asks data","title":"SEE ALSO"},{"location":"powergate/cli/pow_faults/","text":"pow faults \u00b6 Provides commands to view faults data Synopsis \u00b6 Provides commands to view faults data Options \u00b6 -h, --help help for faults Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data pow faults get - Get the faults index","title":"Faults"},{"location":"powergate/cli/pow_faults/#pow-faults","text":"Provides commands to view faults data","title":"pow faults"},{"location":"powergate/cli/pow_faults/#synopsis","text":"Provides commands to view faults data","title":"Synopsis"},{"location":"powergate/cli/pow_faults/#options","text":"-h, --help help for faults","title":"Options"},{"location":"powergate/cli/pow_faults/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_faults/#see-also","text":"pow - A client for storage and retreival of powergate data pow faults get - Get the faults index","title":"SEE ALSO"},{"location":"powergate/cli/pow_faults_get/","text":"pow faults get \u00b6 Get the faults index Synopsis \u00b6 Get the faults index pow faults get [flags] Options \u00b6 -h, --help help for get Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow faults - Provides commands to view faults data","title":"Pow faults get"},{"location":"powergate/cli/pow_faults_get/#pow-faults-get","text":"Get the faults index","title":"pow faults get"},{"location":"powergate/cli/pow_faults_get/#synopsis","text":"Get the faults index pow faults get [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_faults_get/#options","text":"-h, --help help for get","title":"Options"},{"location":"powergate/cli/pow_faults_get/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_faults_get/#see-also","text":"pow faults - Provides commands to view faults data","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs/","text":"pow ffs \u00b6 Provides commands to manage ffs Synopsis \u00b6 Provides commands to manage ffs Options \u00b6 -h, --help help for ffs Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data pow ffs addrs - Provides commands to manage wallet addresses pow ffs cancel - Cancel an executing job pow ffs config - Provides commands to manage storage configuration pow ffs create - Create ffs instance pow ffs get - Get data by cid from ffs pow ffs id - Returns the FFS instance id pow ffs info - Get info from ffs instance pow ffs log - Display logs for specified cid pow ffs paych - Provides commands to manage payment channels pow ffs remove - Removes a Cid from being tracked as an active storage pow ffs replace - Pushes a StorageConfig for c2 equal to that of c1, and removes c1 pow ffs retrievals - List retrieval deal records for an FFS instance pow ffs send - Send fil from one managed address to any other address pow ffs show - Show pinned cid data pow ffs stage - Temporarily stage data in the Hot layer in preparation for pushing a cid storage config pow ffs storage - List storage deal records for an FFS instance pow ffs watch - Watch for job status updates","title":"FFS"},{"location":"powergate/cli/pow_ffs/#pow-ffs","text":"Provides commands to manage ffs","title":"pow ffs"},{"location":"powergate/cli/pow_ffs/#synopsis","text":"Provides commands to manage ffs","title":"Synopsis"},{"location":"powergate/cli/pow_ffs/#options","text":"-h, --help help for ffs","title":"Options"},{"location":"powergate/cli/pow_ffs/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs/#see-also","text":"pow - A client for storage and retreival of powergate data pow ffs addrs - Provides commands to manage wallet addresses pow ffs cancel - Cancel an executing job pow ffs config - Provides commands to manage storage configuration pow ffs create - Create ffs instance pow ffs get - Get data by cid from ffs pow ffs id - Returns the FFS instance id pow ffs info - Get info from ffs instance pow ffs log - Display logs for specified cid pow ffs paych - Provides commands to manage payment channels pow ffs remove - Removes a Cid from being tracked as an active storage pow ffs replace - Pushes a StorageConfig for c2 equal to that of c1, and removes c1 pow ffs retrievals - List retrieval deal records for an FFS instance pow ffs send - Send fil from one managed address to any other address pow ffs show - Show pinned cid data pow ffs stage - Temporarily stage data in the Hot layer in preparation for pushing a cid storage config pow ffs storage - List storage deal records for an FFS instance pow ffs watch - Watch for job status updates","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_addrs/","text":"pow ffs addrs \u00b6 Provides commands to manage wallet addresses Synopsis \u00b6 Provides commands to manage wallet addresses Options \u00b6 -h, --help help for addrs Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs pow ffs addrs list - List the wallet adresses for the ffs instance pow ffs addrs new - Create a new wallet address","title":"Pow ffs addrs"},{"location":"powergate/cli/pow_ffs_addrs/#pow-ffs-addrs","text":"Provides commands to manage wallet addresses","title":"pow ffs addrs"},{"location":"powergate/cli/pow_ffs_addrs/#synopsis","text":"Provides commands to manage wallet addresses","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_addrs/#options","text":"-h, --help help for addrs","title":"Options"},{"location":"powergate/cli/pow_ffs_addrs/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_addrs/#see-also","text":"pow ffs - Provides commands to manage ffs pow ffs addrs list - List the wallet adresses for the ffs instance pow ffs addrs new - Create a new wallet address","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_addrs_list/","text":"pow ffs addrs list \u00b6 List the wallet adresses for the ffs instance Synopsis \u00b6 List the wallet adresses for the ffs instance pow ffs addrs list [flags] Options \u00b6 -h, --help help for list -t, --token string token of the request Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs addrs - Provides commands to manage wallet addresses","title":"Pow ffs addrs list"},{"location":"powergate/cli/pow_ffs_addrs_list/#pow-ffs-addrs-list","text":"List the wallet adresses for the ffs instance","title":"pow ffs addrs list"},{"location":"powergate/cli/pow_ffs_addrs_list/#synopsis","text":"List the wallet adresses for the ffs instance pow ffs addrs list [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_addrs_list/#options","text":"-h, --help help for list -t, --token string token of the request","title":"Options"},{"location":"powergate/cli/pow_ffs_addrs_list/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_addrs_list/#see-also","text":"pow ffs addrs - Provides commands to manage wallet addresses","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_addrs_new/","text":"pow ffs addrs new \u00b6 Create a new wallet address Synopsis \u00b6 Create a new wallet address pow ffs addrs new [name] [flags] Options \u00b6 -d, --default Make the new address the ffs default -f, --format string Optionally specify address format bls or secp256k1 -h, --help help for new -t, --token string FFS auth token Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs addrs - Provides commands to manage wallet addresses","title":"Pow ffs addrs new"},{"location":"powergate/cli/pow_ffs_addrs_new/#pow-ffs-addrs-new","text":"Create a new wallet address","title":"pow ffs addrs new"},{"location":"powergate/cli/pow_ffs_addrs_new/#synopsis","text":"Create a new wallet address pow ffs addrs new [name] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_addrs_new/#options","text":"-d, --default Make the new address the ffs default -f, --format string Optionally specify address format bls or secp256k1 -h, --help help for new -t, --token string FFS auth token","title":"Options"},{"location":"powergate/cli/pow_ffs_addrs_new/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_addrs_new/#see-also","text":"pow ffs addrs - Provides commands to manage wallet addresses","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_cancel/","text":"pow ffs cancel \u00b6 Cancel an executing job Synopsis \u00b6 Cancel an executing job pow ffs cancel [jobid] [flags] Options \u00b6 -h, --help help for cancel -t, --token string FFS auth token Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs","title":"Pow ffs cancel"},{"location":"powergate/cli/pow_ffs_cancel/#pow-ffs-cancel","text":"Cancel an executing job","title":"pow ffs cancel"},{"location":"powergate/cli/pow_ffs_cancel/#synopsis","text":"Cancel an executing job pow ffs cancel [jobid] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_cancel/#options","text":"-h, --help help for cancel -t, --token string FFS auth token","title":"Options"},{"location":"powergate/cli/pow_ffs_cancel/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_cancel/#see-also","text":"pow ffs - Provides commands to manage ffs","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_config/","text":"pow ffs config \u00b6 Provides commands to manage storage configuration Synopsis \u00b6 Provides commands to manage storage configuration Options \u00b6 -h, --help help for config Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs pow ffs config default - Returns the default storage config pow ffs config get - Fetches the storage config for the provided cid pow ffs config push - Add data to FFS via cid pow ffs config set-default - Sets the default cid storage config from stdin or a file","title":"Pow ffs config"},{"location":"powergate/cli/pow_ffs_config/#pow-ffs-config","text":"Provides commands to manage storage configuration","title":"pow ffs config"},{"location":"powergate/cli/pow_ffs_config/#synopsis","text":"Provides commands to manage storage configuration","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_config/#options","text":"-h, --help help for config","title":"Options"},{"location":"powergate/cli/pow_ffs_config/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_config/#see-also","text":"pow ffs - Provides commands to manage ffs pow ffs config default - Returns the default storage config pow ffs config get - Fetches the storage config for the provided cid pow ffs config push - Add data to FFS via cid pow ffs config set-default - Sets the default cid storage config from stdin or a file","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_config_default/","text":"pow ffs config default \u00b6 Returns the default storage config Synopsis \u00b6 Returns the default storage config pow ffs config default [flags] Options \u00b6 -h, --help help for default -t, --token string FFS auth token Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs config - Provides commands to manage storage configuration","title":"Pow ffs config default"},{"location":"powergate/cli/pow_ffs_config_default/#pow-ffs-config-default","text":"Returns the default storage config","title":"pow ffs config default"},{"location":"powergate/cli/pow_ffs_config_default/#synopsis","text":"Returns the default storage config pow ffs config default [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_config_default/#options","text":"-h, --help help for default -t, --token string FFS auth token","title":"Options"},{"location":"powergate/cli/pow_ffs_config_default/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_config_default/#see-also","text":"pow ffs config - Provides commands to manage storage configuration","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_config_get/","text":"pow ffs config get \u00b6 Fetches the storage config for the provided cid Synopsis \u00b6 Fetches the storage config for the provided cid pow ffs config get [cid] [flags] Options \u00b6 -h, --help help for get -t, --token string FFS auth token Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs config - Provides commands to manage storage configuration","title":"Pow ffs config get"},{"location":"powergate/cli/pow_ffs_config_get/#pow-ffs-config-get","text":"Fetches the storage config for the provided cid","title":"pow ffs config get"},{"location":"powergate/cli/pow_ffs_config_get/#synopsis","text":"Fetches the storage config for the provided cid pow ffs config get [cid] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_config_get/#options","text":"-h, --help help for get -t, --token string FFS auth token","title":"Options"},{"location":"powergate/cli/pow_ffs_config_get/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_config_get/#see-also","text":"pow ffs config - Provides commands to manage storage configuration","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_config_push/","text":"pow ffs config push \u00b6 Add data to FFS via cid Synopsis \u00b6 Add data to FFS via a cid already in IPFS pow ffs config push [cid] [flags] Options \u00b6 -c, --conf string Optional path to a file containing storage config json, falls back to stdin, uses FFS default by default -h, --help help for push -o, --override If set, override any pre-existing storage configuration for the cid -t, --token string FFS access token -w, --watch Watch the progress of the resulting job Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs config - Provides commands to manage storage configuration","title":"Pow ffs config push"},{"location":"powergate/cli/pow_ffs_config_push/#pow-ffs-config-push","text":"Add data to FFS via cid","title":"pow ffs config push"},{"location":"powergate/cli/pow_ffs_config_push/#synopsis","text":"Add data to FFS via a cid already in IPFS pow ffs config push [cid] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_config_push/#options","text":"-c, --conf string Optional path to a file containing storage config json, falls back to stdin, uses FFS default by default -h, --help help for push -o, --override If set, override any pre-existing storage configuration for the cid -t, --token string FFS access token -w, --watch Watch the progress of the resulting job","title":"Options"},{"location":"powergate/cli/pow_ffs_config_push/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_config_push/#see-also","text":"pow ffs config - Provides commands to manage storage configuration","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_config_set-default/","text":"pow ffs config set-default \u00b6 Sets the default cid storage config from stdin or a file Synopsis \u00b6 Sets the default cid storage config from stdin or a file pow ffs config set-default [(optional)file] [flags] Options \u00b6 -h, --help help for set-default -t, --token string FFS auth token Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs config - Provides commands to manage storage configuration","title":"Pow ffs config set default"},{"location":"powergate/cli/pow_ffs_config_set-default/#pow-ffs-config-set-default","text":"Sets the default cid storage config from stdin or a file","title":"pow ffs config set-default"},{"location":"powergate/cli/pow_ffs_config_set-default/#synopsis","text":"Sets the default cid storage config from stdin or a file pow ffs config set-default [(optional)file] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_config_set-default/#options","text":"-h, --help help for set-default -t, --token string FFS auth token","title":"Options"},{"location":"powergate/cli/pow_ffs_config_set-default/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_config_set-default/#see-also","text":"pow ffs config - Provides commands to manage storage configuration","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_create/","text":"pow ffs create \u00b6 Create ffs instance Synopsis \u00b6 Create ffs instance pow ffs create [flags] Options \u00b6 -h, --help help for create Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs","title":"Pow ffs create"},{"location":"powergate/cli/pow_ffs_create/#pow-ffs-create","text":"Create ffs instance","title":"pow ffs create"},{"location":"powergate/cli/pow_ffs_create/#synopsis","text":"Create ffs instance pow ffs create [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_create/#options","text":"-h, --help help for create","title":"Options"},{"location":"powergate/cli/pow_ffs_create/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_create/#see-also","text":"pow ffs - Provides commands to manage ffs","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_get/","text":"pow ffs get \u00b6 Get data by cid from ffs Synopsis \u00b6 Get data by cid from ffs pow ffs get [cid] [output file path] [flags] Options \u00b6 -f, --folder Indicates that the retrieved Cid is a folder -h, --help help for get --ipfsrevproxy string Powergate IPFS reverse proxy multiaddr (default \"127.0.0.1:6002\") -t, --token string token of the request Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs","title":"Pow ffs get"},{"location":"powergate/cli/pow_ffs_get/#pow-ffs-get","text":"Get data by cid from ffs","title":"pow ffs get"},{"location":"powergate/cli/pow_ffs_get/#synopsis","text":"Get data by cid from ffs pow ffs get [cid] [output file path] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_get/#options","text":"-f, --folder Indicates that the retrieved Cid is a folder -h, --help help for get --ipfsrevproxy string Powergate IPFS reverse proxy multiaddr (default \"127.0.0.1:6002\") -t, --token string token of the request","title":"Options"},{"location":"powergate/cli/pow_ffs_get/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_get/#see-also","text":"pow ffs - Provides commands to manage ffs","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_id/","text":"pow ffs id \u00b6 Returns the FFS instance id Synopsis \u00b6 Returns the FFS instance id pow ffs id [flags] Options \u00b6 -h, --help help for id -t, --token string FFS auth token Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs","title":"Pow ffs id"},{"location":"powergate/cli/pow_ffs_id/#pow-ffs-id","text":"Returns the FFS instance id","title":"pow ffs id"},{"location":"powergate/cli/pow_ffs_id/#synopsis","text":"Returns the FFS instance id pow ffs id [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_id/#options","text":"-h, --help help for id -t, --token string FFS auth token","title":"Options"},{"location":"powergate/cli/pow_ffs_id/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_id/#see-also","text":"pow ffs - Provides commands to manage ffs","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_info/","text":"pow ffs info \u00b6 Get info from ffs instance Synopsis \u00b6 Get info from ffs instance pow ffs info [flags] Options \u00b6 -h, --help help for info -t, --token string token of the request Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs","title":"Pow ffs info"},{"location":"powergate/cli/pow_ffs_info/#pow-ffs-info","text":"Get info from ffs instance","title":"pow ffs info"},{"location":"powergate/cli/pow_ffs_info/#synopsis","text":"Get info from ffs instance pow ffs info [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_info/#options","text":"-h, --help help for info -t, --token string token of the request","title":"Options"},{"location":"powergate/cli/pow_ffs_info/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_info/#see-also","text":"pow ffs - Provides commands to manage ffs","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_log/","text":"pow ffs log \u00b6 Display logs for specified cid Synopsis \u00b6 Display logs for specified cid pow ffs log [cid] [flags] Options \u00b6 -h, --help help for log -j, --jid string Display information for only this job id -t, --token string FFS auth token Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs","title":"Pow ffs log"},{"location":"powergate/cli/pow_ffs_log/#pow-ffs-log","text":"Display logs for specified cid","title":"pow ffs log"},{"location":"powergate/cli/pow_ffs_log/#synopsis","text":"Display logs for specified cid pow ffs log [cid] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_log/#options","text":"-h, --help help for log -j, --jid string Display information for only this job id -t, --token string FFS auth token","title":"Options"},{"location":"powergate/cli/pow_ffs_log/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_log/#see-also","text":"pow ffs - Provides commands to manage ffs","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_paych/","text":"pow ffs paych \u00b6 Provides commands to manage payment channels Synopsis \u00b6 Provides commands to manage payment channels Options \u00b6 -h, --help help for paych Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs pow ffs paych create - Create a payment channel pow ffs paych list - List the payment channels for the ffs instance pow ffs paych redeem - Redeem a payment channel","title":"Pow ffs paych"},{"location":"powergate/cli/pow_ffs_paych/#pow-ffs-paych","text":"Provides commands to manage payment channels","title":"pow ffs paych"},{"location":"powergate/cli/pow_ffs_paych/#synopsis","text":"Provides commands to manage payment channels","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_paych/#options","text":"-h, --help help for paych","title":"Options"},{"location":"powergate/cli/pow_ffs_paych/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_paych/#see-also","text":"pow ffs - Provides commands to manage ffs pow ffs paych create - Create a payment channel pow ffs paych list - List the payment channels for the ffs instance pow ffs paych redeem - Redeem a payment channel","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_paych_create/","text":"pow ffs paych create \u00b6 Create a payment channel Synopsis \u00b6 Create a payment channel pow ffs paych create [from] [to] [amount] [flags] Options \u00b6 -h, --help help for create -t, --token string token of the request Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs paych - Provides commands to manage payment channels","title":"Pow ffs paych create"},{"location":"powergate/cli/pow_ffs_paych_create/#pow-ffs-paych-create","text":"Create a payment channel","title":"pow ffs paych create"},{"location":"powergate/cli/pow_ffs_paych_create/#synopsis","text":"Create a payment channel pow ffs paych create [from] [to] [amount] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_paych_create/#options","text":"-h, --help help for create -t, --token string token of the request","title":"Options"},{"location":"powergate/cli/pow_ffs_paych_create/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_paych_create/#see-also","text":"pow ffs paych - Provides commands to manage payment channels","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_paych_list/","text":"pow ffs paych list \u00b6 List the payment channels for the ffs instance Synopsis \u00b6 List the payment channels for the ffs instance pow ffs paych list [flags] Options \u00b6 -h, --help help for list -t, --token string token of the request Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs paych - Provides commands to manage payment channels","title":"Pow ffs paych list"},{"location":"powergate/cli/pow_ffs_paych_list/#pow-ffs-paych-list","text":"List the payment channels for the ffs instance","title":"pow ffs paych list"},{"location":"powergate/cli/pow_ffs_paych_list/#synopsis","text":"List the payment channels for the ffs instance pow ffs paych list [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_paych_list/#options","text":"-h, --help help for list -t, --token string token of the request","title":"Options"},{"location":"powergate/cli/pow_ffs_paych_list/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_paych_list/#see-also","text":"pow ffs paych - Provides commands to manage payment channels","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_paych_redeem/","text":"pow ffs paych redeem \u00b6 Redeem a payment channel Synopsis \u00b6 Redeem a payment channel pow ffs paych redeem [from] [to] [amount] [flags] Options \u00b6 -h, --help help for redeem -t, --token string token of the request Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs paych - Provides commands to manage payment channels","title":"Pow ffs paych redeem"},{"location":"powergate/cli/pow_ffs_paych_redeem/#pow-ffs-paych-redeem","text":"Redeem a payment channel","title":"pow ffs paych redeem"},{"location":"powergate/cli/pow_ffs_paych_redeem/#synopsis","text":"Redeem a payment channel pow ffs paych redeem [from] [to] [amount] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_paych_redeem/#options","text":"-h, --help help for redeem -t, --token string token of the request","title":"Options"},{"location":"powergate/cli/pow_ffs_paych_redeem/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_paych_redeem/#see-also","text":"pow ffs paych - Provides commands to manage payment channels","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_remove/","text":"pow ffs remove \u00b6 Removes a Cid from being tracked as an active storage Synopsis \u00b6 Removes a Cid from being tracked as an active storage. The Cid should have both Hot and Cold storage disabled, if that isn't the case it will return ErrActiveInStorage pow ffs remove [cid] [flags] Options \u00b6 -h, --help help for remove -t, --token string FFS access token Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs","title":"Pow ffs remove"},{"location":"powergate/cli/pow_ffs_remove/#pow-ffs-remove","text":"Removes a Cid from being tracked as an active storage","title":"pow ffs remove"},{"location":"powergate/cli/pow_ffs_remove/#synopsis","text":"Removes a Cid from being tracked as an active storage. The Cid should have both Hot and Cold storage disabled, if that isn't the case it will return ErrActiveInStorage pow ffs remove [cid] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_remove/#options","text":"-h, --help help for remove -t, --token string FFS access token","title":"Options"},{"location":"powergate/cli/pow_ffs_remove/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_remove/#see-also","text":"pow ffs - Provides commands to manage ffs","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_replace/","text":"pow ffs replace \u00b6 Pushes a StorageConfig for c2 equal to that of c1, and removes c1 Synopsis \u00b6 Pushes a StorageConfig for c2 equal to that of c1, and removes c1. This operation is more efficient than manually removing and adding in two separate operations pow ffs replace [cid1] [cid2] [flags] Options \u00b6 -h, --help help for replace -t, --token string FFS access token -w, --watch Watch the progress of the resulting job Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs","title":"Pow ffs replace"},{"location":"powergate/cli/pow_ffs_replace/#pow-ffs-replace","text":"Pushes a StorageConfig for c2 equal to that of c1, and removes c1","title":"pow ffs replace"},{"location":"powergate/cli/pow_ffs_replace/#synopsis","text":"Pushes a StorageConfig for c2 equal to that of c1, and removes c1. This operation is more efficient than manually removing and adding in two separate operations pow ffs replace [cid1] [cid2] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_replace/#options","text":"-h, --help help for replace -t, --token string FFS access token -w, --watch Watch the progress of the resulting job","title":"Options"},{"location":"powergate/cli/pow_ffs_replace/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_replace/#see-also","text":"pow ffs - Provides commands to manage ffs","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_retrievals/","text":"pow ffs retrievals \u00b6 List retrieval deal records for an FFS instance Synopsis \u00b6 List retrieval deal records for an FFS instance pow ffs retrievals [flags] Options \u00b6 --addrs strings limit the records to deals initiated from the specified wallet addresses -a, --ascending sort records ascending, default is descending --cids strings limit the records to deals for the specified data cids -h, --help help for retrievals -t, --token string token of the request Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs","title":"Pow ffs retrievals"},{"location":"powergate/cli/pow_ffs_retrievals/#pow-ffs-retrievals","text":"List retrieval deal records for an FFS instance","title":"pow ffs retrievals"},{"location":"powergate/cli/pow_ffs_retrievals/#synopsis","text":"List retrieval deal records for an FFS instance pow ffs retrievals [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_retrievals/#options","text":"--addrs strings limit the records to deals initiated from the specified wallet addresses -a, --ascending sort records ascending, default is descending --cids strings limit the records to deals for the specified data cids -h, --help help for retrievals -t, --token string token of the request","title":"Options"},{"location":"powergate/cli/pow_ffs_retrievals/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_retrievals/#see-also","text":"pow ffs - Provides commands to manage ffs","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_send/","text":"pow ffs send \u00b6 Send fil from one managed address to any other address Synopsis \u00b6 Send fil from one managed address to any other address pow ffs send [from address] [to address] [amount] [flags] Options \u00b6 -h, --help help for send -t, --token string FFS auth token Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs","title":"Pow ffs send"},{"location":"powergate/cli/pow_ffs_send/#pow-ffs-send","text":"Send fil from one managed address to any other address","title":"pow ffs send"},{"location":"powergate/cli/pow_ffs_send/#synopsis","text":"Send fil from one managed address to any other address pow ffs send [from address] [to address] [amount] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_send/#options","text":"-h, --help help for send -t, --token string FFS auth token","title":"Options"},{"location":"powergate/cli/pow_ffs_send/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_send/#see-also","text":"pow ffs - Provides commands to manage ffs","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_show/","text":"pow ffs show \u00b6 Show pinned cid data Synopsis \u00b6 Show pinned cid data pow ffs show [cid] [flags] Options \u00b6 -h, --help help for show -t, --token string FFS auth token Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs","title":"Pow ffs show"},{"location":"powergate/cli/pow_ffs_show/#pow-ffs-show","text":"Show pinned cid data","title":"pow ffs show"},{"location":"powergate/cli/pow_ffs_show/#synopsis","text":"Show pinned cid data pow ffs show [cid] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_show/#options","text":"-h, --help help for show -t, --token string FFS auth token","title":"Options"},{"location":"powergate/cli/pow_ffs_show/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_show/#see-also","text":"pow ffs - Provides commands to manage ffs","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_stage/","text":"pow ffs stage \u00b6 Temporarily stage data in the Hot layer in preparation for pushing a cid storage config Synopsis \u00b6 Temporarily stage data in the Hot layer in preparation for pushing a cid storage config pow ffs stage [path] [flags] Options \u00b6 -h, --help help for stage --ipfsrevproxy string Powergate IPFS reverse proxy multiaddr (default \"127.0.0.1:6002\") -t, --token string FFS access token Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs","title":"Pow ffs stage"},{"location":"powergate/cli/pow_ffs_stage/#pow-ffs-stage","text":"Temporarily stage data in the Hot layer in preparation for pushing a cid storage config","title":"pow ffs stage"},{"location":"powergate/cli/pow_ffs_stage/#synopsis","text":"Temporarily stage data in the Hot layer in preparation for pushing a cid storage config pow ffs stage [path] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_stage/#options","text":"-h, --help help for stage --ipfsrevproxy string Powergate IPFS reverse proxy multiaddr (default \"127.0.0.1:6002\") -t, --token string FFS access token","title":"Options"},{"location":"powergate/cli/pow_ffs_stage/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_stage/#see-also","text":"pow ffs - Provides commands to manage ffs","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_storage/","text":"pow ffs storage \u00b6 List storage deal records for an FFS instance Synopsis \u00b6 List storage deal records for an FFS instance pow ffs storage [flags] Options \u00b6 --addrs strings limit the records to deals initiated from the specified wallet addresses, treated as and AND operation if --cids is also provided -a, --ascending sort records ascending, default is sort descending --cids strings limit the records to deals for the specified data cids, treated as and AND operation if --addrs is also provided -h, --help help for storage -f, --include-final include final deals -p, --include-pending include pending deals -t, --token string token of the request Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs","title":"Pow ffs storage"},{"location":"powergate/cli/pow_ffs_storage/#pow-ffs-storage","text":"List storage deal records for an FFS instance","title":"pow ffs storage"},{"location":"powergate/cli/pow_ffs_storage/#synopsis","text":"List storage deal records for an FFS instance pow ffs storage [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_storage/#options","text":"--addrs strings limit the records to deals initiated from the specified wallet addresses, treated as and AND operation if --cids is also provided -a, --ascending sort records ascending, default is sort descending --cids strings limit the records to deals for the specified data cids, treated as and AND operation if --addrs is also provided -h, --help help for storage -f, --include-final include final deals -p, --include-pending include pending deals -t, --token string token of the request","title":"Options"},{"location":"powergate/cli/pow_ffs_storage/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_storage/#see-also","text":"pow ffs - Provides commands to manage ffs","title":"SEE ALSO"},{"location":"powergate/cli/pow_ffs_watch/","text":"pow ffs watch \u00b6 Watch for job status updates Synopsis \u00b6 Watch for job status updates pow ffs watch [jobid,...] [flags] Options \u00b6 -h, --help help for watch -t, --token string FFS auth token Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow ffs - Provides commands to manage ffs","title":"Pow ffs watch"},{"location":"powergate/cli/pow_ffs_watch/#pow-ffs-watch","text":"Watch for job status updates","title":"pow ffs watch"},{"location":"powergate/cli/pow_ffs_watch/#synopsis","text":"Watch for job status updates pow ffs watch [jobid,...] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_ffs_watch/#options","text":"-h, --help help for watch -t, --token string FFS auth token","title":"Options"},{"location":"powergate/cli/pow_ffs_watch/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_ffs_watch/#see-also","text":"pow ffs - Provides commands to manage ffs","title":"SEE ALSO"},{"location":"powergate/cli/pow_health/","text":"pow health \u00b6 Display the node health status Synopsis \u00b6 Display the node health status pow health [flags] Options \u00b6 -h, --help help for health Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data","title":"Health"},{"location":"powergate/cli/pow_health/#pow-health","text":"Display the node health status","title":"pow health"},{"location":"powergate/cli/pow_health/#synopsis","text":"Display the node health status pow health [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_health/#options","text":"-h, --help help for health","title":"Options"},{"location":"powergate/cli/pow_health/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_health/#see-also","text":"pow - A client for storage and retreival of powergate data","title":"SEE ALSO"},{"location":"powergate/cli/pow_miners/","text":"pow miners \u00b6 Provides commands to view miners data Synopsis \u00b6 Provides commands to view miners data Options \u00b6 -h, --help help for miners Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data pow miners get - Get the miners index","title":"Miners"},{"location":"powergate/cli/pow_miners/#pow-miners","text":"Provides commands to view miners data","title":"pow miners"},{"location":"powergate/cli/pow_miners/#synopsis","text":"Provides commands to view miners data","title":"Synopsis"},{"location":"powergate/cli/pow_miners/#options","text":"-h, --help help for miners","title":"Options"},{"location":"powergate/cli/pow_miners/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_miners/#see-also","text":"pow - A client for storage and retreival of powergate data pow miners get - Get the miners index","title":"SEE ALSO"},{"location":"powergate/cli/pow_miners_get/","text":"pow miners get \u00b6 Get the miners index Synopsis \u00b6 Get the miners index pow miners get [flags] Options \u00b6 -h, --help help for get Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow miners - Provides commands to view miners data","title":"Pow miners get"},{"location":"powergate/cli/pow_miners_get/#pow-miners-get","text":"Get the miners index","title":"pow miners get"},{"location":"powergate/cli/pow_miners_get/#synopsis","text":"Get the miners index pow miners get [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_miners_get/#options","text":"-h, --help help for get","title":"Options"},{"location":"powergate/cli/pow_miners_get/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_miners_get/#see-also","text":"pow miners - Provides commands to view miners data","title":"SEE ALSO"},{"location":"powergate/cli/pow_net/","text":"pow net \u00b6 Provides commands related to peers and network Synopsis \u00b6 Provides commands related to peers and network Options \u00b6 -h, --help help for net Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data pow net addr - Get the listen address of the node pow net connect - Connect to a specified peer pow net connectedness - Check connectedness to a specified peer pow net disconnect - Disconnect from specified peer pow net find - Find a peer by peer id pow net peers - Get the node peers","title":"Net"},{"location":"powergate/cli/pow_net/#pow-net","text":"Provides commands related to peers and network","title":"pow net"},{"location":"powergate/cli/pow_net/#synopsis","text":"Provides commands related to peers and network","title":"Synopsis"},{"location":"powergate/cli/pow_net/#options","text":"-h, --help help for net","title":"Options"},{"location":"powergate/cli/pow_net/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_net/#see-also","text":"pow - A client for storage and retreival of powergate data pow net addr - Get the listen address of the node pow net connect - Connect to a specified peer pow net connectedness - Check connectedness to a specified peer pow net disconnect - Disconnect from specified peer pow net find - Find a peer by peer id pow net peers - Get the node peers","title":"SEE ALSO"},{"location":"powergate/cli/pow_net_addr/","text":"pow net addr \u00b6 Get the listen address of the node Synopsis \u00b6 Get the listen address of the node pow net addr [flags] Options \u00b6 -h, --help help for addr Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow net - Provides commands related to peers and network","title":"Pow net addr"},{"location":"powergate/cli/pow_net_addr/#pow-net-addr","text":"Get the listen address of the node","title":"pow net addr"},{"location":"powergate/cli/pow_net_addr/#synopsis","text":"Get the listen address of the node pow net addr [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_net_addr/#options","text":"-h, --help help for addr","title":"Options"},{"location":"powergate/cli/pow_net_addr/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_net_addr/#see-also","text":"pow net - Provides commands related to peers and network","title":"SEE ALSO"},{"location":"powergate/cli/pow_net_connect/","text":"pow net connect \u00b6 Connect to a specified peer Synopsis \u00b6 Connect to a specified peer pow net connect [peerID] [optional address] [flags] Options \u00b6 -h, --help help for connect Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow net - Provides commands related to peers and network","title":"Pow net connect"},{"location":"powergate/cli/pow_net_connect/#pow-net-connect","text":"Connect to a specified peer","title":"pow net connect"},{"location":"powergate/cli/pow_net_connect/#synopsis","text":"Connect to a specified peer pow net connect [peerID] [optional address] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_net_connect/#options","text":"-h, --help help for connect","title":"Options"},{"location":"powergate/cli/pow_net_connect/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_net_connect/#see-also","text":"pow net - Provides commands related to peers and network","title":"SEE ALSO"},{"location":"powergate/cli/pow_net_connectedness/","text":"pow net connectedness \u00b6 Check connectedness to a specified peer Synopsis \u00b6 Check connectedness to a specified peer pow net connectedness [peerID] [flags] Options \u00b6 -h, --help help for connectedness Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow net - Provides commands related to peers and network","title":"Pow net connectedness"},{"location":"powergate/cli/pow_net_connectedness/#pow-net-connectedness","text":"Check connectedness to a specified peer","title":"pow net connectedness"},{"location":"powergate/cli/pow_net_connectedness/#synopsis","text":"Check connectedness to a specified peer pow net connectedness [peerID] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_net_connectedness/#options","text":"-h, --help help for connectedness","title":"Options"},{"location":"powergate/cli/pow_net_connectedness/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_net_connectedness/#see-also","text":"pow net - Provides commands related to peers and network","title":"SEE ALSO"},{"location":"powergate/cli/pow_net_disconnect/","text":"pow net disconnect \u00b6 Disconnect from specified peer Synopsis \u00b6 Disconnect from specified peer pow net disconnect [peerID] [address] [flags] Options \u00b6 -h, --help help for disconnect Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow net - Provides commands related to peers and network","title":"Pow net disconnect"},{"location":"powergate/cli/pow_net_disconnect/#pow-net-disconnect","text":"Disconnect from specified peer","title":"pow net disconnect"},{"location":"powergate/cli/pow_net_disconnect/#synopsis","text":"Disconnect from specified peer pow net disconnect [peerID] [address] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_net_disconnect/#options","text":"-h, --help help for disconnect","title":"Options"},{"location":"powergate/cli/pow_net_disconnect/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_net_disconnect/#see-also","text":"pow net - Provides commands related to peers and network","title":"SEE ALSO"},{"location":"powergate/cli/pow_net_find/","text":"pow net find \u00b6 Find a peer by peer id Synopsis \u00b6 Find a peer by peer id pow net find [peerID] [flags] Options \u00b6 -h, --help help for find Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow net - Provides commands related to peers and network","title":"Pow net find"},{"location":"powergate/cli/pow_net_find/#pow-net-find","text":"Find a peer by peer id","title":"pow net find"},{"location":"powergate/cli/pow_net_find/#synopsis","text":"Find a peer by peer id pow net find [peerID] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_net_find/#options","text":"-h, --help help for find","title":"Options"},{"location":"powergate/cli/pow_net_find/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_net_find/#see-also","text":"pow net - Provides commands related to peers and network","title":"SEE ALSO"},{"location":"powergate/cli/pow_net_peers/","text":"pow net peers \u00b6 Get the node peers Synopsis \u00b6 Get the node peers pow net peers [flags] Options \u00b6 -h, --help help for peers Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow net - Provides commands related to peers and network","title":"Pow net peers"},{"location":"powergate/cli/pow_net_peers/#pow-net-peers","text":"Get the node peers","title":"pow net peers"},{"location":"powergate/cli/pow_net_peers/#synopsis","text":"Get the node peers pow net peers [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_net_peers/#options","text":"-h, --help help for peers","title":"Options"},{"location":"powergate/cli/pow_net_peers/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_net_peers/#see-also","text":"pow net - Provides commands related to peers and network","title":"SEE ALSO"},{"location":"powergate/cli/pow_reputation/","text":"pow reputation \u00b6 Provides commands to view miner reputation data Synopsis \u00b6 Provides commands to view miner reputation data Options \u00b6 -h, --help help for reputation Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data pow reputation addSource - Adds a new external source to be considered for reputation generation pow reputation topMiners - Fetches a list of the currently top rated miners","title":"Reputation"},{"location":"powergate/cli/pow_reputation/#pow-reputation","text":"Provides commands to view miner reputation data","title":"pow reputation"},{"location":"powergate/cli/pow_reputation/#synopsis","text":"Provides commands to view miner reputation data","title":"Synopsis"},{"location":"powergate/cli/pow_reputation/#options","text":"-h, --help help for reputation","title":"Options"},{"location":"powergate/cli/pow_reputation/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_reputation/#see-also","text":"pow - A client for storage and retreival of powergate data pow reputation addSource - Adds a new external source to be considered for reputation generation pow reputation topMiners - Fetches a list of the currently top rated miners","title":"SEE ALSO"},{"location":"powergate/cli/pow_reputation_addSource/","text":"pow reputation addSource \u00b6 Adds a new external source to be considered for reputation generation Synopsis \u00b6 Aadds a new external source to be considered for reputation generation pow reputation addSource [flags] Options \u00b6 -a, --address string multiaddress of the miner to add -h, --help help for addSource -i, --id string id of the miner to add Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow reputation - Provides commands to view miner reputation data","title":"pow reputation addSource"},{"location":"powergate/cli/pow_reputation_addSource/#pow-reputation-addsource","text":"Adds a new external source to be considered for reputation generation","title":"pow reputation addSource"},{"location":"powergate/cli/pow_reputation_addSource/#synopsis","text":"Aadds a new external source to be considered for reputation generation pow reputation addSource [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_reputation_addSource/#options","text":"-a, --address string multiaddress of the miner to add -h, --help help for addSource -i, --id string id of the miner to add","title":"Options"},{"location":"powergate/cli/pow_reputation_addSource/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_reputation_addSource/#see-also","text":"pow reputation - Provides commands to view miner reputation data","title":"SEE ALSO"},{"location":"powergate/cli/pow_reputation_topMiners/","text":"pow reputation topMiners \u00b6 Fetches a list of the currently top rated miners Synopsis \u00b6 Fetches a list of the currently top rated miners pow reputation topMiners [flags] Options \u00b6 -h, --help help for topMiners -l, --limit int limit the number of results (default -1) Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow reputation - Provides commands to view miner reputation data","title":"pow reputation topMiners"},{"location":"powergate/cli/pow_reputation_topMiners/#pow-reputation-topminers","text":"Fetches a list of the currently top rated miners","title":"pow reputation topMiners"},{"location":"powergate/cli/pow_reputation_topMiners/#synopsis","text":"Fetches a list of the currently top rated miners pow reputation topMiners [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_reputation_topMiners/#options","text":"-h, --help help for topMiners -l, --limit int limit the number of results (default -1)","title":"Options"},{"location":"powergate/cli/pow_reputation_topMiners/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_reputation_topMiners/#see-also","text":"pow reputation - Provides commands to view miner reputation data","title":"SEE ALSO"},{"location":"powergate/cli/pow_server-info/","text":"pow server-info \u00b6 Display information about the connected server Synopsis \u00b6 Display information about the connected server pow server-info [flags] Options \u00b6 -h, --help help for server-info Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data","title":"Pow server info"},{"location":"powergate/cli/pow_server-info/#pow-server-info","text":"Display information about the connected server","title":"pow server-info"},{"location":"powergate/cli/pow_server-info/#synopsis","text":"Display information about the connected server pow server-info [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_server-info/#options","text":"-h, --help help for server-info","title":"Options"},{"location":"powergate/cli/pow_server-info/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_server-info/#see-also","text":"pow - A client for storage and retreival of powergate data","title":"SEE ALSO"},{"location":"powergate/cli/pow_wallet/","text":"pow wallet \u00b6 Provides commands about filecoin wallets Synopsis \u00b6 Provides commands about filecoin wallets Options \u00b6 -h, --help help for wallet Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data pow wallet balance - Print the balance of the specified wallet address pow wallet list - Print all wallet addresses pow wallet new - Create a new filecoin wallet address pow wallet send - Send Fil from one address to another","title":"Wallet"},{"location":"powergate/cli/pow_wallet/#pow-wallet","text":"Provides commands about filecoin wallets","title":"pow wallet"},{"location":"powergate/cli/pow_wallet/#synopsis","text":"Provides commands about filecoin wallets","title":"Synopsis"},{"location":"powergate/cli/pow_wallet/#options","text":"-h, --help help for wallet","title":"Options"},{"location":"powergate/cli/pow_wallet/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_wallet/#see-also","text":"pow - A client for storage and retreival of powergate data pow wallet balance - Print the balance of the specified wallet address pow wallet list - Print all wallet addresses pow wallet new - Create a new filecoin wallet address pow wallet send - Send Fil from one address to another","title":"SEE ALSO"},{"location":"powergate/cli/pow_wallet_balance/","text":"pow wallet balance \u00b6 Print the balance of the specified wallet address Synopsis \u00b6 Print the balance of the specified wallet address pow wallet balance [address] [flags] Options \u00b6 -h, --help help for balance Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow wallet - Provides commands about filecoin wallets","title":"Pow wallet balance"},{"location":"powergate/cli/pow_wallet_balance/#pow-wallet-balance","text":"Print the balance of the specified wallet address","title":"pow wallet balance"},{"location":"powergate/cli/pow_wallet_balance/#synopsis","text":"Print the balance of the specified wallet address pow wallet balance [address] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_wallet_balance/#options","text":"-h, --help help for balance","title":"Options"},{"location":"powergate/cli/pow_wallet_balance/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_wallet_balance/#see-also","text":"pow wallet - Provides commands about filecoin wallets","title":"SEE ALSO"},{"location":"powergate/cli/pow_wallet_list/","text":"pow wallet list \u00b6 Print all wallet addresses Synopsis \u00b6 Print all wallet addresses pow wallet list [flags] Options \u00b6 -h, --help help for list Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow wallet - Provides commands about filecoin wallets","title":"Pow wallet list"},{"location":"powergate/cli/pow_wallet_list/#pow-wallet-list","text":"Print all wallet addresses","title":"pow wallet list"},{"location":"powergate/cli/pow_wallet_list/#synopsis","text":"Print all wallet addresses pow wallet list [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_wallet_list/#options","text":"-h, --help help for list","title":"Options"},{"location":"powergate/cli/pow_wallet_list/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_wallet_list/#see-also","text":"pow wallet - Provides commands about filecoin wallets","title":"SEE ALSO"},{"location":"powergate/cli/pow_wallet_new/","text":"pow wallet new \u00b6 Create a new filecoin wallet address Synopsis \u00b6 Create a new filecoin wallet address pow wallet new [flags] Options \u00b6 -h, --help help for new -t, --type string specifies the wallet type, either bls or secp256k1. Defaults to bls. (default \"bls\") Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow wallet - Provides commands about filecoin wallets","title":"Pow wallet new"},{"location":"powergate/cli/pow_wallet_new/#pow-wallet-new","text":"Create a new filecoin wallet address","title":"pow wallet new"},{"location":"powergate/cli/pow_wallet_new/#synopsis","text":"Create a new filecoin wallet address pow wallet new [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_wallet_new/#options","text":"-h, --help help for new -t, --type string specifies the wallet type, either bls or secp256k1. Defaults to bls. (default \"bls\")","title":"Options"},{"location":"powergate/cli/pow_wallet_new/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_wallet_new/#see-also","text":"pow wallet - Provides commands about filecoin wallets","title":"SEE ALSO"},{"location":"powergate/cli/pow_wallet_send/","text":"pow wallet send \u00b6 Send Fil from one address to another Synopsis \u00b6 Send Fil from one address to another pow wallet send [from address] [to address] [amount] [flags] Options \u00b6 -h, --help help for send Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") SEE ALSO \u00b6 pow wallet - Provides commands about filecoin wallets","title":"Pow wallet send"},{"location":"powergate/cli/pow_wallet_send/#pow-wallet-send","text":"Send Fil from one address to another","title":"pow wallet send"},{"location":"powergate/cli/pow_wallet_send/#synopsis","text":"Send Fil from one address to another pow wallet send [from address] [to address] [amount] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_wallet_send/#options","text":"-h, --help help for send","title":"Options"},{"location":"powergate/cli/pow_wallet_send/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\")","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_wallet_send/#see-also","text":"pow wallet - Provides commands about filecoin wallets","title":"SEE ALSO"},{"location":"threads/","text":"Getting Started \u00b6 ThreadDB is a multi-party database built on IPFS and Libp2p . Threads provide an alternative architecture for data on the web. ThreadDB aims to help power a new generation of web technologies by combining a novel use of event sourcing, Interplanetary Linked Data ( IPLD ), and access control to provide a distributed, scalable, and flexible database solution for decentralized applications. Thread Implementations \u00b6 There are two implementations of ThreadDB. Golang \u00b6 The first is written in Go and can be found at https://github.com/textileio/go-threads/ . This is the reference implementation, it contains all the latest components to use as a library, write trustless services, build a client connected to a a threads daemon. More documentation for the Go implementation will be coming in the future. JavaScript \u00b6 The second implementation is written in JavaScript (Typescript, really). This implementation has some optimizations to make it more ideal when writing web applications. The JavaScript implementation is currently a Client of the Go implementation. You can run it against your own go-threads instance or connect it to the Textile Hub to use one of ours. Read more about the Client here . In general, when you are building apps that use threads in remote context (e.g. the browser) it's best to push the networking later to remote services whenever possible (while using/allowing p2p when it works). You can also build your own remote relays and services using the go-threads library. For the rest of the explanation below, we'll focus on examples using the JavaScript library. Developer API \u00b6 ThreadDB is designed to be simple enough for any developer to start using. The API will feel familiar to developers who have worked with technologies like MongoDB. Data organization \u00b6 The first three concepts a developer will encounter with ThreadDB are Threads , Collections , and Instances . Instances are the individual records you create, update, or delete. Instances are stored in a Collection. Collections have one or many Schemas and can only store Instances that match one of those Schemas. Databases can store many Collections. Collections are similar to Tables in other databases. A Thread-based Database is tied to a single Thread (with associated Thread ID). Creating a new thread \u00b6 To start a new, empty Thread, with remote networking using the Hub APIs you simply initialize your Thread with the UserAuth object. You can read more about creating UserAuth objects in the creating web apps tutorial . Create a new Thread API client import { Client , PrivateKey , UserAuth } from '@textile/hub' async function setup ( auth : UserAuth ) { const user = await PrivateKey . fromRandom () const client = await Client . withUserAuth ( auth ) return client } Authorize a new user to use your Hub API You must generate a new API token for each user you want on your API. import { Client , PrivateKey } from '@textile/hub' async function newToken ( client : Client , user : PrivateKey ) { const token = await client . getToken ( user ) return token } List a user's existing Threads import { Client } from '@textile/hub' async function list ( client : Client ) { const threads = await client . listThreads () return threads } create a new database import { Client , Identity , ThreadID , UserAuth } from '@textile/hub' async function createDB ( client : Client ) { const thread : ThreadID = await client . newDB () return thread } Congrats! You now have a new ThreadDB! Each ThreadDB has a unique ThreadID . You can create your own ThreadIDs, or easily generate a random ThreadID as we do in the above example. Collections \u00b6 To handle different data structures in the same Database, a Database contains Collections. Each Collection is defined by a json-schema.org schema . These schemas define the shape of Collection Instances (the individual entries). Collections are similar to tables in other databases. Ultimately, a Collection is a single document store with a set of APIs to make it feel like a local database table . Collections can be created from an existing Schema or from an Object. Create from schema import { Client , ThreadID } from '@textile/hub' // Define a simple person schema const schema = { $schema : 'http://json-schema.org/draft-07/schema#' , title : 'Person' , type : 'object' , properties : { _id : { type : 'string' }, name : { type : 'string' }, missions : { type : 'number' , minimum : 0 , exclusiveMaximum : 100 , }, }, } // Requires the started database we created above async function collectionFromSchema ( client : Client , threadID : ThreadID ) { await client . newCollection ( threadID , 'Astronauts' , schema ) } Instances \u00b6 Instances are the objects you store in your Collection. Instances are JSON documents with schemas that match those defined in your Collection. get all instances import { Client , ThreadID } from '@textile/hub' async function findEntity ( client : Client , threadId : ThreadID , collection : string ) { const found = await client . find ( threadId , collection , {}) console . debug ( 'found:' , found . instancesList . length ) } add an instance import { Client , ThreadID } from '@textile/hub' // matches YourModel and schema async function create ( client : Client , threadId : ThreadID , collection : string ) { const created = await client . create ( threadId , collection , [{ some : 'data' , numbers : [ 1 , 2 , 3 ] }]) } Query \u00b6 Each Threads implementation supports query and look-up capabilities such as insert , findOne , has , and more. ThreadDB also supports the MongoDB query language . In the JavaScript library, you might write queries like the following. import { Client , ThreadID , QueryJSON } from '@textile/hub' // Requires the started database we generated above containing the Player collection async function createQuery ( client : Client , threadID : ThreadID , query : QueryJSON ) { // Get results const all = await client . find ( threadID , 'astronauts' , query ) return all } Listen \u00b6 You can also subscribe to changes in a database. import { Client , PrivateKey , ThreadID , Update } from '@textile/hub' const userID = PrivateKey . fromRandom () interface Astronaut { _id : string name : string missions : number } const callback = async ( reply? : Update < Astronaut > , err? : Error ) => { console . log ( reply . instance ) } // Requires userID already be authenticated to the Users API async function startListener ( client : Client , threadID : ThreadID ) { const filters = [{ actionTypes : [ 'CREATE' ]}] const closer = client . listen < Astronaut > ( threadID , filters , callback ) return closer } Access-control \u00b6 ThreadDB uses a modular role-based access control system that will allow access control lists (ACLs) to be declared in a wide-variety of ways. ACLs are in active development and you can follow the development here . Identity \u00b6 ThreadDB allows you to handle user identities (for access control and security/encryption) in the best way for your app and your users. In order to handle multiple peers collaborating on a single database, as well as the ability to handle storage on behalf of a user, ThreadDB expects a simple Identity interface for singing and validating database updates. See the Hub documentation on user identities for details. Replication with the Hub \u00b6 ThreadDB has been designed to support trustless peers on the network to provide services that improve or enhance performance and experience for end-users. The Hub offers Thread Services for relay, replication, and backup that you can add for your users in a couple of minutes. You can learn more about Identity, Access Control, and other advanced topics, in the Hub documentation. Connect to the Hub \u00b6 Create an Account Create an App Token Add the Textile Hub Library to your App Pinning, Relay, and Replication \u00b6 Thread Services (e.g. pinning encrypted data on IPFS and helping multiple peers relay updates across the network) can be built and deployed to the network using go-threads . Textile offers a number of these functions through the Hub. Attaching the Hub to your databases will allow you to deliver a high-quality user-experience. Installation \u00b6 ThreadDB can be used from many different languages and has libraries written in Javascript and Go. Find documentation on each of those Libraries below. JavaScript Add Threads to NodeJS, React Native or browser apps. Golang Use Threads in Go or compile to many other platforms. Advanced Details \u00b6 The protocols and design of ThreadDB can be explored in detail in the whitepaper: A protocol & event-sourced database for decentralized user-siloed data . For further technical details. the reference implementation of Threads is written in Go and the full implementation details can be found on godocs (jump to go-threads client ).","title":"ThreadDB Overview"},{"location":"threads/#getting-started","text":"ThreadDB is a multi-party database built on IPFS and Libp2p . Threads provide an alternative architecture for data on the web. ThreadDB aims to help power a new generation of web technologies by combining a novel use of event sourcing, Interplanetary Linked Data ( IPLD ), and access control to provide a distributed, scalable, and flexible database solution for decentralized applications.","title":"Getting Started"},{"location":"threads/#thread-implementations","text":"There are two implementations of ThreadDB.","title":"Thread Implementations"},{"location":"threads/#golang","text":"The first is written in Go and can be found at https://github.com/textileio/go-threads/ . This is the reference implementation, it contains all the latest components to use as a library, write trustless services, build a client connected to a a threads daemon. More documentation for the Go implementation will be coming in the future.","title":"Golang"},{"location":"threads/#javascript","text":"The second implementation is written in JavaScript (Typescript, really). This implementation has some optimizations to make it more ideal when writing web applications. The JavaScript implementation is currently a Client of the Go implementation. You can run it against your own go-threads instance or connect it to the Textile Hub to use one of ours. Read more about the Client here . In general, when you are building apps that use threads in remote context (e.g. the browser) it's best to push the networking later to remote services whenever possible (while using/allowing p2p when it works). You can also build your own remote relays and services using the go-threads library. For the rest of the explanation below, we'll focus on examples using the JavaScript library.","title":"JavaScript"},{"location":"threads/#developer-api","text":"ThreadDB is designed to be simple enough for any developer to start using. The API will feel familiar to developers who have worked with technologies like MongoDB.","title":"Developer API"},{"location":"threads/#data-organization","text":"The first three concepts a developer will encounter with ThreadDB are Threads , Collections , and Instances . Instances are the individual records you create, update, or delete. Instances are stored in a Collection. Collections have one or many Schemas and can only store Instances that match one of those Schemas. Databases can store many Collections. Collections are similar to Tables in other databases. A Thread-based Database is tied to a single Thread (with associated Thread ID).","title":"Data organization"},{"location":"threads/#creating-a-new-thread","text":"To start a new, empty Thread, with remote networking using the Hub APIs you simply initialize your Thread with the UserAuth object. You can read more about creating UserAuth objects in the creating web apps tutorial . Create a new Thread API client import { Client , PrivateKey , UserAuth } from '@textile/hub' async function setup ( auth : UserAuth ) { const user = await PrivateKey . fromRandom () const client = await Client . withUserAuth ( auth ) return client } Authorize a new user to use your Hub API You must generate a new API token for each user you want on your API. import { Client , PrivateKey } from '@textile/hub' async function newToken ( client : Client , user : PrivateKey ) { const token = await client . getToken ( user ) return token } List a user's existing Threads import { Client } from '@textile/hub' async function list ( client : Client ) { const threads = await client . listThreads () return threads } create a new database import { Client , Identity , ThreadID , UserAuth } from '@textile/hub' async function createDB ( client : Client ) { const thread : ThreadID = await client . newDB () return thread } Congrats! You now have a new ThreadDB! Each ThreadDB has a unique ThreadID . You can create your own ThreadIDs, or easily generate a random ThreadID as we do in the above example.","title":"Creating a new thread"},{"location":"threads/#collections","text":"To handle different data structures in the same Database, a Database contains Collections. Each Collection is defined by a json-schema.org schema . These schemas define the shape of Collection Instances (the individual entries). Collections are similar to tables in other databases. Ultimately, a Collection is a single document store with a set of APIs to make it feel like a local database table . Collections can be created from an existing Schema or from an Object. Create from schema import { Client , ThreadID } from '@textile/hub' // Define a simple person schema const schema = { $schema : 'http://json-schema.org/draft-07/schema#' , title : 'Person' , type : 'object' , properties : { _id : { type : 'string' }, name : { type : 'string' }, missions : { type : 'number' , minimum : 0 , exclusiveMaximum : 100 , }, }, } // Requires the started database we created above async function collectionFromSchema ( client : Client , threadID : ThreadID ) { await client . newCollection ( threadID , 'Astronauts' , schema ) }","title":"Collections"},{"location":"threads/#instances","text":"Instances are the objects you store in your Collection. Instances are JSON documents with schemas that match those defined in your Collection. get all instances import { Client , ThreadID } from '@textile/hub' async function findEntity ( client : Client , threadId : ThreadID , collection : string ) { const found = await client . find ( threadId , collection , {}) console . debug ( 'found:' , found . instancesList . length ) } add an instance import { Client , ThreadID } from '@textile/hub' // matches YourModel and schema async function create ( client : Client , threadId : ThreadID , collection : string ) { const created = await client . create ( threadId , collection , [{ some : 'data' , numbers : [ 1 , 2 , 3 ] }]) }","title":"Instances"},{"location":"threads/#query","text":"Each Threads implementation supports query and look-up capabilities such as insert , findOne , has , and more. ThreadDB also supports the MongoDB query language . In the JavaScript library, you might write queries like the following. import { Client , ThreadID , QueryJSON } from '@textile/hub' // Requires the started database we generated above containing the Player collection async function createQuery ( client : Client , threadID : ThreadID , query : QueryJSON ) { // Get results const all = await client . find ( threadID , 'astronauts' , query ) return all }","title":"Query"},{"location":"threads/#listen","text":"You can also subscribe to changes in a database. import { Client , PrivateKey , ThreadID , Update } from '@textile/hub' const userID = PrivateKey . fromRandom () interface Astronaut { _id : string name : string missions : number } const callback = async ( reply? : Update < Astronaut > , err? : Error ) => { console . log ( reply . instance ) } // Requires userID already be authenticated to the Users API async function startListener ( client : Client , threadID : ThreadID ) { const filters = [{ actionTypes : [ 'CREATE' ]}] const closer = client . listen < Astronaut > ( threadID , filters , callback ) return closer }","title":"Listen"},{"location":"threads/#access-control","text":"ThreadDB uses a modular role-based access control system that will allow access control lists (ACLs) to be declared in a wide-variety of ways. ACLs are in active development and you can follow the development here .","title":"Access-control"},{"location":"threads/#identity","text":"ThreadDB allows you to handle user identities (for access control and security/encryption) in the best way for your app and your users. In order to handle multiple peers collaborating on a single database, as well as the ability to handle storage on behalf of a user, ThreadDB expects a simple Identity interface for singing and validating database updates. See the Hub documentation on user identities for details.","title":"Identity"},{"location":"threads/#replication-with-the-hub","text":"ThreadDB has been designed to support trustless peers on the network to provide services that improve or enhance performance and experience for end-users. The Hub offers Thread Services for relay, replication, and backup that you can add for your users in a couple of minutes. You can learn more about Identity, Access Control, and other advanced topics, in the Hub documentation.","title":"Replication with the Hub"},{"location":"threads/#connect-to-the-hub","text":"Create an Account Create an App Token Add the Textile Hub Library to your App","title":"Connect to the Hub"},{"location":"threads/#pinning-relay-and-replication","text":"Thread Services (e.g. pinning encrypted data on IPFS and helping multiple peers relay updates across the network) can be built and deployed to the network using go-threads . Textile offers a number of these functions through the Hub. Attaching the Hub to your databases will allow you to deliver a high-quality user-experience.","title":"Pinning, Relay, and Replication"},{"location":"threads/#installation","text":"ThreadDB can be used from many different languages and has libraries written in Javascript and Go. Find documentation on each of those Libraries below.","title":"Installation"},{"location":"threads/#advanced-details","text":"The protocols and design of ThreadDB can be explored in detail in the whitepaper: A protocol & event-sourced database for decentralized user-siloed data . For further technical details. the reference implementation of Threads is written in Go and the full implementation details can be found on godocs (jump to go-threads client ).","title":"Advanced Details"},{"location":"tutorials/nodejs/","text":"Building with NodeJS \u00b6 There aren't many differences when using Textile's JavaScript libraries with NodeJS, except one, most of of the APIs exposed (Buckets daemon, Threads daemons, and the Hub) do so over WebSockets. WebSockets are baked into every major browser, but don't come with NodeJS by default, so we'll have to add them. Adding WebSockets to NodeJS \u00b6 The easiest solution to make all libraries compatible is to add WebSockets to the global namespace. Install We'll use the isomorphic-ws library to add WebSockets to our Node app. npm install --save isomorphic-ws ws Setup You can now just add WebSockets to the global namespace in your apps. Add this to the first line in your js or ts files, usually index.js or main.js or similar. In TypeScript: ;( global as any ). WebSocket = require ( 'isomorphic-ws' ) In JavaScript: ; global . WebSocket = require ( 'isomorphic-ws' ) Start building \u00b6 That's it, now start building the full suite of Textile tools. Check out the app building tutorials for ideas.","title":"Build with NodeJS"},{"location":"tutorials/nodejs/#building-with-nodejs","text":"There aren't many differences when using Textile's JavaScript libraries with NodeJS, except one, most of of the APIs exposed (Buckets daemon, Threads daemons, and the Hub) do so over WebSockets. WebSockets are baked into every major browser, but don't come with NodeJS by default, so we'll have to add them.","title":"Building with NodeJS"},{"location":"tutorials/nodejs/#adding-websockets-to-nodejs","text":"The easiest solution to make all libraries compatible is to add WebSockets to the global namespace. Install We'll use the isomorphic-ws library to add WebSockets to our Node app. npm install --save isomorphic-ws ws Setup You can now just add WebSockets to the global namespace in your apps. Add this to the first line in your js or ts files, usually index.js or main.js or similar. In TypeScript: ;( global as any ). WebSocket = require ( 'isomorphic-ws' ) In JavaScript: ; global . WebSocket = require ( 'isomorphic-ws' )","title":"Adding WebSockets to NodeJS"},{"location":"tutorials/nodejs/#start-building","text":"That's it, now start building the full suite of Textile tools. Check out the app building tutorials for ideas.","title":"Start building"},{"location":"tutorials/react-native-buckets/","text":"User Buckets from React Native \u00b6 The Hub gets really powerful when you allow your app users to leverage IPFS, IPNS, and ThreadDB from inside your applications. In this tutorial, we'll look at how you can let users author, own, and manage buckets right from a mobile app built in React Native. Click here to see an example app built with this tutorial . Preview video \u00b6 Install libraries \u00b6 Textile Libraries npm install --save @textile/hub @textile/threads-id We'll use the above combination of Textile libraries in our app below. rn-nodify npm install -D rn-nodeify We are going to use rn-nodify and a few other libraries it will install to manage adding Buffer , crypto , and some other tools to our JavaScript environment in React Native. Read about rn-nodify here . Next, you need to run, ./node_modules/.bin/rn-nodeify --install This will install a shim.js into the root of your file. You need to import shim.js at the top of your app's root file (typically index.js ), import './shim' ; This may need to be updated on future package changes, you can make this easier on yourself by adding a postinstall step to your package.json , as follows, \"scripts\" : { ... \"postinstall\" : \"./node_modules/.bin/rn-nodeify --install fs,path,process,buffer,crypto,stream,vm --hack\" } Dot env You will need to add API keys to your app. If you plan to store your sourcecode anywhere public, you should not store those keys publicly. In our example app, we use react-native-dotenv to manage our key. npm install --save react-native-dotenv Next, create a .env file in the root of your project. You can find an example .env in our example project here . Be certain that the .env is added to your .gitignore and note checked in with your code. The contents of .env will be, USER_API_KEY = textile-hub-user-group-key You can follow the instructions to generate a User Group Key here, API Access . If you have already generated keys, you can list them by executing hub keys ls . You'll add the values to your .env file on the right side of the equality sign. Typescript The rest of the JavaScript portions of the tutorial will be in TypeScript. You do not need to use TypeScript, but if you don't be sure to strip the typings from any code you copy below. Build your app \u00b6 Hint In the example app, we put all the ThreadDB and Bucket logic into a single component called checklist.ts . You can view that file for reference. Import Textile // Buckets client and an API Context helper import { Buckets , Client , ThreadID , PrivateKey , Where } from '@textile/hub' ; Register with remote API \u00b6 Next, we'll connect to the remote API using our Key from an insecure (non-signing) api key (read more about keys for development mode ). We do this so that the user can later push their bucket for remote persistence on IPFS and publishing on IPNS. import { Client } from '@textile/hub' const client = Client . withKeyInfo ({ key : 'USER_API_KEY' , }) Hint Read more about the Context tool in the Threads Introduction . Generate an Identity \u00b6 Read the basic identities tutorial now . import { PrivateKey } from '@textile/hub' async function example () { const id = await PrivateKey . fromRandom (); return id } Here we are just using a helper to generate a private-key identity for the user. Generate user Token \u00b6 import { Client , PrivateKey } from '@textile/hub' async function example ( client : Client , identity : PrivateKey ) { await client . getToken ( identity ); } This will register the user with your remote Hub account, granting them the ability to push data to IPFS through Threads and Buckets. Connect Buckets \u00b6 Now that your user is setup and connected to your API on the Hub, you can start creating Buckets. First, setup a Bucket instance. import { Buckets } from '@textile/hub' const buckets = Buckets . withKeyInfo ({ key : 'USER_API_KEY' , }) In the above, we reuse the Context we already created in our ThreadDB Client because it contains the token, API keys, etc. Info If you have already created a connection using the Threads client , you directly transfer that connection to Buckets with, Buckets.copyAuth(client) . List all Buckets import { Buckets } from '@textile/hub' async function find ( buckets : Buckets ) { const roots = await buckets . list (); const exists = roots . find (( bucket ) => bucket . name === 'buckets' ) return exists } Open a Bucket By far the easiest way to start pushing/pulling bucket files is to use the open method with just the bucket name you intend to use. import { Buckets } from '@textile/hub' async function find ( buckets : Buckets , name : string ) { const root = await buckets . open ( name ) return root // root.key is the bucket key } Push files to user Bucket \u00b6 Finally, let's push a simple file to the user's Bucket. In this example, we'll just create a simple HTML file that says, Hello world . import { Buckets } from '@textile/hub' async function example ( buckets : Buckets , bucketKey : string , content : string ) { const file = { path : '/index.html' , content : Buffer.from ( content ) } const raw = await buckets . pushPath ( bucketKey , 'index.html' , file ) } List the Bucket links \u00b6 Finally, you can list the links to the file on IPFS, IPNS, ThreadDB, and HTTP. Now that the Bucket is created, keep in mind, each time you update the same Bucket for a user: replace the HTTP content. the Bucket head will get a new IPFS address. replace the IPNS content. be appended to the ThreadDB history. This give you a lot of options for how you build apps, deliver content, and do cool things for your users with their data. You can get each of the protocol addresses as follows. HTTP Address Textile give you and your users a public address for each Bucket created. They are created using the Bucket key and you can generate those as follows: https://${bucket-key}.textile.space IPFS Address The IPFS address is contained in the result of pushPath . import { Buckets } from '@textile/hub' async function example ( buckets : Buckets , bucketKey : string , file : Buffer ) { const raw = await buckets . pushPath ( bucketKey ! , 'index.html' , file ) console . log ( raw . root ) } IPNS Address The IPNS Address is always the same and is the Bucket key! If you want to see the Bucket over IPNS from a gateway, you can use the Textile gateway as follows: https://${bucket-key}.ipns.hub.textile.io/ ThreadDB Address You can generate a link to the Bucket with the user thread as follows: https://${thread-id}.thread.hub.textile.io/buckets/${this.state.bucket-key} Warning Remember that at this point in time, Buckets are entirely open, data is available to be viewed or downloaded by anyone your app or user share the link with. Code \u00b6 Check out a complete React Native project on GitHub that generates a user identity, Thread, and Bucket. Running the example \u00b6 Android \u00b6 Simply npm install and then npm run android from the root of the react-native-hub-app folder. iOS \u00b6 If npm run ios doesn't work for you immediately after npm install , follow these steps. Be sure you ran npm install . Be sure you have updated your .env file. Start the react native server, npm run start . Open Xcode Open the iOS project, ./ios/threadsdb_app.xcworkspace . Click run in Xcode. Your app should now be running. Subsequent should work with just, npm run ios .","title":"Mobile threads & buckets"},{"location":"tutorials/react-native-buckets/#user-buckets-from-react-native","text":"The Hub gets really powerful when you allow your app users to leverage IPFS, IPNS, and ThreadDB from inside your applications. In this tutorial, we'll look at how you can let users author, own, and manage buckets right from a mobile app built in React Native. Click here to see an example app built with this tutorial .","title":"User Buckets from React Native"},{"location":"tutorials/react-native-buckets/#preview-video","text":"","title":"Preview video"},{"location":"tutorials/react-native-buckets/#install-libraries","text":"Textile Libraries npm install --save @textile/hub @textile/threads-id We'll use the above combination of Textile libraries in our app below. rn-nodify npm install -D rn-nodeify We are going to use rn-nodify and a few other libraries it will install to manage adding Buffer , crypto , and some other tools to our JavaScript environment in React Native. Read about rn-nodify here . Next, you need to run, ./node_modules/.bin/rn-nodeify --install This will install a shim.js into the root of your file. You need to import shim.js at the top of your app's root file (typically index.js ), import './shim' ; This may need to be updated on future package changes, you can make this easier on yourself by adding a postinstall step to your package.json , as follows, \"scripts\" : { ... \"postinstall\" : \"./node_modules/.bin/rn-nodeify --install fs,path,process,buffer,crypto,stream,vm --hack\" } Dot env You will need to add API keys to your app. If you plan to store your sourcecode anywhere public, you should not store those keys publicly. In our example app, we use react-native-dotenv to manage our key. npm install --save react-native-dotenv Next, create a .env file in the root of your project. You can find an example .env in our example project here . Be certain that the .env is added to your .gitignore and note checked in with your code. The contents of .env will be, USER_API_KEY = textile-hub-user-group-key You can follow the instructions to generate a User Group Key here, API Access . If you have already generated keys, you can list them by executing hub keys ls . You'll add the values to your .env file on the right side of the equality sign. Typescript The rest of the JavaScript portions of the tutorial will be in TypeScript. You do not need to use TypeScript, but if you don't be sure to strip the typings from any code you copy below.","title":"Install libraries"},{"location":"tutorials/react-native-buckets/#build-your-app","text":"Hint In the example app, we put all the ThreadDB and Bucket logic into a single component called checklist.ts . You can view that file for reference. Import Textile // Buckets client and an API Context helper import { Buckets , Client , ThreadID , PrivateKey , Where } from '@textile/hub' ;","title":"Build your app"},{"location":"tutorials/react-native-buckets/#register-with-remote-api","text":"Next, we'll connect to the remote API using our Key from an insecure (non-signing) api key (read more about keys for development mode ). We do this so that the user can later push their bucket for remote persistence on IPFS and publishing on IPNS. import { Client } from '@textile/hub' const client = Client . withKeyInfo ({ key : 'USER_API_KEY' , }) Hint Read more about the Context tool in the Threads Introduction .","title":"Register with remote API"},{"location":"tutorials/react-native-buckets/#generate-an-identity","text":"Read the basic identities tutorial now . import { PrivateKey } from '@textile/hub' async function example () { const id = await PrivateKey . fromRandom (); return id } Here we are just using a helper to generate a private-key identity for the user.","title":"Generate an Identity"},{"location":"tutorials/react-native-buckets/#generate-user-token","text":"import { Client , PrivateKey } from '@textile/hub' async function example ( client : Client , identity : PrivateKey ) { await client . getToken ( identity ); } This will register the user with your remote Hub account, granting them the ability to push data to IPFS through Threads and Buckets.","title":"Generate user Token"},{"location":"tutorials/react-native-buckets/#connect-buckets","text":"Now that your user is setup and connected to your API on the Hub, you can start creating Buckets. First, setup a Bucket instance. import { Buckets } from '@textile/hub' const buckets = Buckets . withKeyInfo ({ key : 'USER_API_KEY' , }) In the above, we reuse the Context we already created in our ThreadDB Client because it contains the token, API keys, etc. Info If you have already created a connection using the Threads client , you directly transfer that connection to Buckets with, Buckets.copyAuth(client) . List all Buckets import { Buckets } from '@textile/hub' async function find ( buckets : Buckets ) { const roots = await buckets . list (); const exists = roots . find (( bucket ) => bucket . name === 'buckets' ) return exists } Open a Bucket By far the easiest way to start pushing/pulling bucket files is to use the open method with just the bucket name you intend to use. import { Buckets } from '@textile/hub' async function find ( buckets : Buckets , name : string ) { const root = await buckets . open ( name ) return root // root.key is the bucket key }","title":"Connect Buckets"},{"location":"tutorials/react-native-buckets/#push-files-to-user-bucket","text":"Finally, let's push a simple file to the user's Bucket. In this example, we'll just create a simple HTML file that says, Hello world . import { Buckets } from '@textile/hub' async function example ( buckets : Buckets , bucketKey : string , content : string ) { const file = { path : '/index.html' , content : Buffer.from ( content ) } const raw = await buckets . pushPath ( bucketKey , 'index.html' , file ) }","title":"Push files to user Bucket"},{"location":"tutorials/react-native-buckets/#list-the-bucket-links","text":"Finally, you can list the links to the file on IPFS, IPNS, ThreadDB, and HTTP. Now that the Bucket is created, keep in mind, each time you update the same Bucket for a user: replace the HTTP content. the Bucket head will get a new IPFS address. replace the IPNS content. be appended to the ThreadDB history. This give you a lot of options for how you build apps, deliver content, and do cool things for your users with their data. You can get each of the protocol addresses as follows. HTTP Address Textile give you and your users a public address for each Bucket created. They are created using the Bucket key and you can generate those as follows: https://${bucket-key}.textile.space IPFS Address The IPFS address is contained in the result of pushPath . import { Buckets } from '@textile/hub' async function example ( buckets : Buckets , bucketKey : string , file : Buffer ) { const raw = await buckets . pushPath ( bucketKey ! , 'index.html' , file ) console . log ( raw . root ) } IPNS Address The IPNS Address is always the same and is the Bucket key! If you want to see the Bucket over IPNS from a gateway, you can use the Textile gateway as follows: https://${bucket-key}.ipns.hub.textile.io/ ThreadDB Address You can generate a link to the Bucket with the user thread as follows: https://${thread-id}.thread.hub.textile.io/buckets/${this.state.bucket-key} Warning Remember that at this point in time, Buckets are entirely open, data is available to be viewed or downloaded by anyone your app or user share the link with.","title":"List the Bucket links"},{"location":"tutorials/react-native-buckets/#code","text":"Check out a complete React Native project on GitHub that generates a user identity, Thread, and Bucket.","title":"Code"},{"location":"tutorials/react-native-buckets/#running-the-example","text":"","title":"Running the example"},{"location":"tutorials/react-native-buckets/#android","text":"Simply npm install and then npm run android from the root of the react-native-hub-app folder.","title":"Android"},{"location":"tutorials/react-native-buckets/#ios","text":"If npm run ios doesn't work for you immediately after npm install , follow these steps. Be sure you ran npm install . Be sure you have updated your .env file. Start the react native server, npm run start . Open Xcode Open the iOS project, ./ios/threadsdb_app.xcworkspace . Click run in Xcode. Your app should now be running. Subsequent should work with just, npm run ios .","title":"iOS"},{"location":"tutorials/static-websites/","text":"Buckets make it simple to publish websites using IPFS. If you are using a static site builder such as Jekyll , Gatsby , Hugo , or Mkdocs you can add Buckets to your build steps for both staging and production site hosting. Site builder tutorials \u00b6 If you are using one of these static site builders, jump to the specific tutorials. Jekyll Site An example Jekyll site published in a Bucket. Gatsby Site An example Gatsby site published in a Bucket. Hugo Site An example Hugo site published in a Bucket. Automation and deployment (CI/CD) \u00b6 Buckets are an ideal tool for persisting your website, source code, or documentation on IPFS using continuous integration. Tools like Travis CI, CircleCI, and GitHub Actions all make it possible to do very easily. If you kepe your website source code on GitHub, we have provided a configurable GitHub Action that allows you to automatically push updates to your Bucket whenever your website changes. View the Textile Buckets GitHub Action . Resources \u00b6 Domain Name Management \u00b6 Fleek Fleek offers domain management tools and soon, Bucket support. Cloudflare Easily add your Bucket IPNS address to Cloudflare with DNSLink. Network Replication \u00b6 Your website may be one of your most important assets on IPFS. Why not pin it on multiple infrastructure providers for added network speed. Pinata Simple and easy to use, Pinata offers a great pinning API for IPFS. Infura Seasoned builders of API portals for the dWeb, pin with confidence on Infura. Temporal Get the stopwatch out, Temporal is your pinning service with speed on the brain . Overview \u00b6 Initialize your Bucket \u00b6 If you are building a static site with an engine such as Jekyll or Gatsyb, or even React you will want to initialize your Bucket in the root of the project, not in the build folder. Your project might look like this. ls ./ build package.json src In this case, we are building the raw site code in src into the build folder. We should initialize the Bucket at the root of the project. cd build hub bucket init Push your Bucket \u00b6 Now, pushing your Bucket is simple. After you build your project so that build contains the latest version of your site ready to deploy you run the bucket push command. hub bucket push That's it! Your site is now available on the free subdomain and over IPNS. You can easily integrate it into your own DNS using DNSLink. DNSLink \u00b6 You can use Buckets to host websites from your own domain using DNSLink . The easiest way to do this is using your Bucket's IPNS link. On Cloudflare for example, your updated DNS records should look like the following. CNAME <site> www.cloudflare-ipfs.com TXT _dnslink.<site> dnslink = /ipns/<bucket ipns link>","title":"Static websites"},{"location":"tutorials/static-websites/#site-builder-tutorials","text":"If you are using one of these static site builders, jump to the specific tutorials.","title":"Site builder tutorials"},{"location":"tutorials/static-websites/#automation-and-deployment-cicd","text":"Buckets are an ideal tool for persisting your website, source code, or documentation on IPFS using continuous integration. Tools like Travis CI, CircleCI, and GitHub Actions all make it possible to do very easily. If you kepe your website source code on GitHub, we have provided a configurable GitHub Action that allows you to automatically push updates to your Bucket whenever your website changes. View the Textile Buckets GitHub Action .","title":"Automation and deployment (CI/CD)"},{"location":"tutorials/static-websites/#resources","text":"","title":"Resources"},{"location":"tutorials/static-websites/#domain-name-management","text":"","title":"Domain Name Management"},{"location":"tutorials/static-websites/#network-replication","text":"Your website may be one of your most important assets on IPFS. Why not pin it on multiple infrastructure providers for added network speed.","title":"Network Replication"},{"location":"tutorials/static-websites/#overview","text":"","title":"Overview"},{"location":"tutorials/static-websites/#initialize-your-bucket","text":"If you are building a static site with an engine such as Jekyll or Gatsyb, or even React you will want to initialize your Bucket in the root of the project, not in the build folder. Your project might look like this. ls ./ build package.json src In this case, we are building the raw site code in src into the build folder. We should initialize the Bucket at the root of the project. cd build hub bucket init","title":"Initialize your Bucket"},{"location":"tutorials/static-websites/#push-your-bucket","text":"Now, pushing your Bucket is simple. After you build your project so that build contains the latest version of your site ready to deploy you run the bucket push command. hub bucket push That's it! Your site is now available on the free subdomain and over IPNS. You can easily integrate it into your own DNS using DNSLink.","title":"Push your Bucket"},{"location":"tutorials/static-websites/#dnslink","text":"You can use Buckets to host websites from your own domain using DNSLink . The easiest way to do this is using your Bucket's IPNS link. On Cloudflare for example, your updated DNS records should look like the following. CNAME <site> www.cloudflare-ipfs.com TXT _dnslink.<site> dnslink = /ipns/<bucket ipns link>","title":"DNSLink"},{"location":"tutorials/golang/getting-started/","text":"Buckets and Threads in Go \u00b6 You have access to the full suite of Textile APIs and technologies in Go. This includes access to Hub-based persistence, thread client, local thread databases, bucket client, and more. Below, we'll walk you through the basic flow for creating new user identities and giving them access to your resources on the Hub. You can read more about Go support in the Thread Client , Bucket Client , and Hub API docs. Create a new Identity \u00b6 Many functions below require some form of PKI identity. You can use the Threads library to generate a basic one. package main import ( crand \"crypto/rand\" \"github.com/libp2p/go-libp2p-core/crypto\" \"github.com/textileio/go-threads/core/thread\" ) func createIdentity () ( thread . Identity , error ) { sk , _ , err := crypto . GenerateEd25519Key ( crand . Reader ) if err != nil { return nil , err } return thread . NewLibp2pIdentity ( sk ), nil } Info The NewLibp2pIdentity method returns a new thread.Identity . Hub authentication \u00b6 Authentication on the Hub is done using your API keys and secrets, either Account Keys or User Group Keys depending on what kind of application you are building and which APIs you plan to use. Below is an example authentication function that will use your User Group Key to create a context that stores the correct session information to begin using the APIs. This function would need to be run before all functions below in order to generate the proper context object. package main import ( \"context\" \"time\" \"github.com/textileio/textile/api/common\" ) func authenticate ( ctx context . Context , userGroupKey string , userGroupSecret string ) ( context . Context , error ) { // Add our user group key to the context ctx = common . NewAPIKeyContext ( ctx , userGroupKey ) // Add a signature using our user group secret var err error ctx , err = common . CreateAPISigContext ( ctx , time . Now (). Add ( time . Minute ), userGroupSecret ) return ctx , err } Hub user authorization \u00b6 Next, you can provide access to your Hub APIs to your users by generating an API token for them. Tokens are based on your user's identity public keys and your context created above. You could use any keypair identity, but we'll use the simple threads.Identity type shown above. package main import ( \"context\" \"github.com/textileio/go-threads/api/client\" \"github.com/textileio/go-threads/core/thread\" \"google.golang.org/grpc\" ) var HUB_API = \"api.textile.io:3447\" var HUB_HEADERS = [] grpc . DialOption { grpc . WithInsecure (), grpc . WithPerRPCCredentials ( common . Credentials {})} func authorizeUser ( ctx context . Context , user thread . Identity ) ( context . Context , error ) { // Create an API Client cli , err := client . NewClient ( HUB_API , HUB_HEADERS ... ) if err != nil { return nil , err } // Generate a new token for the user tok , err := cli . GetToken ( ctx , user ) if err != nil { return nil , err } // // Add the token to the context ctx = thread . NewTokenContext ( ctx , tok ) return ctx , nil } Create threads with the client \u00b6 The client allows you to create fully remote threads on the Hub. This is a good approach for cases where the application doesn't require fully offline modes. package main import ( \"context\" \"time\" crand \"crypto/rand\" \"github.com/libp2p/go-libp2p-core/crypto\" \"github.com/textileio/go-threads/core/thread\" \"github.com/textileio/go-threads/common\" \"google.golang.org/grpc\" ) var HUB_API = \"api.textile.io:3447\" var HUB_HEADERS = [] grpc . DialOption { grpc . WithInsecure (), grpc . WithPerRPCCredentials ( common . Credentials {})} func createThreadDB ( ctx context . Context , name string ) error { // Assign the name for the Thread ctx = common . NewThreadNameContext ( ctx , name ) // Generate our client again cli , err := client . NewClient ( HUB_API , HUB_HEADERS ... ) if err != nil { return err } // Create the ID dbID := thread . NewIDV1 ( thread . Raw , 32 ) // Create the database return cli . NewDB ( ctx , dbID ) } Create a Bucket \u00b6 Creating buckets in Go applications shares many of the same steps as creating threads. Because buckets are managed in a thread, you must first create a thread where you will then add a bucket. A single thread can store all of your user's buckets (and more). package main import ( \"context\" \"time\" crand \"crypto/rand\" \"github.com/textileio/go-threads/core/thread\" \"github.com/textileio/go-threads/common\" buckets \"github.com/textileio/textile/api/buckets/client\" \"google.golang.org/grpc\" ) var HUB_API = \"api.textile.io:3447\" var HUB_HEADERS = [] grpc . DialOption { grpc . WithInsecure (), grpc . WithPerRPCCredentials ( common . Credentials {})} func createBucket ( ctx context . Context , name string ) error { // Create a new threaddb for our buckets ctx = common . NewThreadNameContext ( ctx , \"my-buckets\" ) cli , err := client . NewClient ( HUB_API , HUB_HEADERS ... ) if err != nil { return err } dbID := thread . NewIDV1 ( thread . Raw , 32 ) err = cli . NewDB ( ctx , dbID ) if err != nil { return err } // Connect our Bucket client bucket , err := buckets . NewClient ( HUB_API , HUB_HEADERS ... ) if err != nil { return err } // Initialize a new bucket in the db ctx = common . NewThreadIDContext ( ctx , dbID ) buck , err := bucket . Init ( ctx , \"images\" ) if err != nil { return err } //Finally, push a file to the bucket. file , err := os . Open ( \"data/file1.jpg\" ) if err != nil { return err } defer file . Close () _ , file1Root , err := buckets . PushPath ( ctx , buck . Root . Key , \"file1.jpg\" , file ) return err }","title":"Getting started with Golang"},{"location":"tutorials/golang/getting-started/#buckets-and-threads-in-go","text":"You have access to the full suite of Textile APIs and technologies in Go. This includes access to Hub-based persistence, thread client, local thread databases, bucket client, and more. Below, we'll walk you through the basic flow for creating new user identities and giving them access to your resources on the Hub. You can read more about Go support in the Thread Client , Bucket Client , and Hub API docs.","title":"Buckets and Threads in Go"},{"location":"tutorials/golang/getting-started/#create-a-new-identity","text":"Many functions below require some form of PKI identity. You can use the Threads library to generate a basic one. package main import ( crand \"crypto/rand\" \"github.com/libp2p/go-libp2p-core/crypto\" \"github.com/textileio/go-threads/core/thread\" ) func createIdentity () ( thread . Identity , error ) { sk , _ , err := crypto . GenerateEd25519Key ( crand . Reader ) if err != nil { return nil , err } return thread . NewLibp2pIdentity ( sk ), nil } Info The NewLibp2pIdentity method returns a new thread.Identity .","title":"Create a new Identity"},{"location":"tutorials/golang/getting-started/#hub-authentication","text":"Authentication on the Hub is done using your API keys and secrets, either Account Keys or User Group Keys depending on what kind of application you are building and which APIs you plan to use. Below is an example authentication function that will use your User Group Key to create a context that stores the correct session information to begin using the APIs. This function would need to be run before all functions below in order to generate the proper context object. package main import ( \"context\" \"time\" \"github.com/textileio/textile/api/common\" ) func authenticate ( ctx context . Context , userGroupKey string , userGroupSecret string ) ( context . Context , error ) { // Add our user group key to the context ctx = common . NewAPIKeyContext ( ctx , userGroupKey ) // Add a signature using our user group secret var err error ctx , err = common . CreateAPISigContext ( ctx , time . Now (). Add ( time . Minute ), userGroupSecret ) return ctx , err }","title":"Hub authentication"},{"location":"tutorials/golang/getting-started/#hub-user-authorization","text":"Next, you can provide access to your Hub APIs to your users by generating an API token for them. Tokens are based on your user's identity public keys and your context created above. You could use any keypair identity, but we'll use the simple threads.Identity type shown above. package main import ( \"context\" \"github.com/textileio/go-threads/api/client\" \"github.com/textileio/go-threads/core/thread\" \"google.golang.org/grpc\" ) var HUB_API = \"api.textile.io:3447\" var HUB_HEADERS = [] grpc . DialOption { grpc . WithInsecure (), grpc . WithPerRPCCredentials ( common . Credentials {})} func authorizeUser ( ctx context . Context , user thread . Identity ) ( context . Context , error ) { // Create an API Client cli , err := client . NewClient ( HUB_API , HUB_HEADERS ... ) if err != nil { return nil , err } // Generate a new token for the user tok , err := cli . GetToken ( ctx , user ) if err != nil { return nil , err } // // Add the token to the context ctx = thread . NewTokenContext ( ctx , tok ) return ctx , nil }","title":"Hub user authorization"},{"location":"tutorials/golang/getting-started/#create-threads-with-the-client","text":"The client allows you to create fully remote threads on the Hub. This is a good approach for cases where the application doesn't require fully offline modes. package main import ( \"context\" \"time\" crand \"crypto/rand\" \"github.com/libp2p/go-libp2p-core/crypto\" \"github.com/textileio/go-threads/core/thread\" \"github.com/textileio/go-threads/common\" \"google.golang.org/grpc\" ) var HUB_API = \"api.textile.io:3447\" var HUB_HEADERS = [] grpc . DialOption { grpc . WithInsecure (), grpc . WithPerRPCCredentials ( common . Credentials {})} func createThreadDB ( ctx context . Context , name string ) error { // Assign the name for the Thread ctx = common . NewThreadNameContext ( ctx , name ) // Generate our client again cli , err := client . NewClient ( HUB_API , HUB_HEADERS ... ) if err != nil { return err } // Create the ID dbID := thread . NewIDV1 ( thread . Raw , 32 ) // Create the database return cli . NewDB ( ctx , dbID ) }","title":"Create threads with the client"},{"location":"tutorials/golang/getting-started/#create-a-bucket","text":"Creating buckets in Go applications shares many of the same steps as creating threads. Because buckets are managed in a thread, you must first create a thread where you will then add a bucket. A single thread can store all of your user's buckets (and more). package main import ( \"context\" \"time\" crand \"crypto/rand\" \"github.com/textileio/go-threads/core/thread\" \"github.com/textileio/go-threads/common\" buckets \"github.com/textileio/textile/api/buckets/client\" \"google.golang.org/grpc\" ) var HUB_API = \"api.textile.io:3447\" var HUB_HEADERS = [] grpc . DialOption { grpc . WithInsecure (), grpc . WithPerRPCCredentials ( common . Credentials {})} func createBucket ( ctx context . Context , name string ) error { // Create a new threaddb for our buckets ctx = common . NewThreadNameContext ( ctx , \"my-buckets\" ) cli , err := client . NewClient ( HUB_API , HUB_HEADERS ... ) if err != nil { return err } dbID := thread . NewIDV1 ( thread . Raw , 32 ) err = cli . NewDB ( ctx , dbID ) if err != nil { return err } // Connect our Bucket client bucket , err := buckets . NewClient ( HUB_API , HUB_HEADERS ... ) if err != nil { return err } // Initialize a new bucket in the db ctx = common . NewThreadIDContext ( ctx , dbID ) buck , err := bucket . Init ( ctx , \"images\" ) if err != nil { return err } //Finally, push a file to the bucket. file , err := os . Open ( \"data/file1.jpg\" ) if err != nil { return err } defer file . Close () _ , file1Root , err := buckets . PushPath ( ctx , buck . Root . Key , \"file1.jpg\" , file ) return err }","title":"Create a Bucket"},{"location":"tutorials/hub/development-mode/","text":"Development mode \u00b6 You are now ready to start running your app! The Hub allows you to generate API keys that will grant your app access to your APIs. There are two flavors of API key, Account keys that are not ideal for apps since they will grant admin access to your developer account, and User group keys which are designed for apps where you want one set of keys to grant API access for many users. API Access \u00b6 User group keys come with a key and a secret . You never want to share your secret or save it in a place where it may be exposed. However, when you are in development mode, you can create keys that have signing disabled , meaning no secret is required. This is ideal during development or working with your internal team, because it will make your first steps of app development a bit faster. Create insecure keys \u00b6 You can create your insecure keys during the key generation step, simply select N for requiring signature authentication. \u25b6 hub keys create \u2714 user group ? Require Signature Authentication ( recommended ) ? [ y/N ] N \u2588 Use insecure keys \u00b6 Now, you can use the insecure keys for building your app without having to first setup a user login flow. However, when you are ready to add that step to your app, be sure to use a new set of keys. You can read more about production setup in the next part of this tutorial . Start building \u00b6 With your insecure API key, you have everything you need to start building with the Hub APIs, Threads, and Buckets. Using the API \u00b6 Now, your users have identities and they've verified themselves. Next, you'll want to start created Buckets and ThreadDBs for your user. Let's start using hte Hub from inside the webapp. Install dependencies # Textile libraries npm install --save @textile/hub Connect to the API Now, you just need to create a KeyInfo object above to connect to the API. import { Client , Identity , KeyInfo } from '@textile/hub' ; async function authorize ( key : KeyInfo , identity : Identity ) { const client = await Client . withKeyInfo ( key ) await client . getToken ( identity ) return client } The KeyInfo you supply to the API will look as follows, import { KeyInfo } from '@textile/hub' ; const keyinfo : KeyInfo = { key : 'INSECURE API KEY' , } Your user is now setup to start creating Threads and Buckets that replicate on the Hub API! Read more tutorials or jump over to the js-threads docs to keep building.","title":"Development mode"},{"location":"tutorials/hub/development-mode/#development-mode","text":"You are now ready to start running your app! The Hub allows you to generate API keys that will grant your app access to your APIs. There are two flavors of API key, Account keys that are not ideal for apps since they will grant admin access to your developer account, and User group keys which are designed for apps where you want one set of keys to grant API access for many users.","title":"Development mode"},{"location":"tutorials/hub/development-mode/#api-access","text":"User group keys come with a key and a secret . You never want to share your secret or save it in a place where it may be exposed. However, when you are in development mode, you can create keys that have signing disabled , meaning no secret is required. This is ideal during development or working with your internal team, because it will make your first steps of app development a bit faster.","title":"API Access"},{"location":"tutorials/hub/development-mode/#create-insecure-keys","text":"You can create your insecure keys during the key generation step, simply select N for requiring signature authentication. \u25b6 hub keys create \u2714 user group ? Require Signature Authentication ( recommended ) ? [ y/N ] N \u2588","title":"Create insecure keys"},{"location":"tutorials/hub/development-mode/#use-insecure-keys","text":"Now, you can use the insecure keys for building your app without having to first setup a user login flow. However, when you are ready to add that step to your app, be sure to use a new set of keys. You can read more about production setup in the next part of this tutorial .","title":"Use insecure keys"},{"location":"tutorials/hub/development-mode/#start-building","text":"With your insecure API key, you have everything you need to start building with the Hub APIs, Threads, and Buckets.","title":"Start building"},{"location":"tutorials/hub/development-mode/#using-the-api","text":"Now, your users have identities and they've verified themselves. Next, you'll want to start created Buckets and ThreadDBs for your user. Let's start using hte Hub from inside the webapp. Install dependencies # Textile libraries npm install --save @textile/hub Connect to the API Now, you just need to create a KeyInfo object above to connect to the API. import { Client , Identity , KeyInfo } from '@textile/hub' ; async function authorize ( key : KeyInfo , identity : Identity ) { const client = await Client . withKeyInfo ( key ) await client . getToken ( identity ) return client } The KeyInfo you supply to the API will look as follows, import { KeyInfo } from '@textile/hub' ; const keyinfo : KeyInfo = { key : 'INSECURE API KEY' , } Your user is now setup to start creating Threads and Buckets that replicate on the Hub API! Read more tutorials or jump over to the js-threads docs to keep building.","title":"Using the API"},{"location":"tutorials/hub/pki-identities/","text":"User identity \u00b6 In this section, we're going to focus on identity. Specifically, we're going to create user identities using private-keys. The Textile Hub supports public-key infrastructure (PKI) allowing your app to support many user identity providers based on PKI (e.g. Metamask, 3Box, uPort, Blockstack) or derive your own. In most of our examples, we'll use a simple, platform agnostic keypair identity based on ed2559 and extending the Noble ed2559 library . Key-based identity access \u00b6 Your application can grant users access to your Hub APIs very easily. When doing so, the Hub can also help you verify that the users are who they claim to be using encryption. The general flow is as follows: A user attempts to sign-in by providing their public key . Your app creates a one-time challenge for the users. The user signs the challenge with their private key to generate credentials . Your app verifies the credentials. Below, we will simplify these steps by using the Hub's helpful token generation endpoint that also does credential verification. Generating an identity \u00b6 In this example, we'll use an identity based on an ed2559 signature scheme and made available through the @textile/hub library. Install dependency npm install --save @textile/hub Generating Identities You can use the PrivateKey utility to generate random new identities (private and public keys) and later, to sign challenges to prove private key ownership. import { PrivateKey } from '@textile/hub' ; async function example () { /** Random new identity */ const identity = await PrivateKey . fromRandom () /** Convert to string. */ const identityString = identity . toString () /** Restore an identity object from a string */ const restored = PrivateKey . fromString ( identityString ) } All of the instances above are different representations of the same user generated by PrivateKey.fromRandom() . Each instance holds a different copy of the user's private-key and therefore should remain private between your app and your user. Caching user identity \u00b6 You can add simple client-side caching to store a user's identity in the browser and restore it when the user returns to the app. Warning localStorage isn't guaranteed and may be cleared by the browser, the system, or the users. Even more important, localStorage isn't a secure place to store secrets. You should provide alternative storage mechanisms if maintaining identity (and therefore data ownership and access) over time is important. import { PrivateKey } from '@textile/hub' ; const getIdentity = async () : Promise < PrivateKey > => { /** Restore any cached user identity first */ const cached = localStorage . getItem ( \"user-private-identity\" ) if ( cached !== null ) { /** Convert the cached identity string to a PrivateKey and return */ return PrivateKey . fromString ( cached ) } /** No cached identity existed, so create a new one */ const identity = await PrivateKey . fromRandom () /** Add the string copy to the cache */ localStorage . setItem ( \"identity\" , identity . toString ()) /** Return the random identity */ return identity } Signing transactions \u00b6 The PrivateKey object contains a signing method, allowing your app to now sign arbitrary bytes for your users. You can create your own identity verification endpoint or use the Hub's token endpoint to verify the credentials. import { PrivateKey } from '@textile/hub' ; async function sign ( identity : PrivateKey ) { const challenge = Buffer . from ( 'Sign this string' ); const credentials = identity . sign ( challenge ); return credentials } Next steps \u00b6 Time to setup your app in development mode . Advanced identity providers \u00b6 Public key provider \u00b6 The below describe two generic identity interfaces used. You can import these interfaces from @textile/hub . // Read more https://textileio.github.io/js-hub/docs/hub.public interface Public { verify ( data : Buffer , sig : Buffer ) : Promise < boolean > } // Read more https://textileio.github.io/js-hub/docs/hub.identity interface Identity { sign ( data : Buffer ) : Promise < Buffer > public : Public } Identity here represents any entity capable of signing a message. This is a simple public key infrastructure inspired interface that similarly requires the implementer to be capable of returning an associated public key for verification. In many cases, the Identity will just be a private key, but callers can use any setup that suits their needs. A default implementation based on Noble ed2559 library but many developers will want to use alternative identity provides, such as 3box/Ceramic , Fortmatic , and existing private/public keypair, or a web3 provider such as Metamask . Textile Hub also provides email-based identities. 3Box \u00b6 One trick with the above workflow is that you need to help your users store and recover their private keys. You could do this with your own user model stored over an API. Alternatively, you can use any keypair manager, such as Metamask. There are a few of steps to generate a Textile compatible identity from the Metamask API. A good starting point is to use the 3Box SDK . 3Box manages a cluster of nodes that web3 users can push small bits of information to. In this approach, a user with a 3Box identity can use that identity to create and track Buckets or Threads generated on Textile. Info As of writing this, 3Box doesn't have Typescript typings available. const Box = require ( \"3box\" ); getIdentity = async () : Promise < PrivateKey > => { /** * Initialize the 3Box API uses Metamask * This will allow the user to sign their transactions * Using Metamask and 3Box directly */ const box = await Box . create (( window as any ). ethereum ) const [ address ] = await ( window as any ). ethereum . enable () await box . auth ([], { address }); // Note: sometimes, openSpace returns early... caution const space = await box . openSpace ( 'io-textile-dropzone' ); await box . syncDone ; try { // We'll try to restore the private key if it's available var storedIdent = await space . private . get ( 'identity' ); if ( storedIdent === null ) { throw new Error ( 'No identity' ) } const identity = await PrivateKey . fromString ( storedIdent ) return identity } catch ( e ) { /** * If the stored identity wasn't found, create a new one. */ const identity = await PrivateKey . fromRandom () const identityString = identity . toString () await space . private . set ( 'identity' , identityString ); return identity } }","title":"User identities"},{"location":"tutorials/hub/pki-identities/#user-identity","text":"In this section, we're going to focus on identity. Specifically, we're going to create user identities using private-keys. The Textile Hub supports public-key infrastructure (PKI) allowing your app to support many user identity providers based on PKI (e.g. Metamask, 3Box, uPort, Blockstack) or derive your own. In most of our examples, we'll use a simple, platform agnostic keypair identity based on ed2559 and extending the Noble ed2559 library .","title":"User identity"},{"location":"tutorials/hub/pki-identities/#key-based-identity-access","text":"Your application can grant users access to your Hub APIs very easily. When doing so, the Hub can also help you verify that the users are who they claim to be using encryption. The general flow is as follows: A user attempts to sign-in by providing their public key . Your app creates a one-time challenge for the users. The user signs the challenge with their private key to generate credentials . Your app verifies the credentials. Below, we will simplify these steps by using the Hub's helpful token generation endpoint that also does credential verification.","title":"Key-based identity access"},{"location":"tutorials/hub/pki-identities/#generating-an-identity","text":"In this example, we'll use an identity based on an ed2559 signature scheme and made available through the @textile/hub library. Install dependency npm install --save @textile/hub Generating Identities You can use the PrivateKey utility to generate random new identities (private and public keys) and later, to sign challenges to prove private key ownership. import { PrivateKey } from '@textile/hub' ; async function example () { /** Random new identity */ const identity = await PrivateKey . fromRandom () /** Convert to string. */ const identityString = identity . toString () /** Restore an identity object from a string */ const restored = PrivateKey . fromString ( identityString ) } All of the instances above are different representations of the same user generated by PrivateKey.fromRandom() . Each instance holds a different copy of the user's private-key and therefore should remain private between your app and your user.","title":"Generating an identity"},{"location":"tutorials/hub/pki-identities/#caching-user-identity","text":"You can add simple client-side caching to store a user's identity in the browser and restore it when the user returns to the app. Warning localStorage isn't guaranteed and may be cleared by the browser, the system, or the users. Even more important, localStorage isn't a secure place to store secrets. You should provide alternative storage mechanisms if maintaining identity (and therefore data ownership and access) over time is important. import { PrivateKey } from '@textile/hub' ; const getIdentity = async () : Promise < PrivateKey > => { /** Restore any cached user identity first */ const cached = localStorage . getItem ( \"user-private-identity\" ) if ( cached !== null ) { /** Convert the cached identity string to a PrivateKey and return */ return PrivateKey . fromString ( cached ) } /** No cached identity existed, so create a new one */ const identity = await PrivateKey . fromRandom () /** Add the string copy to the cache */ localStorage . setItem ( \"identity\" , identity . toString ()) /** Return the random identity */ return identity }","title":"Caching user identity"},{"location":"tutorials/hub/pki-identities/#signing-transactions","text":"The PrivateKey object contains a signing method, allowing your app to now sign arbitrary bytes for your users. You can create your own identity verification endpoint or use the Hub's token endpoint to verify the credentials. import { PrivateKey } from '@textile/hub' ; async function sign ( identity : PrivateKey ) { const challenge = Buffer . from ( 'Sign this string' ); const credentials = identity . sign ( challenge ); return credentials }","title":"Signing transactions"},{"location":"tutorials/hub/pki-identities/#next-steps","text":"Time to setup your app in development mode .","title":"Next steps"},{"location":"tutorials/hub/pki-identities/#advanced-identity-providers","text":"","title":"Advanced identity providers"},{"location":"tutorials/hub/pki-identities/#public-key-provider","text":"The below describe two generic identity interfaces used. You can import these interfaces from @textile/hub . // Read more https://textileio.github.io/js-hub/docs/hub.public interface Public { verify ( data : Buffer , sig : Buffer ) : Promise < boolean > } // Read more https://textileio.github.io/js-hub/docs/hub.identity interface Identity { sign ( data : Buffer ) : Promise < Buffer > public : Public } Identity here represents any entity capable of signing a message. This is a simple public key infrastructure inspired interface that similarly requires the implementer to be capable of returning an associated public key for verification. In many cases, the Identity will just be a private key, but callers can use any setup that suits their needs. A default implementation based on Noble ed2559 library but many developers will want to use alternative identity provides, such as 3box/Ceramic , Fortmatic , and existing private/public keypair, or a web3 provider such as Metamask . Textile Hub also provides email-based identities.","title":"Public key provider"},{"location":"tutorials/hub/pki-identities/#3box","text":"One trick with the above workflow is that you need to help your users store and recover their private keys. You could do this with your own user model stored over an API. Alternatively, you can use any keypair manager, such as Metamask. There are a few of steps to generate a Textile compatible identity from the Metamask API. A good starting point is to use the 3Box SDK . 3Box manages a cluster of nodes that web3 users can push small bits of information to. In this approach, a user with a 3Box identity can use that identity to create and track Buckets or Threads generated on Textile. Info As of writing this, 3Box doesn't have Typescript typings available. const Box = require ( \"3box\" ); getIdentity = async () : Promise < PrivateKey > => { /** * Initialize the 3Box API uses Metamask * This will allow the user to sign their transactions * Using Metamask and 3Box directly */ const box = await Box . create (( window as any ). ethereum ) const [ address ] = await ( window as any ). ethereum . enable () await box . auth ([], { address }); // Note: sometimes, openSpace returns early... caution const space = await box . openSpace ( 'io-textile-dropzone' ); await box . syncDone ; try { // We'll try to restore the private key if it's available var storedIdent = await space . private . get ( 'identity' ); if ( storedIdent === null ) { throw new Error ( 'No identity' ) } const identity = await PrivateKey . fromString ( storedIdent ) return identity } catch ( e ) { /** * If the stored identity wasn't found, create a new one. */ const identity = await PrivateKey . fromRandom () const identityString = identity . toString () await space . private . set ( 'identity' , identityString ); return identity } }","title":"3Box"},{"location":"tutorials/hub/production-auth/","text":"Production mode \u00b6 You've not had time to build and test your app using the insecure keys described in the development mode section. Now, you want to convert your app to running in production mode. To do so, you'll need to: Generate a new API key and secret that has mandatory signing enabled. Set up an authorization endpoint that will hold your API secret and any optional user model for your app. Add a login step to your app that will use the new endpoint to authorization users in your app. Differences from development mode \u00b6 There are a few difference once you switch to production mode. A primary one is that your user's API sessions will expire, meaning that you need to have a way to re-verify them occasionally. For this, we'll move from using the withKeyInfo APIs to a new one called, withUserAuth that can refresh your user sessions smoothly in your app. This new API is also designed to work without access to your secret , so your app can authorize users remotely and provide them that authorization on demand. Other than that, all the APIs will work in the exact same way. User identity \u00b6 If you've followed the tutorials up until now, you are already using PKI , so your users will only ever share their public key with your API (or any API). Therefore, you'll now just need a way to verify that they hold the private key linked with the public key, otherwise users could spoof your system very easily. From there, you can provide Hub API access to your users based on that verification. Authentication server \u00b6 Now, we will setup a simple server that will accept a user's public key, verify that they control the private key (via a challenge), and then grant the user access to the Hub APIs. The user can pass the result (a UserAuth object) to the API and start creating Threads and Buckets. Setup \u00b6 There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A user group key . This is how your users will be able to access your Hub APIs. Consider creating the key in an organization not your personal account so that you can invite collaborators later. A new Typescript project . We recommend using Typescript, as Textile libraries are in a stage rapid of development and type detection is valuable during upgrades. A server framework. The example below uses KoaJS but could just as easily be written for Express or the basic Node server. Install dependencies # Textile libraries npm install --save @textile/hub # Other utilities use in example npm install --save dotenv emittery isomorphic-ws # Libraries specific to our server framework, koajs npm install --save koa koa-router koa-logger koa-json koa-bodyparser koa-route koa-websocket Environment variables We use a .env file in the root of our project repo. The values in the file will be pulled into the app each time it's run. This is where you'll add your Hub API key and secret. Danger The .env file should be added to your .gitignore so that your key and secret are never shared. Contents of .env . USER_API_KEY=<insert user group key> USER_API_SECRET=<insert user group secret> Create the server \u00b6 In our project setup, our main server is defined in src/index.ts . Unlike the simple credentials example , our server needs to handle two-way communication with the client during identity verification. The flow is as follows: First, the client will make a request login. The server will initiate the request with the Hub and get back an identity challenge. The server will pass the challenge to the client . The client will confirm they own their private key by signing the challenge and passing it back to the server The server which passes it on to the Hub. If successful, a token is generated for the user. If successful, the server* generates API credentials and passes credentials, token, and API key back to the **client . Now, the client can use the Hub APIs directly! It sounds complicated, but you'll see it happens very fast with only a few lines of code. In our example, we use websockets to enable the multi-step communication between the server and the client. /** Provides nodejs access to a global Websocket value, required by Hub API */ ;( global as any ). WebSocket = require ( 'isomorphic-ws' ) import koa from \"koa\" import Router from \"koa-router\" import logger from \"koa-logger\" import json from \"koa-json\" import bodyParser from \"koa-bodyparser\" import route from \"koa-route\" import websockify from \"koa-websocket\" import Emittery from \"emittery\" import dotenv from \"dotenv\" import { Client , UserAuth } from \"@textile/hub\" /** Read the values of .env into the environment */ dotenv . config (); /** Port our server will run */ const PORT : number = 3000 /** Init Koa with Websocket support */ const app = websockify ( new koa ()) /** Middlewares */ app . use ( json () ) app . use ( logger () ) app . use ( bodyParser () ) /** * Add websocket login endpoint */ /** Start the server! */ app . listen ( PORT , () => console . log ( \"Server started.\" ) ) Add a websocket login handler \u00b6 Next, we'll add a websocket endpoint to our server. Note the Add websocket login endpoint location in the server code above. The primary step that the server needs to do is accept a pubkey and issue a new challenge back to the client. When successful, new API credentials can be handed to the client. View the full code example in the repo . import { Client } from '@textile/hub' async function example ( pubkey : string ) { /** * Init new Hub API Client with the user group API keys */ const client = await Client . withKeyInfo ({ key : 'USER_API_KEY' , secret : 'USER_API_SECRET' , }) /** * Request a token from the Hub based on the user public key */ const token = await client . getTokenChallenge ( pubkey , /** The callback passes the challenge back to the client */ ( challenge : Buffer ) => { return new Promise (( resolve , reject ) => { // Send the challenge back to the client and // resolve(Buffer.from(sig)) resolve () }) }) } Now when you refresh your locally running server you should have a websocket endpoint for client token creation. Wrap-up \u00b6 Now that the user is verified in your system, you can keep their public key without any security issues. However, you should never trust an API call only by the public key, the challenge step is critical. The token provided in the response should be considered a secret that only should be shared with a single user. It does not expire. Example on GitHub \u00b6 We've provided an abstracted view of the main parts of server-side authentication and authorization. If you'd like to learn more, we've provided a fully working example on GitHub, you can see it here. Login API Source code for login and Hub credentials endpoint. Client (app) authentication \u00b6 Now that our credentials endpoint is set up, we simply need to generate new credentials for each user's identity. A basic client needs to submit a login and handle a challenge request from the server, where the challenge will be signed and returned over websocket. We'll create a login function that handles the back and forth of the websocket and can combine with the withUserAuth function. Login function \u00b6 import { Buckets , Client , Identity , PrivateKey , UserAuth } from '@textile/hub' /** * loginWithChallenge uses websocket to initiate and respond to * a challenge for the user based on their keypair. * * Read more about setting up user verification here: * https://docs.textile.io/tutorials/hub/web-app/ */ const loginWithChallenge = ( id : Identity ) => { return () : Promise < UserAuth > => { return new Promise (( resolve , reject ) => { /** * Configured for our development server * * Note: this should be upgraded to wss for production environments. */ const socketUrl = `ws://localhost:3001/ws/userauth` /** Initialize our websocket connection */ const socket = new WebSocket ( socketUrl ) /** Wait for our socket to open successfully */ socket . onopen = () => { /** Get public key string */ const publicKey = id . public . toString (); /** Send a new token request */ socket . send ( JSON . stringify ({ pubkey : publicKey , type : 'token' , })) /** Listen for messages from the server */ socket . onmessage = async ( event ) => { const data = JSON . parse ( event . data ) switch ( data . type ) { /** Error never happen :) */ case 'error' : { reject ( data . value ) break } /** The server issued a new challenge */ case 'challenge' : { /** Convert the challenge json to a Buffer */ const buf = Buffer . from ( data . value ) /** User our identity to sign the challenge */ const signed = await id . sign ( buf ) /** Send the signed challenge back to the server */ socket . send ( JSON . stringify ({ type : 'challenge' , sig : Buffer.from ( signed ). toJSON (), })) break } /** New token generated */ case 'token' : { resolve ( data . value ) break } } } } }) } } const setupThreads = async ( identity : Identity ) => { /** * By passing a callback, the Threads library can refresh * the session whenever expiring. */ const callback = loginWithChallenge ( identity ) const client = Client . withUserAuth ( callback ) client . getToken ( identity ) return client } Setup buckets \u00b6 Similarly, if you are looking for how to convert your Buckets from using the insecure API to the secure one, the conversion will look like the following. Insecure keys example When using your insecure API key, you typically initialized Buckets like the following. import { Buckets , Identity , KeyInfo } from '@textile/hub' const init = async ( key : KeyInfo , identity : Identity ) => { const buckets = await Buckets . withKeyInfo ( key ) await buckets . getToken ( identity ) return buckets } Secure keys example You will now replace withKeyInfo and getToken with the single, withUserAuth method that requires the callback method. import { Buckets, UserAuth } from '@textile/hub' const init = (getUserAuth: (() => Promise<UserAuth>)) => { const buckets = Buckets.withUserAuth(getUserAuth) return buckets } Wrap-up \u00b6 Now you've had a chance to see how identities work with API keys to provide Hub resources to your users. If you'd like to explore the examples explained above more, we've provided the fully working example on GitHub. Example on GitHub \u00b6 git clone git@github.com:textileio/js-examples.git cd js-examples/hub-browser-auth-app Explore the repo Clone the source code for a server and client using the Hub.","title":"Production authentication"},{"location":"tutorials/hub/production-auth/#production-mode","text":"You've not had time to build and test your app using the insecure keys described in the development mode section. Now, you want to convert your app to running in production mode. To do so, you'll need to: Generate a new API key and secret that has mandatory signing enabled. Set up an authorization endpoint that will hold your API secret and any optional user model for your app. Add a login step to your app that will use the new endpoint to authorization users in your app.","title":"Production mode"},{"location":"tutorials/hub/production-auth/#differences-from-development-mode","text":"There are a few difference once you switch to production mode. A primary one is that your user's API sessions will expire, meaning that you need to have a way to re-verify them occasionally. For this, we'll move from using the withKeyInfo APIs to a new one called, withUserAuth that can refresh your user sessions smoothly in your app. This new API is also designed to work without access to your secret , so your app can authorize users remotely and provide them that authorization on demand. Other than that, all the APIs will work in the exact same way.","title":"Differences from development mode"},{"location":"tutorials/hub/production-auth/#user-identity","text":"If you've followed the tutorials up until now, you are already using PKI , so your users will only ever share their public key with your API (or any API). Therefore, you'll now just need a way to verify that they hold the private key linked with the public key, otherwise users could spoof your system very easily. From there, you can provide Hub API access to your users based on that verification.","title":"User identity"},{"location":"tutorials/hub/production-auth/#authentication-server","text":"Now, we will setup a simple server that will accept a user's public key, verify that they control the private key (via a challenge), and then grant the user access to the Hub APIs. The user can pass the result (a UserAuth object) to the API and start creating Threads and Buckets.","title":"Authentication server"},{"location":"tutorials/hub/production-auth/#setup","text":"There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A user group key . This is how your users will be able to access your Hub APIs. Consider creating the key in an organization not your personal account so that you can invite collaborators later. A new Typescript project . We recommend using Typescript, as Textile libraries are in a stage rapid of development and type detection is valuable during upgrades. A server framework. The example below uses KoaJS but could just as easily be written for Express or the basic Node server. Install dependencies # Textile libraries npm install --save @textile/hub # Other utilities use in example npm install --save dotenv emittery isomorphic-ws # Libraries specific to our server framework, koajs npm install --save koa koa-router koa-logger koa-json koa-bodyparser koa-route koa-websocket Environment variables We use a .env file in the root of our project repo. The values in the file will be pulled into the app each time it's run. This is where you'll add your Hub API key and secret. Danger The .env file should be added to your .gitignore so that your key and secret are never shared. Contents of .env . USER_API_KEY=<insert user group key> USER_API_SECRET=<insert user group secret>","title":"Setup"},{"location":"tutorials/hub/production-auth/#create-the-server","text":"In our project setup, our main server is defined in src/index.ts . Unlike the simple credentials example , our server needs to handle two-way communication with the client during identity verification. The flow is as follows: First, the client will make a request login. The server will initiate the request with the Hub and get back an identity challenge. The server will pass the challenge to the client . The client will confirm they own their private key by signing the challenge and passing it back to the server The server which passes it on to the Hub. If successful, a token is generated for the user. If successful, the server* generates API credentials and passes credentials, token, and API key back to the **client . Now, the client can use the Hub APIs directly! It sounds complicated, but you'll see it happens very fast with only a few lines of code. In our example, we use websockets to enable the multi-step communication between the server and the client. /** Provides nodejs access to a global Websocket value, required by Hub API */ ;( global as any ). WebSocket = require ( 'isomorphic-ws' ) import koa from \"koa\" import Router from \"koa-router\" import logger from \"koa-logger\" import json from \"koa-json\" import bodyParser from \"koa-bodyparser\" import route from \"koa-route\" import websockify from \"koa-websocket\" import Emittery from \"emittery\" import dotenv from \"dotenv\" import { Client , UserAuth } from \"@textile/hub\" /** Read the values of .env into the environment */ dotenv . config (); /** Port our server will run */ const PORT : number = 3000 /** Init Koa with Websocket support */ const app = websockify ( new koa ()) /** Middlewares */ app . use ( json () ) app . use ( logger () ) app . use ( bodyParser () ) /** * Add websocket login endpoint */ /** Start the server! */ app . listen ( PORT , () => console . log ( \"Server started.\" ) )","title":"Create the server"},{"location":"tutorials/hub/production-auth/#add-a-websocket-login-handler","text":"Next, we'll add a websocket endpoint to our server. Note the Add websocket login endpoint location in the server code above. The primary step that the server needs to do is accept a pubkey and issue a new challenge back to the client. When successful, new API credentials can be handed to the client. View the full code example in the repo . import { Client } from '@textile/hub' async function example ( pubkey : string ) { /** * Init new Hub API Client with the user group API keys */ const client = await Client . withKeyInfo ({ key : 'USER_API_KEY' , secret : 'USER_API_SECRET' , }) /** * Request a token from the Hub based on the user public key */ const token = await client . getTokenChallenge ( pubkey , /** The callback passes the challenge back to the client */ ( challenge : Buffer ) => { return new Promise (( resolve , reject ) => { // Send the challenge back to the client and // resolve(Buffer.from(sig)) resolve () }) }) } Now when you refresh your locally running server you should have a websocket endpoint for client token creation.","title":"Add a websocket login handler"},{"location":"tutorials/hub/production-auth/#wrap-up","text":"Now that the user is verified in your system, you can keep their public key without any security issues. However, you should never trust an API call only by the public key, the challenge step is critical. The token provided in the response should be considered a secret that only should be shared with a single user. It does not expire.","title":"Wrap-up"},{"location":"tutorials/hub/production-auth/#example-on-github","text":"We've provided an abstracted view of the main parts of server-side authentication and authorization. If you'd like to learn more, we've provided a fully working example on GitHub, you can see it here.","title":"Example on GitHub"},{"location":"tutorials/hub/production-auth/#client-app-authentication","text":"Now that our credentials endpoint is set up, we simply need to generate new credentials for each user's identity. A basic client needs to submit a login and handle a challenge request from the server, where the challenge will be signed and returned over websocket. We'll create a login function that handles the back and forth of the websocket and can combine with the withUserAuth function.","title":"Client (app) authentication"},{"location":"tutorials/hub/production-auth/#login-function","text":"import { Buckets , Client , Identity , PrivateKey , UserAuth } from '@textile/hub' /** * loginWithChallenge uses websocket to initiate and respond to * a challenge for the user based on their keypair. * * Read more about setting up user verification here: * https://docs.textile.io/tutorials/hub/web-app/ */ const loginWithChallenge = ( id : Identity ) => { return () : Promise < UserAuth > => { return new Promise (( resolve , reject ) => { /** * Configured for our development server * * Note: this should be upgraded to wss for production environments. */ const socketUrl = `ws://localhost:3001/ws/userauth` /** Initialize our websocket connection */ const socket = new WebSocket ( socketUrl ) /** Wait for our socket to open successfully */ socket . onopen = () => { /** Get public key string */ const publicKey = id . public . toString (); /** Send a new token request */ socket . send ( JSON . stringify ({ pubkey : publicKey , type : 'token' , })) /** Listen for messages from the server */ socket . onmessage = async ( event ) => { const data = JSON . parse ( event . data ) switch ( data . type ) { /** Error never happen :) */ case 'error' : { reject ( data . value ) break } /** The server issued a new challenge */ case 'challenge' : { /** Convert the challenge json to a Buffer */ const buf = Buffer . from ( data . value ) /** User our identity to sign the challenge */ const signed = await id . sign ( buf ) /** Send the signed challenge back to the server */ socket . send ( JSON . stringify ({ type : 'challenge' , sig : Buffer.from ( signed ). toJSON (), })) break } /** New token generated */ case 'token' : { resolve ( data . value ) break } } } } }) } } const setupThreads = async ( identity : Identity ) => { /** * By passing a callback, the Threads library can refresh * the session whenever expiring. */ const callback = loginWithChallenge ( identity ) const client = Client . withUserAuth ( callback ) client . getToken ( identity ) return client }","title":"Login function"},{"location":"tutorials/hub/production-auth/#setup-buckets","text":"Similarly, if you are looking for how to convert your Buckets from using the insecure API to the secure one, the conversion will look like the following. Insecure keys example When using your insecure API key, you typically initialized Buckets like the following. import { Buckets , Identity , KeyInfo } from '@textile/hub' const init = async ( key : KeyInfo , identity : Identity ) => { const buckets = await Buckets . withKeyInfo ( key ) await buckets . getToken ( identity ) return buckets } Secure keys example You will now replace withKeyInfo and getToken with the single, withUserAuth method that requires the callback method. import { Buckets, UserAuth } from '@textile/hub' const init = (getUserAuth: (() => Promise<UserAuth>)) => { const buckets = Buckets.withUserAuth(getUserAuth) return buckets }","title":"Setup buckets"},{"location":"tutorials/hub/production-auth/#wrap-up_1","text":"Now you've had a chance to see how identities work with API keys to provide Hub resources to your users. If you'd like to explore the examples explained above more, we've provided the fully working example on GitHub.","title":"Wrap-up"},{"location":"tutorials/hub/production-auth/#example-on-github_1","text":"git clone git@github.com:textileio/js-examples.git cd js-examples/hub-browser-auth-app","title":"Example on GitHub"},{"location":"tutorials/hub/simple-credentials-endpoint/","text":"Create a simple credentials endpoint \u00b6 The simple credentials endpoint requires no user-identity to be sent to the server. It simply receives a request for new API credentials, uses the key and secret, and then returns the credentials to the client. This type of flow is useful for developers or apps with an existing user-validation flow, or who are able to utilize domain whitelisting and/or are hosting their own app. Setup \u00b6 There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A user group key . This is how your users will be able to access your Hub APIs. Consider creating the key in an organization not your personal account so that you can invite collaborators later. A new Typescript project . We recommend using Typescript, as Textile libraries are in a stage rapid of development and type detection is valuable during upgrades. A server framework. The example below uses KoaJS but could just as easily be written for Express or the basic Node server. Install dependencies # Textile libraries npm install --save @textile/hub # Other utilities use in example npm install --save dotenv isomorphic-ws # Libraries specific to our server framework, koajs npm install --save koa koa-router koa-logger koa-json koa-bodyparser Environment variables \u00b6 We'll use a .env file in the root of our project repo where you'll add your Hub API key and secret. The .env file should be added to your .gitignore so that your key and secret are never shared. Contents of .env . USER_API_KEY=alk3rlkjvl323r09fqpoweruw34 USER_API_SECRET=balkweop3jflk9f43lkjs9df2jlght94nzlkv93s Replace the example key and secret values with values you create usint the CLI Create the server \u00b6 In our project setup, our main server is defined in src/index.ts . /** Import our server libraries */ import koa from \"koa\" ; import Router from \"koa-router\" ; import logger from \"koa-logger\" ; import json from \"koa-json\" ; import bodyParser from \"koa-bodyparser\" ; /** For using values in our .env */ import dotenv from \"dotenv\" ; /** Textile libraries */ import { Client , createAPISig , PrivateKey } from '@textile/hub' ; /** Read the values of .env into the environment */ dotenv . config (); /** Port our server will run */ const PORT : number = 3000 ; /** Init Koa */ const app = new koa () /** Middlewares */ app . use ( json () ); app . use ( logger () ); app . use ( bodyParser () ); /** * Start API Routes * * All prefixed with `/api/` */ const api = new Router ({ prefix : '/api' }); /** * Basic foo-bar endpoint * * https://localhost:3000/api/foo */ api . get ( '/foo' , async ( ctx : koa.Context , next : () => Promise < any > ) => { ctx . body = { foo : 'bar' } await next (); }) /** * Add credentials API here */ /** Tell Koa to use the API routes we generate */ app . use ( api . routes () ). use ( api . allowedMethods () ); /** Start the server! */ app . listen ( PORT , () => console . log ( \"Server started.\" ) ); We now have our basic server setup, we can run it and visit http://localhost/api/foo . ts-node src/index.ts Info Follow your Typescript setup guide for specific ways of launching the server. Add the credentials endpoint \u00b6 Next, we'll add an endpoint so the client can get new or refreshed credentials. Note the Add credentials API here location in the server code above. /** * Add credentials API here */ api . get ( '/credentials' , async ( ctx : koa.Context , next : () => Promise < any > ) => { // Custom validation could be done here... /** Get API authorization for the user */ const expiration = new Date ( Date . now () + 60 * seconds ) const auth = await createAPISig ( process . env . USER_API_SECRET , expiration ) /** Include the API KEY in the auth payload */ const credentials = { ... auth , key : process.env.USER_API_KEY , }; /** Return the credentials in a JSON object */ ctx . body = credentials await next (); }); Now when you refresh your locally running server you should be able to visit the following and receive valid credentials. http://localhost:3000/api/credentials Response: { key: \"<your user group api key>\" , msg: \"<your credentials expiration>\" , sig: \"<the api signature>\" } Create a client \u00b6 Back in the browser, you can now make requests to your credentials endpoint. From their, each user can use the Hub token endpoint directly and begin making calls to the Hub APIs. import { Client , UserAuth } from '@textile/hub' const createCredentials = async () : Promise < UserAuth > => { const response = await fetch ( `/api/credentials` , { method : 'GET' , }) const userAuth = await response . json () return userAuth ; } /** Use the simple auth REST endpoint to get API access */ console . log ( 'Verified on Textile API' ) displayStatus (); /** The simple auth endpoint generates a user's Hub API Token */ const client = Client . withUserAuth ( createCredentials ) /** See identity tutorial */ const token = await client . getToken ( identity ) /** Now, full auth object includes the token */ auth = { ... this . auth , token : token , } GitHub Example \u00b6 If you'd like to explore the examples explained above more, we've provided a fully working example on GitHub. The simple credentials endpoint is part of a more complete example, you can see it here. Simple Credentials API Source code for simple Hub credentials endpoint.","title":"Create a simple credentials endpoint"},{"location":"tutorials/hub/simple-credentials-endpoint/#create-a-simple-credentials-endpoint","text":"The simple credentials endpoint requires no user-identity to be sent to the server. It simply receives a request for new API credentials, uses the key and secret, and then returns the credentials to the client. This type of flow is useful for developers or apps with an existing user-validation flow, or who are able to utilize domain whitelisting and/or are hosting their own app.","title":"Create a simple credentials endpoint"},{"location":"tutorials/hub/simple-credentials-endpoint/#setup","text":"There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A user group key . This is how your users will be able to access your Hub APIs. Consider creating the key in an organization not your personal account so that you can invite collaborators later. A new Typescript project . We recommend using Typescript, as Textile libraries are in a stage rapid of development and type detection is valuable during upgrades. A server framework. The example below uses KoaJS but could just as easily be written for Express or the basic Node server. Install dependencies # Textile libraries npm install --save @textile/hub # Other utilities use in example npm install --save dotenv isomorphic-ws # Libraries specific to our server framework, koajs npm install --save koa koa-router koa-logger koa-json koa-bodyparser","title":"Setup"},{"location":"tutorials/hub/simple-credentials-endpoint/#environment-variables","text":"We'll use a .env file in the root of our project repo where you'll add your Hub API key and secret. The .env file should be added to your .gitignore so that your key and secret are never shared. Contents of .env . USER_API_KEY=alk3rlkjvl323r09fqpoweruw34 USER_API_SECRET=balkweop3jflk9f43lkjs9df2jlght94nzlkv93s Replace the example key and secret values with values you create usint the CLI","title":"Environment variables"},{"location":"tutorials/hub/simple-credentials-endpoint/#create-the-server","text":"In our project setup, our main server is defined in src/index.ts . /** Import our server libraries */ import koa from \"koa\" ; import Router from \"koa-router\" ; import logger from \"koa-logger\" ; import json from \"koa-json\" ; import bodyParser from \"koa-bodyparser\" ; /** For using values in our .env */ import dotenv from \"dotenv\" ; /** Textile libraries */ import { Client , createAPISig , PrivateKey } from '@textile/hub' ; /** Read the values of .env into the environment */ dotenv . config (); /** Port our server will run */ const PORT : number = 3000 ; /** Init Koa */ const app = new koa () /** Middlewares */ app . use ( json () ); app . use ( logger () ); app . use ( bodyParser () ); /** * Start API Routes * * All prefixed with `/api/` */ const api = new Router ({ prefix : '/api' }); /** * Basic foo-bar endpoint * * https://localhost:3000/api/foo */ api . get ( '/foo' , async ( ctx : koa.Context , next : () => Promise < any > ) => { ctx . body = { foo : 'bar' } await next (); }) /** * Add credentials API here */ /** Tell Koa to use the API routes we generate */ app . use ( api . routes () ). use ( api . allowedMethods () ); /** Start the server! */ app . listen ( PORT , () => console . log ( \"Server started.\" ) ); We now have our basic server setup, we can run it and visit http://localhost/api/foo . ts-node src/index.ts Info Follow your Typescript setup guide for specific ways of launching the server.","title":"Create the server"},{"location":"tutorials/hub/simple-credentials-endpoint/#add-the-credentials-endpoint","text":"Next, we'll add an endpoint so the client can get new or refreshed credentials. Note the Add credentials API here location in the server code above. /** * Add credentials API here */ api . get ( '/credentials' , async ( ctx : koa.Context , next : () => Promise < any > ) => { // Custom validation could be done here... /** Get API authorization for the user */ const expiration = new Date ( Date . now () + 60 * seconds ) const auth = await createAPISig ( process . env . USER_API_SECRET , expiration ) /** Include the API KEY in the auth payload */ const credentials = { ... auth , key : process.env.USER_API_KEY , }; /** Return the credentials in a JSON object */ ctx . body = credentials await next (); }); Now when you refresh your locally running server you should be able to visit the following and receive valid credentials. http://localhost:3000/api/credentials Response: { key: \"<your user group api key>\" , msg: \"<your credentials expiration>\" , sig: \"<the api signature>\" }","title":"Add the credentials endpoint"},{"location":"tutorials/hub/simple-credentials-endpoint/#create-a-client","text":"Back in the browser, you can now make requests to your credentials endpoint. From their, each user can use the Hub token endpoint directly and begin making calls to the Hub APIs. import { Client , UserAuth } from '@textile/hub' const createCredentials = async () : Promise < UserAuth > => { const response = await fetch ( `/api/credentials` , { method : 'GET' , }) const userAuth = await response . json () return userAuth ; } /** Use the simple auth REST endpoint to get API access */ console . log ( 'Verified on Textile API' ) displayStatus (); /** The simple auth endpoint generates a user's Hub API Token */ const client = Client . withUserAuth ( createCredentials ) /** See identity tutorial */ const token = await client . getToken ( identity ) /** Now, full auth object includes the token */ auth = { ... this . auth , token : token , }","title":"Create a client"},{"location":"tutorials/hub/simple-credentials-endpoint/#github-example","text":"If you'd like to explore the examples explained above more, we've provided a fully working example on GitHub. The simple credentials endpoint is part of a more complete example, you can see it here.","title":"GitHub Example"},{"location":"tutorials/hub/user-buckets/","text":"User Buckets \u00b6 In this tutorial, we'll walk through the key steps to building file hosting and sharing on IPFS into your application. To do it, we'll use Buckets and we'll use an example that allows users of your app to post photo galleries to IPFS, IPNS, and HTTP using Buckets. Getting Started \u00b6 There are a few resources you'll need before you start writing code. A new Typescript web app . We recommend using Typescript, as Textile libraries are in a period rapid of development and type detection is valuable during upgrades. You should already be familiar with how to create user identities and how to generate API keys. Initialize Buckets \u00b6 In your app, there are two items you will regularly use when building on Buckets. The first is the Buckets class object where you will initialize a new session for your user and call various bucket methods. The second is the key of any bucket you want to interact with regularly, since you will need to tell the API which Bucket you are acting on. So, to get started in our app, we are going to do three things at once. Create a new Bucket object. Create or fetch the existing bucket of interest by name. Get the key of the bucket. Info For this tutorial, you will be using an API key generated as part of a User Group key. It is possible to use Account Keys together with these APIs, but they do not work in quite the same way, since only Account owners (or Org members) can use them. A User Group key will allow you to create buckets for each user of your app. import { Buckets , Identity , KeyInfo } from '@textile/hub' const setup = async ( key : KeyInfo , identity : Identity ) => { // Use the insecure key to setup a new session const buckets = await Buckets . withKeyInfo ( key ) // Authorize the user and your insecure keys with getToken await buckets . getToken ( identity ) const result = await buckets . open ( 'io.textile.dropzone' ) if ( ! result . root ) { throw new Error ( 'Failed to open bucket' ) } return { buckets : buckets , bucketKey : result.root.key , } } Create a photo index \u00b6 If you are going to allow your users to upload images, or files, that may become more than a few, it can be helpful to track metadata in an index. In our final example, we resample the photos on the fly, storing multiple sizes for better display performance. We track all those files with a simple JSON index in the root of our bucket. It would be better to store that index right in the user's Thread! But we wanted to keep this tutorial basic. import { Buckets , Identity } from '@textile/hub' const initIndex = async ( buckets : Buckets , bucketKey : string , identity : Identity ) => { // Create a json model for the index const index = { author : identity.public.toString (), date : ( new Date ()). getTime (), paths : [], } // Store the index in the Bucket (or in the Thread later) const buf = Buffer . from ( JSON . stringify ( index , null , 2 )) const path = `index.json` await buckets . pushPath ( bucketKey , path , buf ) } Now, you can update the paths each time you add new images to the bucket. In our example, we add 4 files for every image, full res, medium res, thumbnail, and metdata. We also update the paths with a link to the file's own metadata on each update. In this way, an app can load just the single list of metadata and decide what to display. Create a public view \u00b6 Buckets are cross-protocol objects, meaning you can use them in IPFS, IPNS or HTTP. If you want to create a public view of bucket over HTTP, you should add an index.html to the root. In our example, we add an index.html that knows how to parse and display files based on the ./index.json stored above, in the same bucket. import { Buckets , Identity } from '@textile/hub' const addIndexHTML = async ( buckets : Buckets , bucketKey : string , html : string ) => { // Store the index.html in the root of the bucket const buf = Buffer . from ( html ) const path = `index.html` await buckets . pushPath ( bucketKey , path , buf ) } Push files \u00b6 You are now ready to start pushing your files to the bucket. You can push each binary file to a specific path in the bucket using pushPath . import { Buckets , PushPathResult } from '@textile/hub' const insertFile = ( buckets : Buckets , bucketKey : string , file : File , path : string ) : Promise < PushPathResult > => { return new Promise (( resolve , reject ) => { const reader = new FileReader () reader . onabort = () => reject ( 'file reading was aborted' ) reader . onerror = () => reject ( 'file reading has failed' ) reader . onload = () => { const binaryStr = reader . result // Finally, push the full file to the bucket buckets . pushPath ( bucketKey , path , binaryStr ). then (( raw ) => { resolve ( raw ) }) } reader . readAsArrayBuffer ( file ) }) } At this point, we also update our index.json with the new file. Push encrypted buckets \u00b6 If your app is providing private spaces for your users to organize their photos or files, you can also create encrypted buckets for them. The open and init methods on the Bucket class take an isPrivate option. So your bucket start method may look more like, import { Buckets } from '@textile/hub' const openEncrypted = async ( buckets : Buckets ) => { const isEncrypted = true const result = await buckets . open ( 'io.textile.encrypted' , undefined , isEncrypted ) if ( ! result . root ) { throw new Error ( 'Failed to open bucket' ) } return { buckets : buckets , bucketKey : result.root.key , } } Sharing encrypted buckets \u00b6 There is no way to convert encrypted Buckets to non-encrypted or vice-versa. However, it should be straight-forward to move files from an encrypted Bucket into a non-encrypted Bucket and back again. Adding multiple readers or writers to Buckets is only currently available through orgs for developers, not app users. However, we will include this ability in future release. This is dependent on our work to implement more advanced Threads ACLs . Be aware that creating encrypted Buckets still posts files to IPFS. Meaning the encrypted contents of Buckets are still publicly available, just encrypted so not possible to view without the encryption keys. Example on GitHub \u00b6 git clone git@github.com:textileio/js-examples.git cd js-examples/bucket-photo-gallery Explore the repo Try out the gallery app built with dropzone.js and buckets","title":"Add images to Buckets"},{"location":"tutorials/hub/user-buckets/#user-buckets","text":"In this tutorial, we'll walk through the key steps to building file hosting and sharing on IPFS into your application. To do it, we'll use Buckets and we'll use an example that allows users of your app to post photo galleries to IPFS, IPNS, and HTTP using Buckets.","title":"User Buckets"},{"location":"tutorials/hub/user-buckets/#getting-started","text":"There are a few resources you'll need before you start writing code. A new Typescript web app . We recommend using Typescript, as Textile libraries are in a period rapid of development and type detection is valuable during upgrades. You should already be familiar with how to create user identities and how to generate API keys.","title":"Getting Started"},{"location":"tutorials/hub/user-buckets/#initialize-buckets","text":"In your app, there are two items you will regularly use when building on Buckets. The first is the Buckets class object where you will initialize a new session for your user and call various bucket methods. The second is the key of any bucket you want to interact with regularly, since you will need to tell the API which Bucket you are acting on. So, to get started in our app, we are going to do three things at once. Create a new Bucket object. Create or fetch the existing bucket of interest by name. Get the key of the bucket. Info For this tutorial, you will be using an API key generated as part of a User Group key. It is possible to use Account Keys together with these APIs, but they do not work in quite the same way, since only Account owners (or Org members) can use them. A User Group key will allow you to create buckets for each user of your app. import { Buckets , Identity , KeyInfo } from '@textile/hub' const setup = async ( key : KeyInfo , identity : Identity ) => { // Use the insecure key to setup a new session const buckets = await Buckets . withKeyInfo ( key ) // Authorize the user and your insecure keys with getToken await buckets . getToken ( identity ) const result = await buckets . open ( 'io.textile.dropzone' ) if ( ! result . root ) { throw new Error ( 'Failed to open bucket' ) } return { buckets : buckets , bucketKey : result.root.key , } }","title":"Initialize Buckets"},{"location":"tutorials/hub/user-buckets/#create-a-photo-index","text":"If you are going to allow your users to upload images, or files, that may become more than a few, it can be helpful to track metadata in an index. In our final example, we resample the photos on the fly, storing multiple sizes for better display performance. We track all those files with a simple JSON index in the root of our bucket. It would be better to store that index right in the user's Thread! But we wanted to keep this tutorial basic. import { Buckets , Identity } from '@textile/hub' const initIndex = async ( buckets : Buckets , bucketKey : string , identity : Identity ) => { // Create a json model for the index const index = { author : identity.public.toString (), date : ( new Date ()). getTime (), paths : [], } // Store the index in the Bucket (or in the Thread later) const buf = Buffer . from ( JSON . stringify ( index , null , 2 )) const path = `index.json` await buckets . pushPath ( bucketKey , path , buf ) } Now, you can update the paths each time you add new images to the bucket. In our example, we add 4 files for every image, full res, medium res, thumbnail, and metdata. We also update the paths with a link to the file's own metadata on each update. In this way, an app can load just the single list of metadata and decide what to display.","title":"Create a photo index"},{"location":"tutorials/hub/user-buckets/#create-a-public-view","text":"Buckets are cross-protocol objects, meaning you can use them in IPFS, IPNS or HTTP. If you want to create a public view of bucket over HTTP, you should add an index.html to the root. In our example, we add an index.html that knows how to parse and display files based on the ./index.json stored above, in the same bucket. import { Buckets , Identity } from '@textile/hub' const addIndexHTML = async ( buckets : Buckets , bucketKey : string , html : string ) => { // Store the index.html in the root of the bucket const buf = Buffer . from ( html ) const path = `index.html` await buckets . pushPath ( bucketKey , path , buf ) }","title":"Create a public view"},{"location":"tutorials/hub/user-buckets/#push-files","text":"You are now ready to start pushing your files to the bucket. You can push each binary file to a specific path in the bucket using pushPath . import { Buckets , PushPathResult } from '@textile/hub' const insertFile = ( buckets : Buckets , bucketKey : string , file : File , path : string ) : Promise < PushPathResult > => { return new Promise (( resolve , reject ) => { const reader = new FileReader () reader . onabort = () => reject ( 'file reading was aborted' ) reader . onerror = () => reject ( 'file reading has failed' ) reader . onload = () => { const binaryStr = reader . result // Finally, push the full file to the bucket buckets . pushPath ( bucketKey , path , binaryStr ). then (( raw ) => { resolve ( raw ) }) } reader . readAsArrayBuffer ( file ) }) } At this point, we also update our index.json with the new file.","title":"Push files"},{"location":"tutorials/hub/user-buckets/#push-encrypted-buckets","text":"If your app is providing private spaces for your users to organize their photos or files, you can also create encrypted buckets for them. The open and init methods on the Bucket class take an isPrivate option. So your bucket start method may look more like, import { Buckets } from '@textile/hub' const openEncrypted = async ( buckets : Buckets ) => { const isEncrypted = true const result = await buckets . open ( 'io.textile.encrypted' , undefined , isEncrypted ) if ( ! result . root ) { throw new Error ( 'Failed to open bucket' ) } return { buckets : buckets , bucketKey : result.root.key , } }","title":"Push encrypted buckets"},{"location":"tutorials/hub/user-buckets/#sharing-encrypted-buckets","text":"There is no way to convert encrypted Buckets to non-encrypted or vice-versa. However, it should be straight-forward to move files from an encrypted Bucket into a non-encrypted Bucket and back again. Adding multiple readers or writers to Buckets is only currently available through orgs for developers, not app users. However, we will include this ability in future release. This is dependent on our work to implement more advanced Threads ACLs . Be aware that creating encrypted Buckets still posts files to IPFS. Meaning the encrypted contents of Buckets are still publicly available, just encrypted so not possible to view without the encryption keys.","title":"Sharing encrypted buckets"},{"location":"tutorials/hub/user-buckets/#example-on-github","text":"git clone git@github.com:textileio/js-examples.git cd js-examples/bucket-photo-gallery","title":"Example on GitHub"},{"location":"tutorials/hub/web-app/","text":"Build a Web App using the Hub \u00b6 In this tutorial, you'll learn how to start building JavaScript apps that use the Hub to push Threads and Buckets to the IPFS network (and beyond). We'll walk-through a series of basic setup options and then show you how to build a couple different types of apps. Using the examples shared here, you will see how you can add interoperable, content addressed datasets to your app. We'll show you how to get started with basic cryptographic identities, or how to integrate your existing identity solution. Getting Started \u00b6 There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A new Typescript web app . We recommend using Typescript, as Textile libraries are in a period rapid of development and type detection is valuable during upgrades. Once you have those two things, you can continue to read the overview or jump ahead to: User identity to create simple user identies for the rest of the tutorial. Or, if you plan to provide your own identity setup, you can skip to the development mode setup instructions. Typescript setup \u00b6 Our examples will primarily be built using Typescript. We wont cover the details of setting up a webapp with Typescript because it's well documented elsewhere . Info With your basic Typescript web app setup, you should have a primary .ts (or .js if you decided to stick with Javascript) file where your webapp exists. We'll work within this single file to start, but the instructions below should be adaptable to any application architecture. Browser, Node, or React Native? \u00b6 You can use the JavaScript libraries for all three, though there are some differences to be aware of. Browser \u00b6 Go go go! Green lights ahead. Just read the rest of the docs and get building. Node \u00b6 Some of our libraries rely on WebSockets for moving data around. WebSockets is packed in every major browser out of the box, but doesn't exist in Node the same way. This can be solved by adding WebSockets to the environment. We've solved this in past examples using, isomorphic-ws . Install isomorphic-ws , npm install --save isomorphic-ws ws Add websockets to the global namespace at the start of your app: ;(global as any).WebSocket = require('isomorphic-ws') See an example of that, here . React Native \u00b6 The React Native environment is missing a whole number of required packages, including crypto . Read the React Native tutorial's installation steps to learn how to add the necessary packages. Tutorial overview \u00b6 User identities \u00b6 Setup simple keypair based identities for your app users. View tutorial . To secure or not to secure \u00b6 Learn how to use non-signing API keys for faster app development. View tutorial . Start building apps \u00b6 Build a photo gallery sharing app for users with Buckets. Start here . Add API authorization \u00b6 Add secure API keys and a login flow to your app. View tutorial .","title":"Introduction"},{"location":"tutorials/hub/web-app/#build-a-web-app-using-the-hub","text":"In this tutorial, you'll learn how to start building JavaScript apps that use the Hub to push Threads and Buckets to the IPFS network (and beyond). We'll walk-through a series of basic setup options and then show you how to build a couple different types of apps. Using the examples shared here, you will see how you can add interoperable, content addressed datasets to your app. We'll show you how to get started with basic cryptographic identities, or how to integrate your existing identity solution.","title":"Build a Web App using the Hub"},{"location":"tutorials/hub/web-app/#getting-started","text":"There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A new Typescript web app . We recommend using Typescript, as Textile libraries are in a period rapid of development and type detection is valuable during upgrades. Once you have those two things, you can continue to read the overview or jump ahead to: User identity to create simple user identies for the rest of the tutorial. Or, if you plan to provide your own identity setup, you can skip to the development mode setup instructions.","title":"Getting Started"},{"location":"tutorials/hub/web-app/#typescript-setup","text":"Our examples will primarily be built using Typescript. We wont cover the details of setting up a webapp with Typescript because it's well documented elsewhere . Info With your basic Typescript web app setup, you should have a primary .ts (or .js if you decided to stick with Javascript) file where your webapp exists. We'll work within this single file to start, but the instructions below should be adaptable to any application architecture.","title":"Typescript setup"},{"location":"tutorials/hub/web-app/#browser-node-or-react-native","text":"You can use the JavaScript libraries for all three, though there are some differences to be aware of.","title":"Browser, Node, or React Native?"},{"location":"tutorials/hub/web-app/#browser","text":"Go go go! Green lights ahead. Just read the rest of the docs and get building.","title":"Browser"},{"location":"tutorials/hub/web-app/#node","text":"Some of our libraries rely on WebSockets for moving data around. WebSockets is packed in every major browser out of the box, but doesn't exist in Node the same way. This can be solved by adding WebSockets to the environment. We've solved this in past examples using, isomorphic-ws . Install isomorphic-ws , npm install --save isomorphic-ws ws Add websockets to the global namespace at the start of your app: ;(global as any).WebSocket = require('isomorphic-ws') See an example of that, here .","title":"Node"},{"location":"tutorials/hub/web-app/#react-native","text":"The React Native environment is missing a whole number of required packages, including crypto . Read the React Native tutorial's installation steps to learn how to add the necessary packages.","title":"React Native"},{"location":"tutorials/hub/web-app/#tutorial-overview","text":"","title":"Tutorial overview"},{"location":"tutorials/hub/web-app/#user-identities","text":"Setup simple keypair based identities for your app users. View tutorial .","title":"User identities"},{"location":"tutorials/hub/web-app/#to-secure-or-not-to-secure","text":"Learn how to use non-signing API keys for faster app development. View tutorial .","title":"To secure or not to secure"},{"location":"tutorials/hub/web-app/#start-building-apps","text":"Build a photo gallery sharing app for users with Buckets. Start here .","title":"Start building apps"},{"location":"tutorials/hub/web-app/#add-api-authorization","text":"Add secure API keys and a login flow to your app. View tutorial .","title":"Add API authorization"},{"location":"tutorials/static-websites/gatsby-site/","text":"Gatsby is an open source, free, and easy to use static site builder. Gatsby uses React and helps you deploy your website or app as a progressive web app with the smallest amount of effort. Gatsby allows you to write your content in Markdown and then compile it to HTML with a command-line tool. When you compile your website, Gatsby will create a single folder containing your final website. When you add that folder to a Textile Bucket, you can simultaneously publishing your Gatsby site to IPFS , IPNS , and HTTP. Getting started \u00b6 The rest of this post assumes that you have a basic familiarity with Gatsby. If you don't, at a minimum, you'll need to complete the Gatsby Quickstart . You should now have a basic webpage setup with Gatsby. If you have run gatsby develop , you should be able to see your website at http://localhost:8000 . Building your website \u00b6 When you run your website on your computer, Gatsby will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Gatsby will build your site into a folder public . The content of public is what you'll want to publish to your Bucket. Publish your Bucket \u00b6 First, you'll need to login to Textile and initialize a Project in the root of your Gatsby folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). Build your site with gatsby build . CD into your Gatsby public directory and initialize a Bucket with textile bucket init . That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Gatsby site"},{"location":"tutorials/static-websites/gatsby-site/#getting-started","text":"The rest of this post assumes that you have a basic familiarity with Gatsby. If you don't, at a minimum, you'll need to complete the Gatsby Quickstart . You should now have a basic webpage setup with Gatsby. If you have run gatsby develop , you should be able to see your website at http://localhost:8000 .","title":"Getting started"},{"location":"tutorials/static-websites/gatsby-site/#building-your-website","text":"When you run your website on your computer, Gatsby will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Gatsby will build your site into a folder public . The content of public is what you'll want to publish to your Bucket.","title":"Building your website"},{"location":"tutorials/static-websites/gatsby-site/#publish-your-bucket","text":"First, you'll need to login to Textile and initialize a Project in the root of your Gatsby folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). Build your site with gatsby build . CD into your Gatsby public directory and initialize a Bucket with textile bucket init . That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Publish your Bucket"},{"location":"tutorials/static-websites/hugo-site/","text":"Hugo is a static website development framework written in Go, meaning it's fast. In fact, Hugo claims to be the fastest framework for building websites. Like many of the popular static website frameworks, Hugo allows you to write your content in Markdown and then compile it to HTML with a command-line tool. When you compile your website, Hugo will create a single folder containing your final website. When you add that folder to a Textile Bucket, you can simultaneously publishing your Hugo site to IPFS , IPNS , and HTTP. Here's how. Getting started \u00b6 The rest of this post assumes that you have a basic familiarity with Hugo. If you don't, at a minimum, you'll need to complete the Hugo Quickstart tutorial. You should now have a basic webpage setup with Hugo. If you have run hugo server -D , you should be able to see your website at http://localhost:1313 . Building your website \u00b6 When you run your site on your computer, Hugo will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Hugo will build your site into a folder public . The content of public is what you'll want to publish to your Bucket. Publish your Bucket \u00b6 First, you'll need to login to Textile and initialize a Project in the root of your Hugo folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). Build your site with hugo -D . CD into your Hugo public directory and initialize a Bucket with textile bucket init . Now, you are ready to push your Bucket. textile buckets push That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Hugo site"},{"location":"tutorials/static-websites/hugo-site/#getting-started","text":"The rest of this post assumes that you have a basic familiarity with Hugo. If you don't, at a minimum, you'll need to complete the Hugo Quickstart tutorial. You should now have a basic webpage setup with Hugo. If you have run hugo server -D , you should be able to see your website at http://localhost:1313 .","title":"Getting started"},{"location":"tutorials/static-websites/hugo-site/#building-your-website","text":"When you run your site on your computer, Hugo will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Hugo will build your site into a folder public . The content of public is what you'll want to publish to your Bucket.","title":"Building your website"},{"location":"tutorials/static-websites/hugo-site/#publish-your-bucket","text":"First, you'll need to login to Textile and initialize a Project in the root of your Hugo folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). Build your site with hugo -D . CD into your Hugo public directory and initialize a Bucket with textile bucket init . Now, you are ready to push your Bucket. textile buckets push That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Publish your Bucket"},{"location":"tutorials/static-websites/jekyll-site/","text":"Jekyll is one of the most popular static website building frameworks around. Bonus, Jekyll is also open-source and free. Jekyll allows you to write your content in Markdown and then compile it to HTML with a command-line tool. When you compile your website, Jekyll will create a single folder containing your final website. When you add that folder to a Textile Bucket, you can simultaneously publishing your Jekyll site to IPFS , IPNS , and HTTP. Getting started \u00b6 The rest of this post assumes that you have a basic familiarity with Jekyll. If you don't, at a minimum, you'll need to complete the Jekyll Quickstart tutorial. You should now have a basic webpage setup with Jekyll. If you have run bundle exec jekyll serve , you should be able to see your website at http://localhost:4000 . Building your website \u00b6 When you run your Jekyll site on your computer, Jekyll will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Jekyll will build your site into a folder _site . The content of _site is what you'll want to publish to your Bucket. Publish your Bucket \u00b6 First, you'll need to login to Textile and initialize a Project in the root of your Jekyll folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). Build your site with Jekyll build. CD into your Jekyll _site directory and initialize a Bucket with textile bucket init . Now, you are ready to push your Bucket. textile buckets push That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Jekyll site"},{"location":"tutorials/static-websites/jekyll-site/#getting-started","text":"The rest of this post assumes that you have a basic familiarity with Jekyll. If you don't, at a minimum, you'll need to complete the Jekyll Quickstart tutorial. You should now have a basic webpage setup with Jekyll. If you have run bundle exec jekyll serve , you should be able to see your website at http://localhost:4000 .","title":"Getting started"},{"location":"tutorials/static-websites/jekyll-site/#building-your-website","text":"When you run your Jekyll site on your computer, Jekyll will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Jekyll will build your site into a folder _site . The content of _site is what you'll want to publish to your Bucket.","title":"Building your website"},{"location":"tutorials/static-websites/jekyll-site/#publish-your-bucket","text":"First, you'll need to login to Textile and initialize a Project in the root of your Jekyll folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). Build your site with Jekyll build. CD into your Jekyll _site directory and initialize a Bucket with textile bucket init . Now, you are ready to push your Bucket. textile buckets push That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Publish your Bucket"},{"location":"users/","text":"User Mailboxes \u00b6 The Hub user APIs provide mechanisms for sending and receiving messages between Hub users. Mailboxes are built on ThreadDB. Visit the GoDoc or JavaScript Users doc for a complete list of methods and more usage descriptions. Mailboxes, Identity, and Encryption \u00b6 User mailboxes are designed to be used with private key based identities. You can read more about creating basic PKI identities in our tutorial . It is important that you keep these mailboxes secure by encrypting messages between your users, ideally using their keypairs, so the API clients will handle encryption and decryption for you automatically. How Message Inboxing Works \u00b6 Sending \u00b6 Your app creates a new user using their identity and your Hub API key. Your app user authors a new message for a contact, based on the remote contact's public key. Your app user encrypts the message using the remote users public key (encyption is handled by Hub library). You app sends the message to the remote user's inbox Receiving \u00b6 You app user checks their Hub inbox using your API key. Your user can pull any available messages (latest or using simple filters). Any message body will be encrypted, so will require to decrypt the message using their private key. User can then read and verify the message came from the recipient. Creating mailboxes \u00b6 A user's mailbox needs to be initiated by them (through your app) before other users can begin sending them messages. We suggest you do this as part of the onboarding steps in your app. You can read about this creation process in Go here and in JavaScript here . Using inboxes and sentboxes \u00b6 After a mailbox is set up you can now add the following methods to your application: Get existing mailbox. Golang JavaScript . Send messages. Golang JavaScript . Watch inbox. Golang JavaScript . And more! Message encryption and signing \u00b6 Messages are encypted using the recipient's ed2559 public key, meaning that the body of the message can only be read by the private key holder. Read more about the identity utilities in the identity tutorial . Some methods you will find useful include: PrivateKey Identities Encryption by PublicKey Decrypt by PrivateKey Sign by PrivateKey","title":"User Mailboxes"},{"location":"users/#user-mailboxes","text":"The Hub user APIs provide mechanisms for sending and receiving messages between Hub users. Mailboxes are built on ThreadDB. Visit the GoDoc or JavaScript Users doc for a complete list of methods and more usage descriptions.","title":"User Mailboxes"},{"location":"users/#mailboxes-identity-and-encryption","text":"User mailboxes are designed to be used with private key based identities. You can read more about creating basic PKI identities in our tutorial . It is important that you keep these mailboxes secure by encrypting messages between your users, ideally using their keypairs, so the API clients will handle encryption and decryption for you automatically.","title":"Mailboxes, Identity, and Encryption"},{"location":"users/#how-message-inboxing-works","text":"","title":"How Message Inboxing Works"},{"location":"users/#sending","text":"Your app creates a new user using their identity and your Hub API key. Your app user authors a new message for a contact, based on the remote contact's public key. Your app user encrypts the message using the remote users public key (encyption is handled by Hub library). You app sends the message to the remote user's inbox","title":"Sending"},{"location":"users/#receiving","text":"You app user checks their Hub inbox using your API key. Your user can pull any available messages (latest or using simple filters). Any message body will be encrypted, so will require to decrypt the message using their private key. User can then read and verify the message came from the recipient.","title":"Receiving"},{"location":"users/#creating-mailboxes","text":"A user's mailbox needs to be initiated by them (through your app) before other users can begin sending them messages. We suggest you do this as part of the onboarding steps in your app. You can read about this creation process in Go here and in JavaScript here .","title":"Creating mailboxes"},{"location":"users/#using-inboxes-and-sentboxes","text":"After a mailbox is set up you can now add the following methods to your application: Get existing mailbox. Golang JavaScript . Send messages. Golang JavaScript . Watch inbox. Golang JavaScript . And more!","title":"Using inboxes and sentboxes"},{"location":"users/#message-encryption-and-signing","text":"Messages are encypted using the recipient's ed2559 public key, meaning that the body of the message can only be read by the private key holder. Read more about the identity utilities in the identity tutorial . Some methods you will find useful include: PrivateKey Identities Encryption by PublicKey Decrypt by PrivateKey Sign by PrivateKey","title":"Message encryption and signing"}]}